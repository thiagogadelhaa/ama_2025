{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1e6b27-e0f1-41fb-842b-62f38834de95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score, roc_curve, auc, precision_recall_curve, average_precision_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c849f7-d51a-4f88-a9bd-54f915d5f705",
   "metadata": {},
   "source": [
    "# Importando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d26ccc2d-cfec-4ac2-920b-ec5dd109efa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>date_game</th>\n",
       "      <th>team_1</th>\n",
       "      <th>team_2</th>\n",
       "      <th>team_1_mp</th>\n",
       "      <th>team_1_fg</th>\n",
       "      <th>team_1_fga</th>\n",
       "      <th>team_1_fg_pct</th>\n",
       "      <th>team_1_fg3</th>\n",
       "      <th>team_1_fg3a</th>\n",
       "      <th>...</th>\n",
       "      <th>team_2_trb_pct</th>\n",
       "      <th>team_2_ast_pct</th>\n",
       "      <th>team_2_stl_pct</th>\n",
       "      <th>team_2_blk_pct</th>\n",
       "      <th>team_2_tov_pct</th>\n",
       "      <th>team_2_usg_pct</th>\n",
       "      <th>team_2_off_rtg</th>\n",
       "      <th>team_2_def_rtg</th>\n",
       "      <th>team_2_ws</th>\n",
       "      <th>game_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8569</th>\n",
       "      <td>2011</td>\n",
       "      <td>Tue, Oct 26, 2010</td>\n",
       "      <td>BOS</td>\n",
       "      <td>MIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8570</th>\n",
       "      <td>2011</td>\n",
       "      <td>Fri, Oct 29, 2010</td>\n",
       "      <td>BOS</td>\n",
       "      <td>NYK</td>\n",
       "      <td>240.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.472</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>52.1</td>\n",
       "      <td>31.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>11.9</td>\n",
       "      <td>14.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.6</td>\n",
       "      <td>95.5</td>\n",
       "      <td>W 1</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8571</th>\n",
       "      <td>2011</td>\n",
       "      <td>Wed, Nov 3, 2010</td>\n",
       "      <td>BOS</td>\n",
       "      <td>MIL</td>\n",
       "      <td>240.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.519</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.6</td>\n",
       "      <td>59.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>7.1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>89.5</td>\n",
       "      <td>106.0</td>\n",
       "      <td>L 1</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8572</th>\n",
       "      <td>2011</td>\n",
       "      <td>Fri, Nov 5, 2010</td>\n",
       "      <td>BOS</td>\n",
       "      <td>CHI</td>\n",
       "      <td>265.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.468</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>52.5</td>\n",
       "      <td>64.3</td>\n",
       "      <td>8.1</td>\n",
       "      <td>10.7</td>\n",
       "      <td>17.7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>113.6</td>\n",
       "      <td>121.7</td>\n",
       "      <td>L 1</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8573</th>\n",
       "      <td>2011</td>\n",
       "      <td>Wed, Nov 17, 2010</td>\n",
       "      <td>BOS</td>\n",
       "      <td>WAS</td>\n",
       "      <td>265.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.577</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>56.6</td>\n",
       "      <td>62.2</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>15.3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>118.4</td>\n",
       "      <td>102.1</td>\n",
       "      <td>W 1</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      season          date_game team_1 team_2  team_1_mp  team_1_fg  \\\n",
       "8569    2011  Tue, Oct 26, 2010    BOS    MIA        NaN        NaN   \n",
       "8570    2011  Fri, Oct 29, 2010    BOS    NYK      240.0       34.0   \n",
       "8571    2011   Wed, Nov 3, 2010    BOS    MIL      240.0       42.0   \n",
       "8572    2011   Fri, Nov 5, 2010    BOS    CHI      265.0       37.0   \n",
       "8573    2011  Wed, Nov 17, 2010    BOS    WAS      265.0       45.0   \n",
       "\n",
       "      team_1_fga  team_1_fg_pct  team_1_fg3  team_1_fg3a  ...  team_2_trb_pct  \\\n",
       "8569         NaN            NaN         NaN          NaN  ...             NaN   \n",
       "8570        72.0          0.472         3.0         12.0  ...            52.1   \n",
       "8571        81.0          0.519         7.0         21.0  ...            50.6   \n",
       "8572        79.0          0.468         4.0         12.0  ...            52.5   \n",
       "8573        78.0          0.577         7.0         12.0  ...            56.6   \n",
       "\n",
       "      team_2_ast_pct  team_2_stl_pct  team_2_blk_pct  team_2_tov_pct  \\\n",
       "8569             NaN             NaN             NaN             NaN   \n",
       "8570            31.6             4.1            11.9            14.4   \n",
       "8571            59.3             4.7             7.1            17.0   \n",
       "8572            64.3             8.1            10.7            17.7   \n",
       "8573            62.2             9.8             6.7            15.3   \n",
       "\n",
       "      team_2_usg_pct  team_2_off_rtg  team_2_def_rtg  team_2_ws  game_result  \n",
       "8569             NaN             NaN             NaN        NaN          NaN  \n",
       "8570           100.0           100.6            95.5        W 1            W  \n",
       "8571           100.0            89.5           106.0        L 1            W  \n",
       "8572           100.0           113.6           121.7        L 1            W  \n",
       "8573           100.0           118.4           102.1        W 1            W  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dados_jogos.csv')\n",
    "df = df[df['season']>2010]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7fc0b6b-6e2c-4672-9630-6d8b85598c47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 16683 entries, 8569 to 25251\n",
      "Data columns (total 73 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   season                   16683 non-null  int64  \n",
      " 1   date_game                16683 non-null  object \n",
      " 2   team_1                   16683 non-null  object \n",
      " 3   team_2                   16683 non-null  object \n",
      " 4   team_1_mp                16450 non-null  float64\n",
      " 5   team_1_fg                16450 non-null  float64\n",
      " 6   team_1_fga               16450 non-null  float64\n",
      " 7   team_1_fg_pct            16450 non-null  float64\n",
      " 8   team_1_fg3               16450 non-null  float64\n",
      " 9   team_1_fg3a              16450 non-null  float64\n",
      " 10  team_1_fg3_pct           16450 non-null  float64\n",
      " 11  team_1_ft                16450 non-null  float64\n",
      " 12  team_1_fta               16450 non-null  float64\n",
      " 13  team_1_ft_pct            16449 non-null  float64\n",
      " 14  team_1_orb               16450 non-null  float64\n",
      " 15  team_1_drb               16450 non-null  float64\n",
      " 16  team_1_trb               16450 non-null  float64\n",
      " 17  team_1_ast               16450 non-null  float64\n",
      " 18  team_1_stl               16450 non-null  float64\n",
      " 19  team_1_blk               16450 non-null  float64\n",
      " 20  team_1_tov               16450 non-null  float64\n",
      " 21  team_1_pf                16450 non-null  float64\n",
      " 22  team_1_pts               16450 non-null  float64\n",
      " 23  team_1_ts_pct            16450 non-null  float64\n",
      " 24  team_1_efg_pct           16450 non-null  float64\n",
      " 25  team_1_fg3a_per_fga_pct  16450 non-null  float64\n",
      " 26  team_1_fta_per_fga_pct   16450 non-null  float64\n",
      " 27  team_1_orb_pct           16450 non-null  float64\n",
      " 28  team_1_drb_pct           16450 non-null  float64\n",
      " 29  team_1_trb_pct           16450 non-null  float64\n",
      " 30  team_1_ast_pct           16450 non-null  float64\n",
      " 31  team_1_stl_pct           16450 non-null  float64\n",
      " 32  team_1_blk_pct           16450 non-null  float64\n",
      " 33  team_1_tov_pct           16450 non-null  float64\n",
      " 34  team_1_usg_pct           16450 non-null  float64\n",
      " 35  team_1_off_rtg           16450 non-null  float64\n",
      " 36  team_1_def_rtg           16442 non-null  float64\n",
      " 37  team_1_ws                16450 non-null  object \n",
      " 38  team_2_mp                16450 non-null  float64\n",
      " 39  team_2_fg                16450 non-null  float64\n",
      " 40  team_2_fga               16450 non-null  float64\n",
      " 41  team_2_fg_pct            16450 non-null  float64\n",
      " 42  team_2_fg3               16450 non-null  float64\n",
      " 43  team_2_fg3a              16450 non-null  float64\n",
      " 44  team_2_fg3_pct           16450 non-null  float64\n",
      " 45  team_2_ft                16450 non-null  float64\n",
      " 46  team_2_fta               16450 non-null  float64\n",
      " 47  team_2_ft_pct            16450 non-null  float64\n",
      " 48  team_2_orb               16450 non-null  float64\n",
      " 49  team_2_drb               16450 non-null  float64\n",
      " 50  team_2_trb               16450 non-null  float64\n",
      " 51  team_2_ast               16450 non-null  float64\n",
      " 52  team_2_stl               16450 non-null  float64\n",
      " 53  team_2_blk               16450 non-null  float64\n",
      " 54  team_2_tov               16450 non-null  float64\n",
      " 55  team_2_pf                16450 non-null  float64\n",
      " 56  team_2_pts               16450 non-null  float64\n",
      " 57  team_2_ts_pct            16450 non-null  float64\n",
      " 58  team_2_efg_pct           16450 non-null  float64\n",
      " 59  team_2_fg3a_per_fga_pct  16450 non-null  float64\n",
      " 60  team_2_fta_per_fga_pct   16450 non-null  float64\n",
      " 61  team_2_orb_pct           16450 non-null  float64\n",
      " 62  team_2_drb_pct           16450 non-null  float64\n",
      " 63  team_2_trb_pct           16450 non-null  float64\n",
      " 64  team_2_ast_pct           16450 non-null  float64\n",
      " 65  team_2_stl_pct           16450 non-null  float64\n",
      " 66  team_2_blk_pct           16450 non-null  float64\n",
      " 67  team_2_tov_pct           16450 non-null  float64\n",
      " 68  team_2_usg_pct           16450 non-null  float64\n",
      " 69  team_2_off_rtg           16450 non-null  float64\n",
      " 70  team_2_def_rtg           16442 non-null  float64\n",
      " 71  team_2_ws                16450 non-null  object \n",
      " 72  game_result              16450 non-null  object \n",
      "dtypes: float64(66), int64(1), object(6)\n",
      "memory usage: 9.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56ad574e-cd80-441e-9ce3-79d4d3999322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['season', 'date_game', 'team_1', 'team_2', 'team_1_mp', 'team_1_fg',\n",
       "       'team_1_fga', 'team_1_fg_pct', 'team_1_fg3', 'team_1_fg3a',\n",
       "       'team_1_fg3_pct', 'team_1_ft', 'team_1_fta', 'team_1_ft_pct',\n",
       "       'team_1_orb', 'team_1_drb', 'team_1_trb', 'team_1_ast', 'team_1_stl',\n",
       "       'team_1_blk', 'team_1_tov', 'team_1_pf', 'team_1_pts', 'team_1_ts_pct',\n",
       "       'team_1_efg_pct', 'team_1_fg3a_per_fga_pct', 'team_1_fta_per_fga_pct',\n",
       "       'team_1_orb_pct', 'team_1_drb_pct', 'team_1_trb_pct', 'team_1_ast_pct',\n",
       "       'team_1_stl_pct', 'team_1_blk_pct', 'team_1_tov_pct', 'team_1_usg_pct',\n",
       "       'team_1_off_rtg', 'team_1_def_rtg', 'team_1_ws', 'team_2_mp',\n",
       "       'team_2_fg', 'team_2_fga', 'team_2_fg_pct', 'team_2_fg3', 'team_2_fg3a',\n",
       "       'team_2_fg3_pct', 'team_2_ft', 'team_2_fta', 'team_2_ft_pct',\n",
       "       'team_2_orb', 'team_2_drb', 'team_2_trb', 'team_2_ast', 'team_2_stl',\n",
       "       'team_2_blk', 'team_2_tov', 'team_2_pf', 'team_2_pts', 'team_2_ts_pct',\n",
       "       'team_2_efg_pct', 'team_2_fg3a_per_fga_pct', 'team_2_fta_per_fga_pct',\n",
       "       'team_2_orb_pct', 'team_2_drb_pct', 'team_2_trb_pct', 'team_2_ast_pct',\n",
       "       'team_2_stl_pct', 'team_2_blk_pct', 'team_2_tov_pct', 'team_2_usg_pct',\n",
       "       'team_2_off_rtg', 'team_2_def_rtg', 'team_2_ws', 'game_result'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "189c4e6d-8f00-4883-a33c-9d4aa0c9aaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['team_1_mp', 'team_1_fg',\n",
    "       'team_1_fga', 'team_1_fg_pct', 'team_1_fg3', 'team_1_fg3a',\n",
    "       'team_1_fg3_pct', 'team_1_ft', 'team_1_fta', 'team_1_ft_pct',\n",
    "       'team_1_orb', 'team_1_drb', 'team_1_trb', 'team_1_ast', 'team_1_stl',\n",
    "       'team_1_blk', 'team_1_tov', 'team_1_pf', 'team_1_pts', 'team_1_ts_pct',\n",
    "       'team_1_efg_pct', 'team_1_fg3a_per_fga_pct', 'team_1_fta_per_fga_pct',\n",
    "       'team_1_orb_pct', 'team_1_drb_pct', 'team_1_trb_pct', 'team_1_ast_pct',\n",
    "       'team_1_stl_pct', 'team_1_blk_pct', 'team_1_tov_pct', 'team_1_usg_pct',\n",
    "       'team_1_off_rtg', 'team_1_def_rtg', 'team_1_ws','team_2_mp',\n",
    "       'team_2_fg', 'team_2_fga', 'team_2_fg_pct', 'team_2_fg3', 'team_2_fg3a',\n",
    "       'team_2_fg3_pct', 'team_2_ft', 'team_2_fta', 'team_2_ft_pct',\n",
    "       'team_2_orb', 'team_2_drb', 'team_2_trb', 'team_2_ast', 'team_2_stl',\n",
    "       'team_2_blk', 'team_2_tov', 'team_2_pf', 'team_2_pts', 'team_2_ts_pct',\n",
    "       'team_2_efg_pct', 'team_2_fg3a_per_fga_pct', 'team_2_fta_per_fga_pct',\n",
    "       'team_2_orb_pct', 'team_2_drb_pct', 'team_2_trb_pct', 'team_2_ast_pct',\n",
    "       'team_2_stl_pct', 'team_2_blk_pct', 'team_2_tov_pct', 'team_2_usg_pct',\n",
    "       'team_2_off_rtg', 'team_2_def_rtg', 'team_2_ws'], inplace = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "628646f9-e27e-49ac-8624-d1b4a4ecf568",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['team_2_ws'] = df['team_2_ws'].apply(lambda x: int(x[1:].strip()) if x[0]=='W' else -int(x[1:].strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74bda396-7068-45a1-8e36-74c228be95f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['team_1_ws'] = df['team_1_ws'].apply(lambda x: int(x[1:].strip()) if x[0]=='W' else -int(x[1:].strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d32d2cd6-f1af-45ac-a437-1f50336b56fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['game_result'] = df['game_result'].apply(lambda x: 1 if x.strip()=='W' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40cff838-a4a6-4fbc-8949-2b0f2eb7a801",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['team_1_mp', 'team_1_fg',\n",
    "       'team_1_fga', 'team_1_fg_pct', 'team_1_fg3', 'team_1_fg3a',\n",
    "       'team_1_fg3_pct', 'team_1_ft', 'team_1_fta', 'team_1_ft_pct',\n",
    "       'team_1_orb', 'team_1_drb', 'team_1_trb', 'team_1_ast', 'team_1_stl',\n",
    "       'team_1_blk', 'team_1_tov', 'team_1_pf', 'team_1_pts', 'team_1_ts_pct',\n",
    "       'team_1_efg_pct', 'team_1_fg3a_per_fga_pct', 'team_1_fta_per_fga_pct',\n",
    "       'team_1_orb_pct', 'team_1_drb_pct', 'team_1_trb_pct', 'team_1_ast_pct',\n",
    "       'team_1_stl_pct', 'team_1_blk_pct', 'team_1_tov_pct', 'team_1_usg_pct',\n",
    "       'team_1_off_rtg', 'team_1_def_rtg', 'team_1_ws','team_2_mp',\n",
    "       'team_2_fg', 'team_2_fga', 'team_2_fg_pct', 'team_2_fg3', 'team_2_fg3a',\n",
    "       'team_2_fg3_pct', 'team_2_ft', 'team_2_fta', 'team_2_ft_pct',\n",
    "       'team_2_orb', 'team_2_drb', 'team_2_trb', 'team_2_ast', 'team_2_stl',\n",
    "       'team_2_blk', 'team_2_tov', 'team_2_pf', 'team_2_pts', 'team_2_ts_pct',\n",
    "       'team_2_efg_pct', 'team_2_fg3a_per_fga_pct', 'team_2_fta_per_fga_pct',\n",
    "       'team_2_orb_pct', 'team_2_drb_pct', 'team_2_trb_pct', 'team_2_ast_pct',\n",
    "       'team_2_stl_pct', 'team_2_blk_pct', 'team_2_tov_pct', 'team_2_usg_pct',\n",
    "       'team_2_off_rtg', 'team_2_def_rtg', 'team_2_ws']]\n",
    "\n",
    "y = df['game_result']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c823a80-4321-4d30-beb6-c150cea4b7e9",
   "metadata": {},
   "source": [
    "# Separando os dados em treinamento e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fff2442e-746b-47c1-bf88-ff11d1a1b1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando em validação e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a20af2fc-9562-4846-9532-96390b6baa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_norma =  pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3c170e-2e7d-4574-b3b6-944bc4e2ee07",
   "metadata": {},
   "source": [
    "# Usando o RandomizedSearchCV para a seleção de hiperparametros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefd7dfa-da23-402a-a350-135c6d390a7c",
   "metadata": {},
   "source": [
    "## XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0c6f50c3-0566-4670-a471-1dfbfd157b09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 150 candidates, totalling 1500 fits\n",
      "[CV] END ....................C=1, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END ...................C=0.75, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END ....................C=5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ....................C=1.5, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=1.5, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ....................C=1.5, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=1.5, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=1.5, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ....................C=1.5, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ....................C=1.5, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=1.5, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ....................C=1.5, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=1, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END ......................C=1, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.25, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.25, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=10, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l2; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.3, max_depth=4, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   1.8s\n",
      "[CV] END .................C=0.75, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=0.5, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=0.5, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=0.5, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ....................C=0.5, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=0.5, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=0.5, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=0.5, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END ......................C=3, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END ....................C=1.5, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=1.5, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=10, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=10, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ...................C=20, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.3, max_depth=4, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=4, n_estimators=250, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   6.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END ...................C=20, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=10, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=5, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .................C=0.75, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.75, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.75, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.75, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ....................C=0.5, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=0.5, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ..................C=1.5, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l2; total time=   0.5s\n",
      "[CV] END ......................C=3, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END ......................C=3, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=5, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=5, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=5, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=5, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=5, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=5, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=5, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=5, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=5, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=5, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ...................C=0.75, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=7, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=7, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=1, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END ......................C=1, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.25, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.25, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=1.5, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=1.5, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l2; total time=   0.5s\n",
      "[CV] END .....................C=10, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.3, max_depth=4, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=4, n_estimators=250, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   6.1s\n",
      "[CV] END ....................C=3, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=3, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=0.5, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=0.5, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=0.5, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=0.5, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=0.5, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.75, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.75, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.75, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.75, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.75, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END ...................C=0.75, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.75, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.75, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END ......................C=1, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=1, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END ......................C=1, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END ......................C=1, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=1, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=1, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=1, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END ......................C=1, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END ......................C=1, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END ......................C=1, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=10, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=10, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=10, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=10, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=10, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=10, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=10, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=10, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=10, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=10, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ...................C=0.75, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ...................C=0.75, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.75, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END ...................C=0.25, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=10, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=10, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=10, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=10, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=10, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ....................C=5, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.3, max_depth=4, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=4, n_estimators=250, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   6.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.2, max_depth=6, n_estimators=250, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   7.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=250, reg_alpha=0.5, reg_lambda=1.5, subsample=0.8, tree_method=approx; total time=   6.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.3, max_depth=6, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.3, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   0.6s\n",
      "[CV] END ..................C=0.5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=0.5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=0.5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=0.5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=0.5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=0.5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=0.5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=0.5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=0.5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=0.5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=1, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=200, penalty=l2; total time=   0.1s\n",
      "[CV] END ....................C=0.5, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END ..................C=1.5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l2; total time=   0.5s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ...................C=0.25, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=1.5, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=10, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END ...................C=20, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.3, max_depth=4, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=4, n_estimators=250, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   6.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.2, max_depth=6, n_estimators=250, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   6.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=3, n_estimators=200, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=250, reg_alpha=0.5, reg_lambda=1.5, subsample=0.8, tree_method=approx; total time=   5.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.3, max_depth=6, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.3, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=3, n_estimators=100, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=200, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=3, n_estimators=100, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=200, reg_alpha=0, reg_lambda=1.5, subsample=0.8, tree_method=approx; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.3, max_depth=5, n_estimators=250, reg_alpha=0, reg_lambda=1.5, subsample=0.6, tree_method=exact; total time=   3.7s\n",
      "[CV] END ....................C=0.5, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=0.5, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=0.5, max_iter=300, penalty=l2; total time=   0.1s\n",
      "[CV] END ....................C=0.5, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END ...................C=0.25, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.25, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ......................C=1, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ......................C=1, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=1, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ......................C=1, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=1, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ......................C=1, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=1, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ......................C=1, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ......................C=3, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=3, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ...................C=12, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=10, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=10, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=10, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=10, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=10, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=10, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=10, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.3, max_depth=4, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=4, n_estimators=250, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   6.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.2, max_depth=6, n_estimators=250, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   6.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=3, n_estimators=200, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=3, n_estimators=200, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=250, reg_alpha=0.5, reg_lambda=1.5, subsample=0.8, tree_method=approx; total time=   5.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.3, max_depth=6, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.3, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=3, n_estimators=100, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=200, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=3, n_estimators=100, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=200, reg_alpha=0, reg_lambda=1.5, subsample=0.8, tree_method=approx; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.3, max_depth=5, n_estimators=250, reg_alpha=0, reg_lambda=1.5, subsample=0.6, tree_method=exact; total time=   3.8s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ....................C=1, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=12, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=12, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=12, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=12, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=12, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=12, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=12, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=12, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=12, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END ......................C=1, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=20, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.25, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=1.5, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=1.5, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=10, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=10, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l2; total time=   0.1s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.3, max_depth=4, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=4, n_estimators=250, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   6.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.2, max_depth=6, n_estimators=250, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   6.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=3, n_estimators=200, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=250, reg_alpha=0.5, reg_lambda=1.5, subsample=0.8, tree_method=approx; total time=   6.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.3, max_depth=6, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.3, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=3, n_estimators=100, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=200, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=200, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=3, n_estimators=100, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=200, reg_alpha=0, reg_lambda=1.5, subsample=0.8, tree_method=approx; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.3, max_depth=5, n_estimators=250, reg_alpha=0, reg_lambda=1.5, subsample=0.6, tree_method=exact; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=3, n_estimators=150, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=4, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   7.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   7.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.3, max_depth=6, n_estimators=150, reg_alpha=1, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=approx; total time=   8.7s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=1, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ...................C=0.25, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.25, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=10, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l2; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.3, max_depth=4, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=4, n_estimators=250, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   6.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.2, max_depth=6, n_estimators=250, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   6.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=hist; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=250, reg_alpha=0.5, reg_lambda=1.5, subsample=0.8, tree_method=approx; total time=   6.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.3, max_depth=6, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.3, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=3, n_estimators=100, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=3, n_estimators=100, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=200, reg_alpha=0, reg_lambda=1.5, subsample=0.8, tree_method=approx; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.3, max_depth=5, n_estimators=250, reg_alpha=0, reg_lambda=1.5, subsample=0.6, tree_method=exact; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=3, n_estimators=150, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=4, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   7.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   7.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.3, max_depth=6, n_estimators=150, reg_alpha=1, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=approx; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   6.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=4, n_estimators=300, reg_alpha=1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=4, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   4.2s\n",
      "[CV] END ......................C=1, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ...................C=20, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.25, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=1.5, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=1.5, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=10, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=10, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l2; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.3, max_depth=4, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=4, n_estimators=250, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   6.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.2, max_depth=6, n_estimators=250, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   6.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=3, n_estimators=200, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=250, reg_alpha=0.5, reg_lambda=1.5, subsample=0.8, tree_method=approx; total time=   5.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.3, max_depth=6, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.3, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=3, n_estimators=100, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=200, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=3, n_estimators=100, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=200, reg_alpha=0, reg_lambda=1.5, subsample=0.8, tree_method=approx; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.3, max_depth=5, n_estimators=250, reg_alpha=0, reg_lambda=1.5, subsample=0.6, tree_method=exact; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=3, n_estimators=150, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=4, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   7.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   7.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.3, max_depth=6, n_estimators=150, reg_alpha=1, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=approx; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   6.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=4, n_estimators=300, reg_alpha=1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=4, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.3, max_depth=6, n_estimators=200, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=exact; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=3, n_estimators=200, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   5.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0.5, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.3, max_depth=4, n_estimators=200, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=4, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=approx; total time=   7.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=150, reg_alpha=0, reg_lambda=2, subsample=1.0, tree_method=approx; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   8.3s\n",
      "[CV] END ......................C=1, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=10, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=10, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.3, max_depth=4, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=4, n_estimators=250, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   6.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.2, max_depth=6, n_estimators=250, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   6.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=3, n_estimators=200, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=3, n_estimators=200, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=250, reg_alpha=0.5, reg_lambda=1.5, subsample=0.8, tree_method=approx; total time=   5.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.3, max_depth=6, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.3, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=3, n_estimators=100, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=200, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=3, n_estimators=100, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=200, reg_alpha=0, reg_lambda=1.5, subsample=0.8, tree_method=approx; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.3, max_depth=5, n_estimators=250, reg_alpha=0, reg_lambda=1.5, subsample=0.6, tree_method=exact; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=3, n_estimators=150, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=4, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   7.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   7.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.3, max_depth=6, n_estimators=150, reg_alpha=1, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=approx; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   6.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=4, n_estimators=300, reg_alpha=1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=4, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.3, max_depth=6, n_estimators=200, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=exact; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=3, n_estimators=200, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0.5, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.3, max_depth=4, n_estimators=200, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=4, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=approx; total time=   7.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=150, reg_alpha=0, reg_lambda=2, subsample=1.0, tree_method=approx; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=6, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.2, max_depth=5, n_estimators=200, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=hist; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=6, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   6.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=6, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.2, max_depth=6, n_estimators=250, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   6.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=3, n_estimators=200, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=3, n_estimators=200, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=250, reg_alpha=0.5, reg_lambda=1.5, subsample=0.8, tree_method=approx; total time=   5.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.3, max_depth=6, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.3, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=3, n_estimators=100, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=200, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=3, n_estimators=100, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=200, reg_alpha=0, reg_lambda=1.5, subsample=0.8, tree_method=approx; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.3, max_depth=5, n_estimators=250, reg_alpha=0, reg_lambda=1.5, subsample=0.6, tree_method=exact; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=3, n_estimators=150, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=4, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   7.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   7.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.3, max_depth=6, n_estimators=150, reg_alpha=1, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=approx; total time=   8.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   6.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=4, n_estimators=300, reg_alpha=1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=4, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.3, max_depth=6, n_estimators=200, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=exact; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=3, n_estimators=200, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   5.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0.5, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.3, max_depth=4, n_estimators=200, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=4, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=approx; total time=   7.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=150, reg_alpha=0, reg_lambda=2, subsample=1.0, tree_method=approx; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=6, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.2, max_depth=5, n_estimators=200, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=0.5, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=6, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   5.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=6, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, n_estimators=100, reg_alpha=0, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=150, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=hist; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=150, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=hist; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=150, reg_alpha=0, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   7.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=250, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   7.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=4, n_estimators=250, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   6.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.2, max_depth=6, n_estimators=250, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   6.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=3, n_estimators=200, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=250, reg_alpha=0.5, reg_lambda=1.5, subsample=0.8, tree_method=approx; total time=   6.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.3, max_depth=6, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.3, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=3, n_estimators=100, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=200, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=3, n_estimators=100, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=200, reg_alpha=0, reg_lambda=1.5, subsample=0.8, tree_method=approx; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.3, max_depth=5, n_estimators=250, reg_alpha=0, reg_lambda=1.5, subsample=0.6, tree_method=exact; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=3, n_estimators=150, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=4, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   7.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   7.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.3, max_depth=6, n_estimators=150, reg_alpha=1, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=approx; total time=   8.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   6.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=4, n_estimators=300, reg_alpha=1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=4, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.3, max_depth=6, n_estimators=200, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=exact; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=3, n_estimators=200, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0.5, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.3, max_depth=4, n_estimators=200, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=4, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=approx; total time=   7.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=150, reg_alpha=0, reg_lambda=2, subsample=1.0, tree_method=approx; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=6, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   5.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.2, max_depth=5, n_estimators=200, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=hist; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=0.5, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=0.5, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=6, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   5.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=6, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, n_estimators=100, reg_alpha=0, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=150, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=hist; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=150, reg_alpha=0, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   7.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=250, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   7.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=3, n_estimators=300, reg_alpha=1, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=6, n_estimators=250, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.2, max_depth=6, n_estimators=250, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   6.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=250, reg_alpha=0.5, reg_lambda=1.5, subsample=0.8, tree_method=approx; total time=   6.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.3, max_depth=6, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.3, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=3, n_estimators=100, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=200, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=3, n_estimators=100, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=200, reg_alpha=0, reg_lambda=1.5, subsample=0.8, tree_method=approx; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.3, max_depth=5, n_estimators=250, reg_alpha=0, reg_lambda=1.5, subsample=0.6, tree_method=exact; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=3, n_estimators=150, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=4, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   7.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   7.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.3, max_depth=6, n_estimators=150, reg_alpha=1, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=approx; total time=   8.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   6.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=4, n_estimators=300, reg_alpha=1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=4, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.3, max_depth=6, n_estimators=200, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=exact; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=3, n_estimators=200, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0.5, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.3, max_depth=4, n_estimators=200, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=4, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=approx; total time=   7.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=150, reg_alpha=0, reg_lambda=2, subsample=1.0, tree_method=approx; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=6, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.2, max_depth=5, n_estimators=200, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=hist; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=0.5, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=6, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   5.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=6, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, n_estimators=100, reg_alpha=0, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=150, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=hist; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=150, reg_alpha=0, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   7.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=250, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   7.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=3, n_estimators=300, reg_alpha=1, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=6, n_estimators=250, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   4.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=4, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=approx; total time=   7.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=5, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=5, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.2, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=3, n_estimators=150, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=4, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   7.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   7.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.3, max_depth=6, n_estimators=150, reg_alpha=1, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=approx; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   6.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=4, n_estimators=300, reg_alpha=1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=4, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.3, max_depth=6, n_estimators=200, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=exact; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=3, n_estimators=200, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   5.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0.5, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.3, max_depth=4, n_estimators=200, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=4, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=approx; total time=   7.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=150, reg_alpha=0, reg_lambda=2, subsample=1.0, tree_method=approx; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   8.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=6, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.2, max_depth=5, n_estimators=200, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=0.5, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=0.5, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=6, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   5.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=6, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, n_estimators=100, reg_alpha=0, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=150, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=hist; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=150, reg_alpha=0, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   7.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=250, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   7.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=3, n_estimators=300, reg_alpha=1, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=6, n_estimators=250, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=4, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=approx; total time=   7.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=5, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.2, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.3, max_depth=6, n_estimators=250, reg_alpha=1, reg_lambda=1.5, subsample=0.8, tree_method=exact; total time=   4.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   5.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=5, n_estimators=200, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=hist; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=5, n_estimators=200, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=hist; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=3, n_estimators=150, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=4, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   7.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   7.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.3, max_depth=6, n_estimators=150, reg_alpha=1, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=approx; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   6.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=4, n_estimators=300, reg_alpha=1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=4, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.3, max_depth=6, n_estimators=200, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=exact; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=3, n_estimators=200, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0.5, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.3, max_depth=4, n_estimators=200, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=4, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=approx; total time=   7.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=150, reg_alpha=0, reg_lambda=2, subsample=1.0, tree_method=approx; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   8.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=6, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   5.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.2, max_depth=5, n_estimators=200, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=hist; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=0.5, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=6, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   5.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=6, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, n_estimators=100, reg_alpha=0, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=150, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=hist; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=150, reg_alpha=0, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   4.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   7.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=250, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   7.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=3, n_estimators=300, reg_alpha=1, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=6, n_estimators=250, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   4.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=4, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=approx; total time=   7.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=5, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=5, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.2, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.3, max_depth=6, n_estimators=250, reg_alpha=1, reg_lambda=1.5, subsample=0.8, tree_method=exact; total time=   4.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   5.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=5, n_estimators=200, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=hist; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=3, n_estimators=100, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=200, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=3, n_estimators=100, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=200, reg_alpha=0, reg_lambda=1.5, subsample=0.8, tree_method=approx; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.3, max_depth=5, n_estimators=250, reg_alpha=0, reg_lambda=1.5, subsample=0.6, tree_method=exact; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=3, n_estimators=150, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=4, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   7.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   7.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.3, max_depth=6, n_estimators=150, reg_alpha=1, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=approx; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   6.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=4, n_estimators=300, reg_alpha=1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=4, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.3, max_depth=6, n_estimators=200, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=exact; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=3, n_estimators=200, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0.5, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.3, max_depth=4, n_estimators=200, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=4, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=approx; total time=   7.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=150, reg_alpha=0, reg_lambda=2, subsample=1.0, tree_method=approx; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=6, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   5.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.2, max_depth=5, n_estimators=200, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=hist; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=6, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   6.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=6, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, n_estimators=100, reg_alpha=0, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=150, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=hist; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=150, reg_alpha=0, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   7.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=250, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   8.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=3, n_estimators=300, reg_alpha=1, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   8.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=6, n_estimators=250, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=4, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=approx; total time=   7.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.2, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.3, max_depth=6, n_estimators=250, reg_alpha=1, reg_lambda=1.5, subsample=0.8, tree_method=exact; total time=   4.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   6.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=0.1, reg_lambda=1, subsample=1.0, tree_method=exact; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=hist; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   6.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=4, n_estimators=300, reg_alpha=1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=4, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.3, max_depth=6, n_estimators=200, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=exact; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=3, n_estimators=200, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0.5, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.3, max_depth=4, n_estimators=200, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=4, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=approx; total time=   7.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=150, reg_alpha=0, reg_lambda=2, subsample=1.0, tree_method=approx; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   8.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=6, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.2, max_depth=5, n_estimators=200, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=hist; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=0.5, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=6, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   5.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=6, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, n_estimators=100, reg_alpha=0, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=150, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=hist; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=150, reg_alpha=0, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   7.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=250, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   8.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=3, n_estimators=300, reg_alpha=1, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=6, n_estimators=250, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   4.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=4, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=approx; total time=   7.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=5, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.2, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.3, max_depth=6, n_estimators=250, reg_alpha=1, reg_lambda=1.5, subsample=0.8, tree_method=exact; total time=   4.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   5.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=5, n_estimators=200, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=hist; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=0.1, reg_lambda=1, subsample=1.0, tree_method=exact; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=hist; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=6, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   5.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0.5, reg_lambda=2, subsample=0.8, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.3, max_depth=6, n_estimators=200, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=exact; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=3, n_estimators=200, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0.5, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.3, max_depth=4, n_estimators=200, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=4, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=approx; total time=   7.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=150, reg_alpha=0, reg_lambda=2, subsample=1.0, tree_method=approx; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   8.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=6, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.2, max_depth=5, n_estimators=200, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=hist; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=0.5, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=6, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   6.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=6, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, n_estimators=100, reg_alpha=0, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=150, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=hist; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=150, reg_alpha=0, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   7.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=250, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   8.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=3, n_estimators=300, reg_alpha=1, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=6, n_estimators=250, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   4.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=4, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=approx; total time=   7.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.2, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.3, max_depth=6, n_estimators=250, reg_alpha=1, reg_lambda=1.5, subsample=0.8, tree_method=exact; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   5.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=5, n_estimators=200, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=hist; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=0.1, reg_lambda=1, subsample=1.0, tree_method=exact; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=hist; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=6, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   6.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=exact; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=6, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=5, n_estimators=200, reg_alpha=0.5, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   4.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=6, n_estimators=300, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   8.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=1, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=150, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=6, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   5.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.2, max_depth=5, n_estimators=200, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=0.5, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=6, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   5.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=6, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, n_estimators=100, reg_alpha=0, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=150, reg_alpha=0, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   7.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=250, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=3, n_estimators=300, reg_alpha=1, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=6, n_estimators=250, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   4.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=4, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=approx; total time=   7.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=5, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.2, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.3, max_depth=6, n_estimators=250, reg_alpha=1, reg_lambda=1.5, subsample=0.8, tree_method=exact; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   5.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=5, n_estimators=200, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=hist; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=0.1, reg_lambda=1, subsample=1.0, tree_method=exact; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=hist; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=6, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   6.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0.5, reg_lambda=2, subsample=0.8, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=exact; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=6, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=250, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=250, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=5, n_estimators=200, reg_alpha=0.5, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   4.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=6, n_estimators=300, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   8.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=1, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=150, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.3, max_depth=6, n_estimators=150, reg_alpha=0.5, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=5, n_estimators=300, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, n_estimators=100, reg_alpha=0, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=150, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=hist; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=150, reg_alpha=0, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   7.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=250, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   8.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=3, n_estimators=300, reg_alpha=1, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=6, n_estimators=250, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   4.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=4, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=approx; total time=   6.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=5, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.2, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.3, max_depth=6, n_estimators=250, reg_alpha=1, reg_lambda=1.5, subsample=0.8, tree_method=exact; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   5.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=5, n_estimators=200, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=hist; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=0.1, reg_lambda=1, subsample=1.0, tree_method=exact; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=hist; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=6, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   6.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0.5, reg_lambda=2, subsample=0.8, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0.5, reg_lambda=2, subsample=0.8, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=exact; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=6, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=250, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=5, n_estimators=200, reg_alpha=0.5, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   4.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=6, n_estimators=300, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   8.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=1, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=150, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.3, max_depth=6, n_estimators=150, reg_alpha=0.5, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=5, n_estimators=300, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   5.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=150, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=exact; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=approx; total time=   9.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=150, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   5.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=100, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0.5, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=4, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=approx; total time=   7.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=5, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.2, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.3, max_depth=6, n_estimators=250, reg_alpha=1, reg_lambda=1.5, subsample=0.8, tree_method=exact; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   5.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=5, n_estimators=200, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=hist; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=0.1, reg_lambda=1, subsample=1.0, tree_method=exact; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=hist; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=6, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   5.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0.5, reg_lambda=2, subsample=0.8, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0.5, reg_lambda=2, subsample=0.8, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=exact; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=6, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=250, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=250, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=5, n_estimators=200, reg_alpha=0.5, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=6, n_estimators=300, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=1, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=150, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.3, max_depth=6, n_estimators=150, reg_alpha=0.5, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=5, n_estimators=300, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   4.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=150, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=exact; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=approx; total time=   9.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=150, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.2, max_depth=6, n_estimators=100, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.2, max_depth=6, n_estimators=100, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.2, max_depth=6, n_estimators=100, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.3, max_depth=4, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=100, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0.5, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=100, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=approx; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=200, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=exact; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=4, n_estimators=300, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=exact; total time=   4.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=3, n_estimators=300, reg_alpha=1, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=6, n_estimators=250, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=4, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=approx; total time=   7.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=5, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.2, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.3, max_depth=6, n_estimators=250, reg_alpha=1, reg_lambda=1.5, subsample=0.8, tree_method=exact; total time=   4.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   5.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=5, n_estimators=200, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=hist; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=0.1, reg_lambda=1, subsample=1.0, tree_method=exact; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=hist; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=hist; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=6, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   6.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0.5, reg_lambda=2, subsample=0.8, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=exact; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=6, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=5, n_estimators=200, reg_alpha=0.5, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=6, n_estimators=300, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=1, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=1, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=150, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.3, max_depth=6, n_estimators=150, reg_alpha=0.5, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=5, n_estimators=300, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   5.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=150, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=exact; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=approx; total time=   9.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=150, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.3, max_depth=4, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=100, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0.5, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=100, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=approx; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=200, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=exact; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=4, n_estimators=300, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=exact; total time=   4.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   7.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=3, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.3, max_depth=6, n_estimators=250, reg_alpha=1, reg_lambda=1.5, subsample=0.8, tree_method=exact; total time=   4.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   6.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=5, n_estimators=200, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=hist; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=0.1, reg_lambda=1, subsample=1.0, tree_method=exact; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=hist; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=6, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   6.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0.5, reg_lambda=2, subsample=0.8, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=exact; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=6, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=250, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=5, n_estimators=200, reg_alpha=0.5, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   4.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=6, n_estimators=300, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=1, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=150, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.3, max_depth=6, n_estimators=150, reg_alpha=0.5, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=5, n_estimators=300, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=150, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=exact; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=approx; total time=   9.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=150, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.3, max_depth=4, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.3, max_depth=4, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=100, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0.5, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=100, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=approx; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=200, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=exact; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=4, n_estimators=300, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=exact; total time=   4.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   7.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.3, max_depth=6, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   6.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.3, max_depth=5, n_estimators=300, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   9.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=4, n_estimators=150, reg_alpha=1, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=5, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=6, n_estimators=200, reg_alpha=0.5, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   6.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=6, n_estimators=300, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=300, reg_alpha=1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   4.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=0.1, reg_lambda=1, subsample=1.0, tree_method=exact; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=6, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   6.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0.5, reg_lambda=2, subsample=0.8, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=exact; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=6, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=250, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=5, n_estimators=200, reg_alpha=0.5, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   4.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=6, n_estimators=300, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=1, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=150, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.3, max_depth=6, n_estimators=150, reg_alpha=0.5, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=5, n_estimators=300, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   5.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=150, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=exact; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=approx; total time=   9.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=150, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.3, max_depth=4, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=100, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0.5, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=100, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=approx; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=200, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=exact; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=4, n_estimators=300, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=exact; total time=   4.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   7.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=3, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=3, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.3, max_depth=6, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   6.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.3, max_depth=5, n_estimators=300, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   9.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=4, n_estimators=150, reg_alpha=1, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=5, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=6, n_estimators=200, reg_alpha=0.5, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   6.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=6, n_estimators=300, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=4, n_estimators=100, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=4, n_estimators=100, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=300, reg_alpha=1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   8.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=0.1, reg_lambda=1, subsample=1.0, tree_method=exact; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=2, subsample=1.0, tree_method=hist; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=6, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   6.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0.5, reg_lambda=2, subsample=0.8, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=exact; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=6, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=5, n_estimators=200, reg_alpha=0.5, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   4.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=6, n_estimators=300, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=1, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=150, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.3, max_depth=6, n_estimators=150, reg_alpha=0.5, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=5, n_estimators=300, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=150, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=exact; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=approx; total time=   9.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=150, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.3, max_depth=4, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=100, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0.5, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=100, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=approx; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=200, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=exact; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=4, n_estimators=300, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=exact; total time=   4.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   7.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.3, max_depth=6, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   6.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.3, max_depth=5, n_estimators=300, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   9.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=4, n_estimators=150, reg_alpha=1, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=5, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=6, n_estimators=200, reg_alpha=0.5, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   6.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=6, n_estimators=300, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=4, n_estimators=100, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=300, reg_alpha=1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   8.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0.5, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=100, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=exact; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=6, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=4, n_estimators=250, reg_alpha=0.1, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=250, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=250, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=5, n_estimators=200, reg_alpha=0.5, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=6, n_estimators=300, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   8.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=150, reg_alpha=1, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=150, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.3, max_depth=6, n_estimators=150, reg_alpha=0.5, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=5, n_estimators=300, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=150, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=exact; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=approx; total time=   9.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=150, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.2, max_depth=6, n_estimators=100, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.2, max_depth=6, n_estimators=100, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.3, max_depth=4, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.3, max_depth=4, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=100, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0.5, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=100, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=approx; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=200, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=exact; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=4, n_estimators=300, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=exact; total time=   4.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   7.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.3, max_depth=6, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   6.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.3, max_depth=5, n_estimators=300, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   9.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=4, n_estimators=150, reg_alpha=1, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=5, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=6, n_estimators=200, reg_alpha=0.5, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   6.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=6, n_estimators=300, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=300, reg_alpha=1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   8.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0.5, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=100, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.3, max_depth=4, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=0.5, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, reg_alpha=1, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   6.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=6, n_estimators=150, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   6.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=150, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=exact; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=exact; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=100, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=6, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=250, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=5, n_estimators=200, reg_alpha=0.5, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   4.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=6, n_estimators=300, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=150, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.3, max_depth=6, n_estimators=150, reg_alpha=0.5, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=5, n_estimators=300, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   5.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=150, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=exact; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=approx; total time=   9.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=150, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.3, max_depth=4, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=100, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0.5, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=100, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=approx; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=200, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=exact; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=4, n_estimators=300, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=exact; total time=   4.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   7.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=3, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.3, max_depth=6, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   6.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.3, max_depth=5, n_estimators=300, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   9.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=4, n_estimators=150, reg_alpha=1, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=5, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=6, n_estimators=200, reg_alpha=0.5, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   6.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=6, n_estimators=300, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=300, reg_alpha=1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0.5, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.3, max_depth=4, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=0.5, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, reg_alpha=1, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   6.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=6, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=1.0, tree_method=hist; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.3, max_depth=6, n_estimators=150, reg_alpha=0.5, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=5, n_estimators=300, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=exact; total time=   4.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=1.0, tree_method=exact; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=150, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=exact; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=approx; total time=   9.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=150, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.2, max_depth=6, n_estimators=100, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.2, max_depth=6, n_estimators=100, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.2, max_depth=6, n_estimators=100, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.2, max_depth=6, n_estimators=100, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=100, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0.5, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=100, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=approx; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=200, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=exact; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=4, n_estimators=300, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=exact; total time=   4.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   7.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=3, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=3, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.3, max_depth=6, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   6.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.3, max_depth=5, n_estimators=300, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   9.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=4, n_estimators=150, reg_alpha=1, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=5, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=6, n_estimators=200, reg_alpha=0.5, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   6.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=6, n_estimators=300, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=4, n_estimators=100, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=4, n_estimators=100, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=300, reg_alpha=1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   8.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0.5, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=100, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.3, max_depth=4, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=0.5, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, reg_alpha=1, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   6.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=6, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=1.0, tree_method=hist; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=4, n_estimators=250, reg_alpha=0.5, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   7.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.3, max_depth=6, n_estimators=200, reg_alpha=0.5, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   6.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.2, max_depth=3, n_estimators=200, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=approx; total time=   5.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=150, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=exact; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=300, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=approx; total time=   9.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=150, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.2, max_depth=6, n_estimators=100, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.3, max_depth=4, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=100, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0.5, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=100, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=approx; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=200, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=exact; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=4, n_estimators=300, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=exact; total time=   4.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   7.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=3, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.3, max_depth=6, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   6.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.3, max_depth=5, n_estimators=300, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   9.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=4, n_estimators=150, reg_alpha=1, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=5, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=6, n_estimators=200, reg_alpha=0.5, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   6.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=6, n_estimators=300, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=4, n_estimators=100, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=300, reg_alpha=1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   8.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0.5, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=100, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=100, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.3, max_depth=4, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=0.5, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, reg_alpha=1, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   6.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=6, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=1.0, tree_method=hist; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=4, n_estimators=250, reg_alpha=0.5, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   6.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.3, max_depth=6, n_estimators=200, reg_alpha=0.5, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   6.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.2, max_depth=3, n_estimators=200, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=approx; total time=   5.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=200, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=200, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=exact; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=0.1, reg_lambda=1, subsample=1.0, tree_method=exact; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=150, reg_alpha=0, reg_lambda=1.5, subsample=0.8, tree_method=exact; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, n_estimators=150, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=100, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=approx; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=200, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=exact; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=4, n_estimators=300, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=exact; total time=   4.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   7.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.3, max_depth=6, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   6.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.3, max_depth=5, n_estimators=300, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   9.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=4, n_estimators=150, reg_alpha=1, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=5, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=6, n_estimators=200, reg_alpha=0.5, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   6.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=6, n_estimators=300, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=4, n_estimators=100, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=4, n_estimators=100, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=300, reg_alpha=1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   8.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0.5, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.3, max_depth=4, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=0.5, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, reg_alpha=1, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   6.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=6, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=1.0, tree_method=hist; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=4, n_estimators=250, reg_alpha=0.5, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   7.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.3, max_depth=6, n_estimators=200, reg_alpha=0.5, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   6.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.2, max_depth=3, n_estimators=200, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=approx; total time=   5.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=200, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=exact; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=0.1, reg_lambda=1, subsample=1.0, tree_method=exact; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=150, reg_alpha=0, reg_lambda=1.5, subsample=0.8, tree_method=exact; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, n_estimators=150, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=150, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=4, n_estimators=150, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=150, reg_alpha=0.5, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.3, max_depth=4, n_estimators=200, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   5.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=250, reg_alpha=0.5, reg_lambda=1.5, subsample=0.8, tree_method=exact; total time=   5.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=4, n_estimators=200, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=exact; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.3, max_depth=6, n_estimators=100, reg_alpha=0, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   9.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   7.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=3, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=3, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.3, max_depth=6, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   6.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.3, max_depth=5, n_estimators=300, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   9.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=4, n_estimators=150, reg_alpha=1, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=5, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=6, n_estimators=200, reg_alpha=0.5, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   6.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=6, n_estimators=300, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=4, n_estimators=100, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=300, reg_alpha=1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0.5, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=100, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=100, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.3, max_depth=4, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=0.5, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, reg_alpha=1, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   6.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=6, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=1.0, tree_method=hist; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=1.0, tree_method=hist; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=4, n_estimators=250, reg_alpha=0.5, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   6.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.3, max_depth=6, n_estimators=200, reg_alpha=0.5, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   6.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.2, max_depth=3, n_estimators=200, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=approx; total time=   5.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=200, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=200, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=exact; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=0.1, reg_lambda=1, subsample=1.0, tree_method=exact; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=150, reg_alpha=0, reg_lambda=1.5, subsample=0.8, tree_method=exact; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, n_estimators=150, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=150, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=4, n_estimators=150, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.3, max_depth=4, n_estimators=200, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   5.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=250, reg_alpha=0.5, reg_lambda=1.5, subsample=0.8, tree_method=exact; total time=   5.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=4, n_estimators=200, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=exact; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.3, max_depth=6, n_estimators=100, reg_alpha=0, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   9.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=3, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.3, max_depth=6, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=0.8, tree_method=hist; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   6.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.3, max_depth=5, n_estimators=300, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   9.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=4, n_estimators=150, reg_alpha=1, reg_lambda=2, subsample=0.6, tree_method=approx; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=5, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=6, n_estimators=200, reg_alpha=0.5, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   6.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=6, n_estimators=300, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=4, n_estimators=100, reg_alpha=0.5, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=300, reg_alpha=1, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=150, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0.5, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=100, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=4, n_estimators=100, reg_alpha=1, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.3, max_depth=4, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=0.5, reg_lambda=1, subsample=0.6, tree_method=hist; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, reg_alpha=1, reg_lambda=1, subsample=0.6, tree_method=approx; total time=   6.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=6, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, reg_alpha=1, reg_lambda=2, subsample=1.0, tree_method=hist; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=4, n_estimators=250, reg_alpha=0.5, reg_lambda=1.5, subsample=1.0, tree_method=approx; total time=   7.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=1, subsample=0.6, tree_method=exact; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.2, max_depth=4, n_estimators=300, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=hist; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.3, max_depth=6, n_estimators=200, reg_alpha=0.5, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   6.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.2, max_depth=3, n_estimators=200, reg_alpha=0.5, reg_lambda=2, subsample=1.0, tree_method=approx; total time=   5.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=4, n_estimators=200, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1.5, subsample=0.6, tree_method=exact; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=0.1, reg_lambda=1, subsample=1.0, tree_method=exact; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=150, reg_alpha=0, reg_lambda=1.5, subsample=0.8, tree_method=exact; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, n_estimators=150, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=150, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, reg_alpha=0, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=3, n_estimators=250, reg_alpha=1, reg_lambda=1, subsample=1.0, tree_method=hist; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=4, n_estimators=150, reg_alpha=0.1, reg_lambda=2, subsample=0.6, tree_method=exact; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=150, reg_alpha=0.5, reg_lambda=1, subsample=0.8, tree_method=hist; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.3, max_depth=4, n_estimators=200, reg_alpha=0, reg_lambda=2, subsample=0.8, tree_method=approx; total time=   5.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=250, reg_alpha=0.5, reg_lambda=1.5, subsample=0.8, tree_method=exact; total time=   5.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=4, n_estimators=200, reg_alpha=0.5, reg_lambda=1, subsample=1.0, tree_method=exact; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.3, max_depth=6, n_estimators=100, reg_alpha=0, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=300, reg_alpha=0.1, reg_lambda=1.5, subsample=0.6, tree_method=approx; total time=   9.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, reg_alpha=0.1, reg_lambda=2, subsample=0.8, tree_method=exact; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, reg_alpha=0.5, reg_lambda=2, subsample=0.6, tree_method=hist; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=250, reg_alpha=0, reg_lambda=1, subsample=0.8, tree_method=approx; total time=   7.2s\n",
      "Melhores hiperparâmetros: {'tree_method': 'approx', 'subsample': 0.6, 'reg_lambda': 1.5, 'reg_alpha': 0.1, 'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 1.0}\n",
      "Melhor acurácia: 0.5993749349913899\n"
     ]
    }
   ],
   "source": [
    "# Instanciando o modelo XGBoost\n",
    "xgb_model = XGBClassifier(eval_metric='logloss', objective='binary:logistic', random_state=42)\n",
    "\n",
    "# Definindo o grid de hiperparâmetros\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150,200, 250,300],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3],\n",
    "    'reg_alpha': [0, 0.1, 0.5, 1],\n",
    "    'reg_lambda': [1, 1.5, 2],\n",
    "    'tree_method':['hist', 'approx', 'exact'],\n",
    "}\n",
    "\n",
    "# Configurando o RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter= 150,  # Número de combinações aleatórias para testar\n",
    "    scoring='accuracy',  # Métrica para avaliar os modelos\n",
    "    n_jobs=10,  # Utiliza todos os processadores disponíveis\n",
    "    cv=10,  # Validação cruzada\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Ajustando o modelo aos dados\n",
    "random_search.fit(X_train_norma, y_train)\n",
    "\n",
    "# Exibindo os melhores hiperparâmetros encontrados\n",
    "print(f\"Melhores hiperparâmetros: {random_search.best_params_}\")\n",
    "print(f\"Melhor acurácia: {random_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ecd8f5-64cf-4957-ba6c-48589009808e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a631ff28-bbd3-4b70-98d1-0aca90ea3792",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8272f110-f233-4a43-ae21-9a91c0bc1164",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 150 candidates, totalling 1500 fits\n",
      "[CV] END ..criterion=entropy, max_depth=12, n_estimators=120; total time=   3.9s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=130; total time=   5.1s\n",
      "[CV] END .....criterion=gini, max_depth=10, n_estimators=190; total time=   5.0s\n",
      "[CV] END .....criterion=gini, max_depth=18, n_estimators=100; total time=   4.6s\n",
      "[CV] END ..criterion=entropy, max_depth=18, n_estimators=160; total time=   8.0s\n",
      "[CV] END ....criterion=entropy, max_depth=6, n_estimators=90; total time=   1.7s\n",
      "[CV] END ......criterion=gini, max_depth=10, n_estimators=90; total time=   2.6s\n",
      "[CV] END ..criterion=entropy, max_depth=10, n_estimators=110; total time=   3.1s\n",
      "[CV] END ......criterion=gini, max_depth=10, n_estimators=40; total time=   1.2s\n",
      "[CV] END ...criterion=entropy, max_depth=8, n_estimators=150; total time=   3.6s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=100; total time=   1.7s\n",
      "[CV] END ......criterion=gini, max_depth=12, n_estimators=30; total time=   1.0s\n",
      "[CV] END ...criterion=entropy, max_depth=4, n_estimators=130; total time=   1.5s\n",
      "[CV] END ......criterion=gini, max_depth=6, n_estimators=140; total time=   2.3s\n",
      "[CV] END ......criterion=gini, max_depth=12, n_estimators=50; total time=   1.9s\n",
      "[CV] END ...criterion=gini, max_depth=None, n_estimators=180; total time=  10.0s\n",
      "[CV] END .......criterion=gini, max_depth=4, n_estimators=10; total time=   0.1s\n",
      "[CV] END .......criterion=gini, max_depth=4, n_estimators=10; total time=   0.1s\n",
      "[CV] END .......criterion=gini, max_depth=4, n_estimators=10; total time=   0.1s\n",
      "[CV] END .......criterion=gini, max_depth=4, n_estimators=10; total time=   0.1s\n",
      "[CV] END ......criterion=gini, max_depth=4, n_estimators=120; total time=   1.3s\n",
      "[CV] END .criterion=log_loss, max_depth=14, n_estimators=130; total time=   5.3s\n",
      "[CV] END .......criterion=gini, max_depth=6, n_estimators=30; total time=   0.5s\n",
      "[CV] END .......criterion=gini, max_depth=6, n_estimators=30; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=170; total time=  10.2s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=110; total time=   3.4s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=100; total time=   3.2s\n",
      "[CV] END .....criterion=gini, max_depth=18, n_estimators=140; total time=   6.0s\n",
      "[CV] END ..criterion=entropy, max_depth=12, n_estimators=180; total time=   6.1s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=180; total time=   7.1s\n",
      "[CV] END ..criterion=log_loss, max_depth=4, n_estimators=170; total time=   1.7s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=120; total time=   4.6s\n",
      "[CV] END .criterion=log_loss, max_depth=10, n_estimators=100; total time=   2.6s\n",
      "[CV] END ......criterion=gini, max_depth=4, n_estimators=190; total time=   1.8s\n",
      "[CV] END ...criterion=entropy, max_depth=14, n_estimators=10; total time=   0.3s\n",
      "[CV] END ...criterion=entropy, max_depth=14, n_estimators=10; total time=   0.3s\n",
      "[CV] END ..criterion=log_loss, max_depth=12, n_estimators=90; total time=   2.9s\n",
      "[CV] END ....criterion=gini, max_depth=None, n_estimators=80; total time=   3.6s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=110; total time=   3.3s\n",
      "[CV] END .....criterion=gini, max_depth=18, n_estimators=180; total time=   7.3s\n",
      "[CV] END ...criterion=entropy, max_depth=4, n_estimators=210; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=290; total time=  14.7s\n",
      "[CV] END criterion=log_loss, max_depth=None, n_estimators=170; total time=   9.1s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=190; total time=   6.8s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=270; total time=   3.9s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=200; total time=   2.8s\n",
      "[CV] END ..criterion=log_loss, max_depth=4, n_estimators=300; total time=   2.7s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=70; total time=   1.3s\n",
      "[CV] END .....criterion=gini, max_depth=18, n_estimators=220; total time=   8.6s\n",
      "[CV] END ..criterion=entropy, max_depth=14, n_estimators=210; total time=   7.5s\n",
      "[CV] END criterion=log_loss, max_depth=None, n_estimators=270; total time=  14.5s\n",
      "[CV] END ...criterion=gini, max_depth=None, n_estimators=200; total time=   8.9s\n",
      "[CV] END ...criterion=entropy, max_depth=14, n_estimators=70; total time=   2.5s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=150; total time=   2.2s\n",
      "[CV] END .....criterion=gini, max_depth=10, n_estimators=200; total time=   4.9s\n",
      "[CV] END ..criterion=entropy, max_depth=10, n_estimators=240; total time=   6.4s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=220; total time=  12.3s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=200; total time=   6.2s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=80; total time=   1.7s\n",
      "[CV] END ...criterion=entropy, max_depth=8, n_estimators=230; total time=   5.4s\n",
      "[CV] END ...criterion=entropy, max_depth=8, n_estimators=270; total time=   5.8s\n",
      "[CV] END ......criterion=gini, max_depth=6, n_estimators=100; total time=   1.5s\n",
      "[CV] END ..criterion=log_loss, max_depth=16, n_estimators=90; total time=   4.1s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=290; total time=  11.7s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=300; total time=  12.1s\n",
      "[CV] END ......criterion=gini, max_depth=8, n_estimators=190; total time=   3.9s\n",
      "[CV] END .criterion=log_loss, max_depth=10, n_estimators=280; total time=   7.6s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=210; total time=   6.8s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=120; total time=   3.7s\n",
      "[CV] END ..criterion=log_loss, max_depth=16, n_estimators=50; total time=   2.0s\n",
      "[CV] END .criterion=log_loss, max_depth=14, n_estimators=150; total time=   5.5s\n",
      "[CV] END ......criterion=gini, max_depth=4, n_estimators=240; total time=   2.3s\n",
      "[CV] END ...criterion=entropy, max_depth=8, n_estimators=220; total time=   4.7s\n",
      "[CV] END ...criterion=entropy, max_depth=12, n_estimators=70; total time=   2.1s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=40; total time=   0.8s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=130; total time=   5.0s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=60; total time=   1.3s\n",
      "[CV] END .criterion=entropy, max_depth=None, n_estimators=50; total time=   3.0s\n",
      "[CV] END ...criterion=entropy, max_depth=4, n_estimators=250; total time=   2.6s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=180; total time=   5.4s\n",
      "[CV] END ..criterion=log_loss, max_depth=10, n_estimators=40; total time=   1.0s\n",
      "[CV] END ......criterion=gini, max_depth=18, n_estimators=20; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=210; total time=  11.5s\n",
      "[CV] END ..criterion=log_loss, max_depth=14, n_estimators=70; total time=   2.8s\n",
      "[CV] END ...criterion=log_loss, max_depth=4, n_estimators=30; total time=   0.3s\n",
      "[CV] END ...criterion=log_loss, max_depth=6, n_estimators=10; total time=   0.2s\n",
      "[CV] END ....criterion=entropy, max_depth=8, n_estimators=70; total time=   1.5s\n",
      "[CV] END ..criterion=log_loss, max_depth=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=220; total time=   3.5s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=140; total time=   4.6s\n",
      "[CV] END ..criterion=entropy, max_depth=12, n_estimators=160; total time=   5.2s\n",
      "[CV] END ..criterion=log_loss, max_depth=4, n_estimators=100; total time=   1.0s\n",
      "[CV] END ......criterion=gini, max_depth=8, n_estimators=270; total time=   5.3s\n",
      "[CV] END ...criterion=entropy, max_depth=18, n_estimators=80; total time=   3.8s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=100; total time=   1.5s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=280; total time=   4.3s\n",
      "[CV] END ...criterion=log_loss, max_depth=8, n_estimators=60; total time=   1.2s\n",
      "[CV] END ......criterion=gini, max_depth=12, n_estimators=10; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=14, n_estimators=250; total time=   8.5s\n",
      "[CV] END .criterion=log_loss, max_depth=16, n_estimators=220; total time=   9.2s\n",
      "[CV] END .....criterion=gini, max_depth=14, n_estimators=190; total time=   6.7s\n",
      "[CV] END ....criterion=entropy, max_depth=6, n_estimators=90; total time=   1.7s\n",
      "[CV] END ......criterion=gini, max_depth=10, n_estimators=90; total time=   2.6s\n",
      "[CV] END ..criterion=entropy, max_depth=10, n_estimators=110; total time=   3.3s\n",
      "[CV] END ......criterion=gini, max_depth=10, n_estimators=40; total time=   1.1s\n",
      "[CV] END ...criterion=entropy, max_depth=8, n_estimators=150; total time=   3.6s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=100; total time=   1.8s\n",
      "[CV] END ......criterion=gini, max_depth=12, n_estimators=30; total time=   1.0s\n",
      "[CV] END ...criterion=entropy, max_depth=4, n_estimators=130; total time=   1.6s\n",
      "[CV] END ......criterion=gini, max_depth=6, n_estimators=140; total time=   2.5s\n",
      "[CV] END ......criterion=gini, max_depth=12, n_estimators=50; total time=   1.8s\n",
      "[CV] END ...criterion=gini, max_depth=None, n_estimators=180; total time=   9.7s\n",
      "[CV] END ......criterion=gini, max_depth=4, n_estimators=120; total time=   1.4s\n",
      "[CV] END .criterion=log_loss, max_depth=14, n_estimators=130; total time=   5.6s\n",
      "[CV] END .......criterion=gini, max_depth=6, n_estimators=30; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=170; total time=   9.9s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=110; total time=   3.5s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=100; total time=   3.1s\n",
      "[CV] END .....criterion=gini, max_depth=18, n_estimators=140; total time=   6.1s\n",
      "[CV] END ..criterion=entropy, max_depth=12, n_estimators=180; total time=   6.0s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=180; total time=   7.2s\n",
      "[CV] END ..criterion=log_loss, max_depth=4, n_estimators=170; total time=   1.8s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=120; total time=   4.7s\n",
      "[CV] END .criterion=log_loss, max_depth=10, n_estimators=100; total time=   2.7s\n",
      "[CV] END ......criterion=gini, max_depth=4, n_estimators=190; total time=   1.9s\n",
      "[CV] END ...criterion=entropy, max_depth=14, n_estimators=10; total time=   0.4s\n",
      "[CV] END ..criterion=log_loss, max_depth=12, n_estimators=90; total time=   3.0s\n",
      "[CV] END ....criterion=gini, max_depth=None, n_estimators=80; total time=   3.6s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=110; total time=   3.2s\n",
      "[CV] END .....criterion=gini, max_depth=18, n_estimators=180; total time=   7.1s\n",
      "[CV] END ...criterion=entropy, max_depth=4, n_estimators=210; total time=   2.1s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=290; total time=  15.0s\n",
      "[CV] END criterion=log_loss, max_depth=None, n_estimators=170; total time=   9.0s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=190; total time=   6.8s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=270; total time=   3.9s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=200; total time=   2.8s\n",
      "[CV] END ..criterion=log_loss, max_depth=4, n_estimators=300; total time=   2.9s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=70; total time=   1.3s\n",
      "[CV] END .....criterion=gini, max_depth=18, n_estimators=220; total time=   8.6s\n",
      "[CV] END ..criterion=entropy, max_depth=14, n_estimators=210; total time=   7.3s\n",
      "[CV] END criterion=log_loss, max_depth=None, n_estimators=270; total time=  13.9s\n",
      "[CV] END ...criterion=gini, max_depth=None, n_estimators=200; total time=   9.0s\n",
      "[CV] END ...criterion=entropy, max_depth=14, n_estimators=70; total time=   2.4s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=150; total time=   2.2s\n",
      "[CV] END .....criterion=gini, max_depth=10, n_estimators=200; total time=   5.0s\n",
      "[CV] END ..criterion=entropy, max_depth=10, n_estimators=240; total time=   6.3s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=220; total time=  12.3s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=200; total time=   6.1s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=80; total time=   1.6s\n",
      "[CV] END ...criterion=entropy, max_depth=8, n_estimators=230; total time=   5.0s\n",
      "[CV] END ...criterion=entropy, max_depth=8, n_estimators=270; total time=   5.9s\n",
      "[CV] END ......criterion=gini, max_depth=6, n_estimators=100; total time=   1.6s\n",
      "[CV] END .......criterion=gini, max_depth=6, n_estimators=10; total time=   0.1s\n",
      "[CV] END .......criterion=gini, max_depth=6, n_estimators=10; total time=   0.1s\n",
      "[CV] END .......criterion=gini, max_depth=6, n_estimators=10; total time=   0.2s\n",
      "[CV] END .......criterion=gini, max_depth=6, n_estimators=10; total time=   0.2s\n",
      "[CV] END ..criterion=log_loss, max_depth=16, n_estimators=90; total time=   3.9s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=290; total time=  11.6s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=300; total time=  12.0s\n",
      "[CV] END ......criterion=gini, max_depth=8, n_estimators=190; total time=   3.9s\n",
      "[CV] END .criterion=log_loss, max_depth=10, n_estimators=280; total time=   7.4s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=210; total time=   6.8s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=120; total time=   3.9s\n",
      "[CV] END ..criterion=log_loss, max_depth=16, n_estimators=50; total time=   2.1s\n",
      "[CV] END .criterion=log_loss, max_depth=14, n_estimators=150; total time=   5.9s\n",
      "[CV] END ......criterion=gini, max_depth=4, n_estimators=240; total time=   2.4s\n",
      "[CV] END ...criterion=entropy, max_depth=8, n_estimators=220; total time=   4.7s\n",
      "[CV] END ...criterion=entropy, max_depth=12, n_estimators=70; total time=   2.3s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=40; total time=   0.8s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=130; total time=   4.8s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=60; total time=   1.2s\n",
      "[CV] END .criterion=entropy, max_depth=None, n_estimators=50; total time=   2.8s\n",
      "[CV] END ...criterion=entropy, max_depth=4, n_estimators=250; total time=   2.5s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=180; total time=   5.2s\n",
      "[CV] END ..criterion=log_loss, max_depth=10, n_estimators=40; total time=   1.1s\n",
      "[CV] END ..criterion=log_loss, max_depth=10, n_estimators=40; total time=   1.0s\n",
      "[CV] END ......criterion=gini, max_depth=18, n_estimators=20; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=210; total time=  11.4s\n",
      "[CV] END ..criterion=log_loss, max_depth=14, n_estimators=70; total time=   2.5s\n",
      "[CV] END ...criterion=log_loss, max_depth=6, n_estimators=10; total time=   0.2s\n",
      "[CV] END ...criterion=log_loss, max_depth=6, n_estimators=10; total time=   0.2s\n",
      "[CV] END ....criterion=entropy, max_depth=8, n_estimators=70; total time=   1.5s\n",
      "[CV] END ..criterion=log_loss, max_depth=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=220; total time=   3.3s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=140; total time=   4.2s\n",
      "[CV] END ....criterion=entropy, max_depth=6, n_estimators=30; total time=   0.5s\n",
      "[CV] END ..criterion=entropy, max_depth=12, n_estimators=160; total time=   4.9s\n",
      "[CV] END ..criterion=log_loss, max_depth=4, n_estimators=100; total time=   1.0s\n",
      "[CV] END ......criterion=gini, max_depth=8, n_estimators=270; total time=   5.4s\n",
      "[CV] END ...criterion=entropy, max_depth=18, n_estimators=80; total time=   3.8s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=100; total time=   1.5s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=280; total time=   4.4s\n",
      "[CV] END ...criterion=log_loss, max_depth=8, n_estimators=60; total time=   1.3s\n",
      "[CV] END .....criterion=gini, max_depth=14, n_estimators=250; total time=   8.6s\n",
      "[CV] END .criterion=log_loss, max_depth=16, n_estimators=220; total time=   9.1s\n",
      "[CV] END .....criterion=gini, max_depth=14, n_estimators=190; total time=   6.8s\n",
      "[CV] END ...criterion=entropy, max_depth=4, n_estimators=160; total time=   1.6s\n",
      "[CV] END ......criterion=gini, max_depth=6, n_estimators=200; total time=   3.1s\n",
      "[CV] END ......criterion=gini, max_depth=10, n_estimators=70; total time=   1.8s\n",
      "[CV] END ......criterion=gini, max_depth=14, n_estimators=60; total time=   2.1s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=100; total time=   3.3s\n",
      "[CV] END ..criterion=entropy, max_depth=18, n_estimators=150; total time=   6.7s\n",
      "[CV] END ......criterion=gini, max_depth=10, n_estimators=90; total time=   2.7s\n",
      "[CV] END ..criterion=entropy, max_depth=10, n_estimators=110; total time=   3.1s\n",
      "[CV] END ......criterion=gini, max_depth=10, n_estimators=40; total time=   1.1s\n",
      "[CV] END ...criterion=entropy, max_depth=8, n_estimators=150; total time=   3.7s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=100; total time=   1.8s\n",
      "[CV] END ......criterion=gini, max_depth=12, n_estimators=30; total time=   1.0s\n",
      "[CV] END ...criterion=entropy, max_depth=4, n_estimators=130; total time=   1.6s\n",
      "[CV] END ......criterion=gini, max_depth=6, n_estimators=140; total time=   2.5s\n",
      "[CV] END ......criterion=gini, max_depth=12, n_estimators=50; total time=   1.8s\n",
      "[CV] END ...criterion=gini, max_depth=None, n_estimators=180; total time=   9.9s\n",
      "[CV] END ......criterion=gini, max_depth=4, n_estimators=120; total time=   1.3s\n",
      "[CV] END .criterion=log_loss, max_depth=14, n_estimators=130; total time=   5.6s\n",
      "[CV] END .......criterion=gini, max_depth=6, n_estimators=30; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=170; total time=  10.2s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=110; total time=   3.2s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=100; total time=   3.0s\n",
      "[CV] END .....criterion=gini, max_depth=18, n_estimators=140; total time=   6.1s\n",
      "[CV] END ..criterion=entropy, max_depth=12, n_estimators=180; total time=   6.1s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=180; total time=   7.2s\n",
      "[CV] END ..criterion=log_loss, max_depth=4, n_estimators=170; total time=   1.8s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=120; total time=   4.4s\n",
      "[CV] END .criterion=log_loss, max_depth=10, n_estimators=100; total time=   2.7s\n",
      "[CV] END ......criterion=gini, max_depth=4, n_estimators=190; total time=   1.9s\n",
      "[CV] END ...criterion=entropy, max_depth=14, n_estimators=10; total time=   0.3s\n",
      "[CV] END ...criterion=entropy, max_depth=14, n_estimators=10; total time=   0.4s\n",
      "[CV] END ...criterion=entropy, max_depth=14, n_estimators=10; total time=   0.4s\n",
      "[CV] END ..criterion=log_loss, max_depth=12, n_estimators=90; total time=   2.9s\n",
      "[CV] END ....criterion=gini, max_depth=None, n_estimators=80; total time=   3.7s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=110; total time=   3.3s\n",
      "[CV] END .....criterion=gini, max_depth=18, n_estimators=180; total time=   7.2s\n",
      "[CV] END ...criterion=entropy, max_depth=4, n_estimators=210; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=290; total time=  14.8s\n",
      "[CV] END criterion=log_loss, max_depth=None, n_estimators=170; total time=   9.0s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=190; total time=   6.9s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=270; total time=   4.0s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=200; total time=   2.8s\n",
      "[CV] END ..criterion=log_loss, max_depth=4, n_estimators=300; total time=   2.9s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=70; total time=   1.3s\n",
      "[CV] END .....criterion=gini, max_depth=18, n_estimators=220; total time=   8.6s\n",
      "[CV] END ..criterion=entropy, max_depth=14, n_estimators=210; total time=   7.3s\n",
      "[CV] END criterion=log_loss, max_depth=None, n_estimators=270; total time=  14.2s\n",
      "[CV] END ...criterion=gini, max_depth=None, n_estimators=200; total time=   9.0s\n",
      "[CV] END ...criterion=entropy, max_depth=14, n_estimators=70; total time=   2.5s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=150; total time=   2.2s\n",
      "[CV] END .....criterion=gini, max_depth=10, n_estimators=200; total time=   5.0s\n",
      "[CV] END ..criterion=entropy, max_depth=10, n_estimators=240; total time=   6.3s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=220; total time=  12.4s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=200; total time=   6.1s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=80; total time=   1.6s\n",
      "[CV] END ...criterion=entropy, max_depth=8, n_estimators=230; total time=   5.0s\n",
      "[CV] END ...criterion=entropy, max_depth=8, n_estimators=270; total time=   5.7s\n",
      "[CV] END ......criterion=gini, max_depth=6, n_estimators=100; total time=   1.5s\n",
      "[CV] END ..criterion=log_loss, max_depth=16, n_estimators=90; total time=   3.9s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=290; total time=  11.5s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=300; total time=  12.0s\n",
      "[CV] END ......criterion=gini, max_depth=8, n_estimators=190; total time=   3.7s\n",
      "[CV] END .criterion=log_loss, max_depth=10, n_estimators=280; total time=   7.6s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=210; total time=   6.8s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=120; total time=   4.1s\n",
      "[CV] END ..criterion=log_loss, max_depth=16, n_estimators=50; total time=   2.2s\n",
      "[CV] END .criterion=log_loss, max_depth=14, n_estimators=150; total time=   5.7s\n",
      "[CV] END ......criterion=gini, max_depth=4, n_estimators=240; total time=   2.5s\n",
      "[CV] END ...criterion=entropy, max_depth=8, n_estimators=220; total time=   4.7s\n",
      "[CV] END ...criterion=entropy, max_depth=12, n_estimators=70; total time=   2.2s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=40; total time=   0.8s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=130; total time=   4.8s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=60; total time=   1.2s\n",
      "[CV] END .criterion=entropy, max_depth=None, n_estimators=50; total time=   2.7s\n",
      "[CV] END ...criterion=entropy, max_depth=4, n_estimators=250; total time=   2.6s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=180; total time=   5.4s\n",
      "[CV] END ..criterion=log_loss, max_depth=10, n_estimators=40; total time=   1.0s\n",
      "[CV] END ......criterion=gini, max_depth=18, n_estimators=20; total time=   0.9s\n",
      "[CV] END ......criterion=gini, max_depth=18, n_estimators=20; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=210; total time=  11.5s\n",
      "[CV] END ..criterion=log_loss, max_depth=14, n_estimators=70; total time=   2.6s\n",
      "[CV] END ...criterion=log_loss, max_depth=6, n_estimators=10; total time=   0.2s\n",
      "[CV] END ....criterion=entropy, max_depth=8, n_estimators=70; total time=   1.4s\n",
      "[CV] END ..criterion=log_loss, max_depth=10, n_estimators=20; total time=   0.6s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=220; total time=   3.4s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=140; total time=   4.6s\n",
      "[CV] END ....criterion=entropy, max_depth=6, n_estimators=30; total time=   0.5s\n",
      "[CV] END ..criterion=entropy, max_depth=12, n_estimators=160; total time=   4.8s\n",
      "[CV] END ..criterion=log_loss, max_depth=4, n_estimators=100; total time=   1.0s\n",
      "[CV] END ......criterion=gini, max_depth=8, n_estimators=270; total time=   5.4s\n",
      "[CV] END ...criterion=entropy, max_depth=18, n_estimators=80; total time=   3.5s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=100; total time=   1.5s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=280; total time=   4.3s\n",
      "[CV] END ...criterion=log_loss, max_depth=8, n_estimators=60; total time=   1.3s\n",
      "[CV] END ......criterion=gini, max_depth=12, n_estimators=10; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=14, n_estimators=250; total time=   8.4s\n",
      "[CV] END .criterion=log_loss, max_depth=16, n_estimators=220; total time=   9.3s\n",
      "[CV] END .....criterion=gini, max_depth=14, n_estimators=190; total time=   6.7s\n",
      "[CV] END ...criterion=entropy, max_depth=4, n_estimators=160; total time=   1.7s\n",
      "[CV] END ......criterion=gini, max_depth=6, n_estimators=200; total time=   2.9s\n",
      "[CV] END ......criterion=gini, max_depth=10, n_estimators=70; total time=   1.8s\n",
      "[CV] END ......criterion=gini, max_depth=14, n_estimators=60; total time=   2.0s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=100; total time=   3.1s\n",
      "[CV] END ..criterion=entropy, max_depth=18, n_estimators=150; total time=   7.1s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=250; total time=   3.9s\n",
      "[CV] END criterion=log_loss, max_depth=None, n_estimators=260; total time=  14.9s\n",
      "[CV] END .......criterion=gini, max_depth=6, n_estimators=40; total time=   0.7s\n",
      "[CV] END ......criterion=gini, max_depth=10, n_estimators=40; total time=   1.2s\n",
      "[CV] END ...criterion=entropy, max_depth=8, n_estimators=150; total time=   3.7s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=100; total time=   1.7s\n",
      "[CV] END ......criterion=gini, max_depth=12, n_estimators=30; total time=   1.1s\n",
      "[CV] END ...criterion=entropy, max_depth=4, n_estimators=130; total time=   1.5s\n",
      "[CV] END ......criterion=gini, max_depth=6, n_estimators=140; total time=   2.5s\n",
      "[CV] END ......criterion=gini, max_depth=12, n_estimators=50; total time=   1.8s\n",
      "[CV] END ...criterion=gini, max_depth=None, n_estimators=180; total time=   9.8s\n",
      "[CV] END ......criterion=gini, max_depth=4, n_estimators=120; total time=   1.3s\n",
      "[CV] END .criterion=log_loss, max_depth=14, n_estimators=130; total time=   5.5s\n",
      "[CV] END .......criterion=gini, max_depth=6, n_estimators=30; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=170; total time=  10.0s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=110; total time=   3.3s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=100; total time=   3.1s\n",
      "[CV] END .....criterion=gini, max_depth=18, n_estimators=140; total time=   6.2s\n",
      "[CV] END ..criterion=entropy, max_depth=12, n_estimators=180; total time=   5.9s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=180; total time=   7.3s\n",
      "[CV] END ..criterion=log_loss, max_depth=4, n_estimators=170; total time=   1.8s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=120; total time=   4.7s\n",
      "[CV] END .criterion=log_loss, max_depth=10, n_estimators=100; total time=   2.7s\n",
      "[CV] END ......criterion=gini, max_depth=4, n_estimators=190; total time=   1.9s\n",
      "[CV] END ...criterion=entropy, max_depth=14, n_estimators=10; total time=   0.4s\n",
      "[CV] END ..criterion=log_loss, max_depth=12, n_estimators=90; total time=   2.8s\n",
      "[CV] END ....criterion=gini, max_depth=None, n_estimators=80; total time=   3.7s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=110; total time=   3.4s\n",
      "[CV] END .....criterion=gini, max_depth=18, n_estimators=180; total time=   7.2s\n",
      "[CV] END ...criterion=entropy, max_depth=4, n_estimators=210; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=290; total time=  14.9s\n",
      "[CV] END criterion=log_loss, max_depth=None, n_estimators=170; total time=   8.8s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=190; total time=   6.8s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=270; total time=   3.8s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=200; total time=   2.9s\n",
      "[CV] END ..criterion=log_loss, max_depth=4, n_estimators=300; total time=   3.0s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=70; total time=   1.2s\n",
      "[CV] END .....criterion=gini, max_depth=18, n_estimators=220; total time=   8.7s\n",
      "[CV] END ..criterion=entropy, max_depth=14, n_estimators=210; total time=   7.1s\n",
      "[CV] END criterion=log_loss, max_depth=None, n_estimators=270; total time=  13.9s\n",
      "[CV] END ...criterion=gini, max_depth=None, n_estimators=200; total time=   9.0s\n",
      "[CV] END ...criterion=entropy, max_depth=14, n_estimators=70; total time=   2.4s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=150; total time=   2.1s\n",
      "[CV] END .....criterion=gini, max_depth=10, n_estimators=200; total time=   4.8s\n",
      "[CV] END ..criterion=entropy, max_depth=10, n_estimators=240; total time=   6.4s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=220; total time=  13.2s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=200; total time=   6.1s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=80; total time=   1.5s\n",
      "[CV] END ...criterion=entropy, max_depth=8, n_estimators=230; total time=   4.9s\n",
      "[CV] END ...criterion=entropy, max_depth=8, n_estimators=270; total time=   5.8s\n",
      "[CV] END ......criterion=gini, max_depth=6, n_estimators=100; total time=   1.5s\n",
      "[CV] END .......criterion=gini, max_depth=6, n_estimators=10; total time=   0.2s\n",
      "[CV] END .......criterion=gini, max_depth=6, n_estimators=10; total time=   0.1s\n",
      "[CV] END .......criterion=gini, max_depth=6, n_estimators=10; total time=   0.1s\n",
      "[CV] END ..criterion=log_loss, max_depth=16, n_estimators=90; total time=   4.1s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=290; total time=  11.6s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=300; total time=  11.9s\n",
      "[CV] END ......criterion=gini, max_depth=8, n_estimators=190; total time=   3.9s\n",
      "[CV] END .criterion=log_loss, max_depth=10, n_estimators=280; total time=   7.8s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=210; total time=   6.9s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=120; total time=   3.8s\n",
      "[CV] END ..criterion=log_loss, max_depth=16, n_estimators=50; total time=   2.1s\n",
      "[CV] END .criterion=log_loss, max_depth=14, n_estimators=150; total time=   5.8s\n",
      "[CV] END ......criterion=gini, max_depth=4, n_estimators=240; total time=   2.3s\n",
      "[CV] END ...criterion=entropy, max_depth=8, n_estimators=220; total time=   4.6s\n",
      "[CV] END ...criterion=entropy, max_depth=12, n_estimators=70; total time=   2.2s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=40; total time=   0.8s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=130; total time=   5.1s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=60; total time=   1.1s\n",
      "[CV] END .criterion=entropy, max_depth=None, n_estimators=50; total time=   2.9s\n",
      "[CV] END ...criterion=entropy, max_depth=4, n_estimators=250; total time=   2.5s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=180; total time=   5.5s\n",
      "[CV] END ..criterion=log_loss, max_depth=10, n_estimators=40; total time=   1.1s\n",
      "[CV] END ......criterion=gini, max_depth=18, n_estimators=20; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=210; total time=  11.4s\n",
      "[CV] END ..criterion=log_loss, max_depth=14, n_estimators=70; total time=   2.7s\n",
      "[CV] END ...criterion=log_loss, max_depth=4, n_estimators=30; total time=   0.3s\n",
      "[CV] END ....criterion=entropy, max_depth=8, n_estimators=70; total time=   1.5s\n",
      "[CV] END ..criterion=log_loss, max_depth=10, n_estimators=20; total time=   0.6s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=220; total time=   3.2s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=140; total time=   4.3s\n",
      "[CV] END ....criterion=entropy, max_depth=6, n_estimators=30; total time=   0.5s\n",
      "[CV] END ....criterion=entropy, max_depth=6, n_estimators=30; total time=   0.4s\n",
      "[CV] END ..criterion=entropy, max_depth=12, n_estimators=160; total time=   5.0s\n",
      "[CV] END ..criterion=log_loss, max_depth=4, n_estimators=100; total time=   1.0s\n",
      "[CV] END ......criterion=gini, max_depth=8, n_estimators=270; total time=   5.3s\n",
      "[CV] END ...criterion=entropy, max_depth=18, n_estimators=80; total time=   3.5s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=100; total time=   1.5s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=280; total time=   4.1s\n",
      "[CV] END ...criterion=log_loss, max_depth=8, n_estimators=60; total time=   1.4s\n",
      "[CV] END ......criterion=gini, max_depth=12, n_estimators=10; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=14, n_estimators=250; total time=   8.6s\n",
      "[CV] END .criterion=log_loss, max_depth=16, n_estimators=220; total time=   9.3s\n",
      "[CV] END .....criterion=gini, max_depth=14, n_estimators=190; total time=   6.5s\n",
      "[CV] END ...criterion=entropy, max_depth=4, n_estimators=160; total time=   1.7s\n",
      "[CV] END ......criterion=gini, max_depth=6, n_estimators=200; total time=   3.2s\n",
      "[CV] END ......criterion=gini, max_depth=10, n_estimators=70; total time=   1.8s\n",
      "[CV] END ......criterion=gini, max_depth=14, n_estimators=60; total time=   2.2s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=100; total time=   3.3s\n",
      "[CV] END ..criterion=entropy, max_depth=18, n_estimators=150; total time=   7.2s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=250; total time=   4.1s\n",
      "[CV] END criterion=log_loss, max_depth=None, n_estimators=260; total time=  15.1s\n",
      "[CV] END .......criterion=gini, max_depth=6, n_estimators=20; total time=   0.4s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=290; total time=   4.8s\n",
      "[CV] END ...criterion=entropy, max_depth=4, n_estimators=130; total time=   1.6s\n",
      "[CV] END ......criterion=gini, max_depth=6, n_estimators=140; total time=   2.3s\n",
      "[CV] END ......criterion=gini, max_depth=12, n_estimators=50; total time=   1.8s\n",
      "[CV] END ...criterion=gini, max_depth=None, n_estimators=180; total time=   9.9s\n",
      "[CV] END .......criterion=gini, max_depth=4, n_estimators=10; total time=   0.1s\n",
      "[CV] END .......criterion=gini, max_depth=4, n_estimators=10; total time=   0.1s\n",
      "[CV] END .......criterion=gini, max_depth=4, n_estimators=10; total time=   0.1s\n",
      "[CV] END .......criterion=gini, max_depth=4, n_estimators=10; total time=   0.1s\n",
      "[CV] END .......criterion=gini, max_depth=4, n_estimators=10; total time=   0.1s\n",
      "[CV] END ......criterion=gini, max_depth=4, n_estimators=120; total time=   1.3s\n",
      "[CV] END .criterion=log_loss, max_depth=14, n_estimators=130; total time=   5.5s\n",
      "[CV] END .......criterion=gini, max_depth=6, n_estimators=30; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=170; total time=  10.2s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=110; total time=   3.4s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=100; total time=   3.2s\n",
      "[CV] END .....criterion=gini, max_depth=18, n_estimators=140; total time=   6.0s\n",
      "[CV] END ..criterion=entropy, max_depth=12, n_estimators=180; total time=   6.3s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=180; total time=   7.1s\n",
      "[CV] END ..criterion=log_loss, max_depth=4, n_estimators=170; total time=   1.8s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=120; total time=   4.7s\n",
      "[CV] END .criterion=log_loss, max_depth=10, n_estimators=100; total time=   2.7s\n",
      "[CV] END ......criterion=gini, max_depth=4, n_estimators=190; total time=   1.9s\n",
      "[CV] END ...criterion=entropy, max_depth=14, n_estimators=10; total time=   0.4s\n",
      "[CV] END ..criterion=log_loss, max_depth=12, n_estimators=90; total time=   2.7s\n",
      "[CV] END ....criterion=gini, max_depth=None, n_estimators=80; total time=   3.7s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=110; total time=   3.2s\n",
      "[CV] END .....criterion=gini, max_depth=18, n_estimators=180; total time=   7.4s\n",
      "[CV] END ...criterion=entropy, max_depth=4, n_estimators=210; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=290; total time=  15.0s\n",
      "[CV] END criterion=log_loss, max_depth=None, n_estimators=170; total time=   8.6s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=190; total time=   6.8s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=270; total time=   3.8s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=200; total time=   2.9s\n",
      "[CV] END ..criterion=log_loss, max_depth=4, n_estimators=300; total time=   3.0s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=70; total time=   1.3s\n",
      "[CV] END .....criterion=gini, max_depth=18, n_estimators=220; total time=   8.4s\n",
      "[CV] END ..criterion=entropy, max_depth=14, n_estimators=210; total time=   7.6s\n",
      "[CV] END criterion=log_loss, max_depth=None, n_estimators=270; total time=  13.9s\n",
      "[CV] END ...criterion=gini, max_depth=None, n_estimators=200; total time=   9.0s\n",
      "[CV] END ...criterion=entropy, max_depth=14, n_estimators=70; total time=   2.4s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=150; total time=   2.1s\n",
      "[CV] END .....criterion=gini, max_depth=10, n_estimators=200; total time=   5.1s\n",
      "[CV] END ..criterion=entropy, max_depth=10, n_estimators=240; total time=   6.6s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=220; total time=  12.8s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=200; total time=   6.3s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=80; total time=   1.6s\n",
      "[CV] END ...criterion=entropy, max_depth=8, n_estimators=230; total time=   4.8s\n",
      "[CV] END ...criterion=entropy, max_depth=8, n_estimators=270; total time=   5.9s\n",
      "[CV] END ......criterion=gini, max_depth=6, n_estimators=100; total time=   1.6s\n",
      "[CV] END ..criterion=log_loss, max_depth=16, n_estimators=90; total time=   4.1s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=290; total time=  12.0s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=300; total time=  11.9s\n",
      "[CV] END ......criterion=gini, max_depth=8, n_estimators=190; total time=   3.8s\n",
      "[CV] END .criterion=log_loss, max_depth=10, n_estimators=280; total time=   7.5s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=210; total time=   6.9s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=120; total time=   4.0s\n",
      "[CV] END ..criterion=log_loss, max_depth=16, n_estimators=50; total time=   2.1s\n",
      "[CV] END .criterion=log_loss, max_depth=14, n_estimators=150; total time=   5.9s\n",
      "[CV] END ......criterion=gini, max_depth=4, n_estimators=240; total time=   2.4s\n",
      "[CV] END ...criterion=entropy, max_depth=8, n_estimators=220; total time=   4.8s\n",
      "[CV] END ...criterion=entropy, max_depth=12, n_estimators=70; total time=   2.2s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=130; total time=   5.2s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=60; total time=   1.1s\n",
      "[CV] END .criterion=entropy, max_depth=None, n_estimators=50; total time=   2.8s\n",
      "[CV] END ...criterion=entropy, max_depth=4, n_estimators=250; total time=   2.6s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=180; total time=   5.4s\n",
      "[CV] END ..criterion=log_loss, max_depth=10, n_estimators=40; total time=   1.0s\n",
      "[CV] END ......criterion=gini, max_depth=18, n_estimators=20; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=210; total time=  11.2s\n",
      "[CV] END ..criterion=log_loss, max_depth=14, n_estimators=70; total time=   2.6s\n",
      "[CV] END ...criterion=log_loss, max_depth=4, n_estimators=30; total time=   0.3s\n",
      "[CV] END ...criterion=log_loss, max_depth=4, n_estimators=30; total time=   0.3s\n",
      "[CV] END ...criterion=log_loss, max_depth=6, n_estimators=10; total time=   0.2s\n",
      "[CV] END ....criterion=entropy, max_depth=8, n_estimators=70; total time=   1.4s\n",
      "[CV] END ..criterion=log_loss, max_depth=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=220; total time=   3.4s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=140; total time=   4.4s\n",
      "[CV] END ....criterion=entropy, max_depth=6, n_estimators=30; total time=   0.5s\n",
      "[CV] END ..criterion=entropy, max_depth=12, n_estimators=160; total time=   5.3s\n",
      "[CV] END ..criterion=log_loss, max_depth=4, n_estimators=100; total time=   1.0s\n",
      "[CV] END ......criterion=gini, max_depth=8, n_estimators=270; total time=   5.2s\n",
      "[CV] END ...criterion=entropy, max_depth=18, n_estimators=80; total time=   3.6s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=100; total time=   1.6s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=280; total time=   4.2s\n",
      "[CV] END ...criterion=log_loss, max_depth=8, n_estimators=60; total time=   1.2s\n",
      "[CV] END ......criterion=gini, max_depth=12, n_estimators=10; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=14, n_estimators=250; total time=   8.7s\n",
      "[CV] END .criterion=log_loss, max_depth=16, n_estimators=220; total time=   9.3s\n",
      "[CV] END .....criterion=gini, max_depth=14, n_estimators=190; total time=   6.7s\n",
      "[CV] END ...criterion=entropy, max_depth=4, n_estimators=160; total time=   1.7s\n",
      "[CV] END ......criterion=gini, max_depth=6, n_estimators=200; total time=   3.1s\n",
      "[CV] END ......criterion=gini, max_depth=10, n_estimators=70; total time=   1.9s\n",
      "[CV] END ......criterion=gini, max_depth=14, n_estimators=60; total time=   2.1s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=100; total time=   3.4s\n",
      "[CV] END ..criterion=entropy, max_depth=18, n_estimators=150; total time=   6.9s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=250; total time=   3.9s\n",
      "[CV] END criterion=log_loss, max_depth=None, n_estimators=260; total time=  14.6s\n",
      "[CV] END .......criterion=gini, max_depth=6, n_estimators=40; total time=   0.7s\n",
      "[CV] END .......criterion=gini, max_depth=6, n_estimators=20; total time=   0.3s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=290; total time=   4.8s\n",
      "[CV] END ....criterion=entropy, max_depth=4, n_estimators=60; total time=   0.7s\n",
      "[CV] END ..criterion=entropy, max_depth=10, n_estimators=110; total time=   3.0s\n",
      "[CV] END ......criterion=gini, max_depth=10, n_estimators=40; total time=   1.1s\n",
      "[CV] END ...criterion=entropy, max_depth=8, n_estimators=150; total time=   3.7s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=100; total time=   1.9s\n",
      "[CV] END ......criterion=gini, max_depth=12, n_estimators=30; total time=   1.1s\n",
      "[CV] END ...criterion=entropy, max_depth=4, n_estimators=130; total time=   1.5s\n",
      "[CV] END ......criterion=gini, max_depth=6, n_estimators=140; total time=   2.4s\n",
      "[CV] END ......criterion=gini, max_depth=12, n_estimators=50; total time=   1.8s\n",
      "[CV] END ...criterion=gini, max_depth=None, n_estimators=180; total time=  10.0s\n",
      "[CV] END ......criterion=gini, max_depth=4, n_estimators=120; total time=   1.3s\n",
      "[CV] END .criterion=log_loss, max_depth=14, n_estimators=130; total time=   5.4s\n",
      "[CV] END .......criterion=gini, max_depth=6, n_estimators=30; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=170; total time=  10.2s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=110; total time=   3.4s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=100; total time=   3.2s\n",
      "[CV] END .....criterion=gini, max_depth=18, n_estimators=140; total time=   6.1s\n",
      "[CV] END ..criterion=entropy, max_depth=12, n_estimators=180; total time=   6.1s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=180; total time=   7.2s\n",
      "[CV] END ..criterion=log_loss, max_depth=4, n_estimators=170; total time=   1.7s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=120; total time=   4.8s\n",
      "[CV] END .criterion=log_loss, max_depth=10, n_estimators=100; total time=   2.8s\n",
      "[CV] END ......criterion=gini, max_depth=4, n_estimators=190; total time=   2.0s\n",
      "[CV] END ...criterion=entropy, max_depth=14, n_estimators=10; total time=   0.4s\n",
      "[CV] END ..criterion=log_loss, max_depth=12, n_estimators=90; total time=   2.9s\n",
      "[CV] END ....criterion=gini, max_depth=None, n_estimators=80; total time=   3.6s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=110; total time=   3.3s\n",
      "[CV] END .....criterion=gini, max_depth=18, n_estimators=180; total time=   7.1s\n",
      "[CV] END ...criterion=entropy, max_depth=4, n_estimators=210; total time=   2.1s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=290; total time=  15.0s\n",
      "[CV] END criterion=log_loss, max_depth=None, n_estimators=170; total time=   9.0s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=190; total time=   6.9s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=270; total time=   4.0s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=200; total time=   2.9s\n",
      "[CV] END ..criterion=log_loss, max_depth=4, n_estimators=300; total time=   2.8s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=70; total time=   1.3s\n",
      "[CV] END .....criterion=gini, max_depth=18, n_estimators=220; total time=   8.6s\n",
      "[CV] END ..criterion=entropy, max_depth=14, n_estimators=210; total time=   7.3s\n",
      "[CV] END criterion=log_loss, max_depth=None, n_estimators=270; total time=  13.5s\n",
      "[CV] END ...criterion=gini, max_depth=None, n_estimators=200; total time=   8.8s\n",
      "[CV] END ...criterion=entropy, max_depth=14, n_estimators=70; total time=   2.4s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=150; total time=   2.1s\n",
      "[CV] END .....criterion=gini, max_depth=10, n_estimators=200; total time=   5.0s\n",
      "[CV] END ..criterion=entropy, max_depth=10, n_estimators=240; total time=   6.3s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=220; total time=  12.2s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=200; total time=   5.9s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=80; total time=   1.7s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=80; total time=   1.6s\n",
      "[CV] END ...criterion=entropy, max_depth=8, n_estimators=230; total time=   5.0s\n",
      "[CV] END ...criterion=entropy, max_depth=8, n_estimators=270; total time=   5.7s\n",
      "[CV] END ......criterion=gini, max_depth=6, n_estimators=100; total time=   1.4s\n",
      "[CV] END ..criterion=log_loss, max_depth=16, n_estimators=90; total time=   3.9s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=290; total time=  11.5s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=300; total time=  11.4s\n",
      "[CV] END ......criterion=gini, max_depth=8, n_estimators=190; total time=   3.7s\n",
      "[CV] END .criterion=log_loss, max_depth=10, n_estimators=280; total time=   7.3s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=210; total time=   6.8s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=120; total time=   3.9s\n",
      "[CV] END ..criterion=log_loss, max_depth=16, n_estimators=50; total time=   2.1s\n",
      "[CV] END ..criterion=log_loss, max_depth=16, n_estimators=50; total time=   2.0s\n",
      "[CV] END .criterion=log_loss, max_depth=14, n_estimators=150; total time=   5.4s\n",
      "[CV] END ......criterion=gini, max_depth=4, n_estimators=240; total time=   2.3s\n",
      "[CV] END ...criterion=entropy, max_depth=8, n_estimators=220; total time=   4.8s\n",
      "[CV] END ...criterion=entropy, max_depth=12, n_estimators=70; total time=   2.3s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=130; total time=   5.0s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=60; total time=   1.2s\n",
      "[CV] END .criterion=entropy, max_depth=None, n_estimators=50; total time=   2.6s\n",
      "[CV] END ...criterion=entropy, max_depth=4, n_estimators=250; total time=   2.4s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=180; total time=   5.7s\n",
      "[CV] END ..criterion=log_loss, max_depth=10, n_estimators=40; total time=   1.0s\n",
      "[CV] END ......criterion=gini, max_depth=18, n_estimators=20; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=210; total time=  11.5s\n",
      "[CV] END ..criterion=log_loss, max_depth=14, n_estimators=70; total time=   2.7s\n",
      "[CV] END ...criterion=log_loss, max_depth=4, n_estimators=30; total time=   0.3s\n",
      "[CV] END ...criterion=log_loss, max_depth=4, n_estimators=30; total time=   0.3s\n",
      "[CV] END ...criterion=log_loss, max_depth=6, n_estimators=10; total time=   0.2s\n",
      "[CV] END ....criterion=entropy, max_depth=8, n_estimators=70; total time=   1.5s\n",
      "[CV] END ..criterion=log_loss, max_depth=10, n_estimators=20; total time=   0.6s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=220; total time=   3.2s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=140; total time=   4.7s\n",
      "[CV] END ....criterion=entropy, max_depth=6, n_estimators=30; total time=   0.4s\n",
      "[CV] END ..criterion=entropy, max_depth=12, n_estimators=160; total time=   5.3s\n",
      "[CV] END ..criterion=log_loss, max_depth=4, n_estimators=100; total time=   1.0s\n",
      "[CV] END ......criterion=gini, max_depth=8, n_estimators=270; total time=   5.2s\n",
      "[CV] END ...criterion=entropy, max_depth=18, n_estimators=80; total time=   3.8s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=100; total time=   1.6s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=280; total time=   4.4s\n",
      "[CV] END ...criterion=log_loss, max_depth=8, n_estimators=60; total time=   1.2s\n",
      "[CV] END .....criterion=gini, max_depth=14, n_estimators=250; total time=   8.8s\n",
      "[CV] END .criterion=log_loss, max_depth=16, n_estimators=220; total time=   9.4s\n",
      "[CV] END .....criterion=gini, max_depth=14, n_estimators=190; total time=   6.6s\n",
      "[CV] END ...criterion=entropy, max_depth=4, n_estimators=160; total time=   1.7s\n",
      "[CV] END ......criterion=gini, max_depth=6, n_estimators=200; total time=   2.9s\n",
      "[CV] END ......criterion=gini, max_depth=10, n_estimators=70; total time=   1.8s\n",
      "[CV] END ......criterion=gini, max_depth=14, n_estimators=60; total time=   2.2s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=100; total time=   3.4s\n",
      "[CV] END ..criterion=entropy, max_depth=18, n_estimators=150; total time=   6.9s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=250; total time=   4.1s\n",
      "[CV] END criterion=log_loss, max_depth=None, n_estimators=260; total time=  15.0s\n",
      "[CV] END .......criterion=gini, max_depth=6, n_estimators=20; total time=   0.3s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=290; total time=   4.8s\n",
      "[CV] END ....criterion=entropy, max_depth=4, n_estimators=60; total time=   0.7s\n",
      "[CV] END ......criterion=gini, max_depth=12, n_estimators=50; total time=   1.8s\n",
      "[CV] END ...criterion=gini, max_depth=None, n_estimators=180; total time=  10.2s\n",
      "[CV] END .......criterion=gini, max_depth=4, n_estimators=10; total time=   0.1s\n",
      "[CV] END ......criterion=gini, max_depth=4, n_estimators=120; total time=   1.4s\n",
      "[CV] END .criterion=log_loss, max_depth=14, n_estimators=130; total time=   5.4s\n",
      "[CV] END .......criterion=gini, max_depth=6, n_estimators=30; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=170; total time=  10.4s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=110; total time=   3.3s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=100; total time=   3.2s\n",
      "[CV] END .....criterion=gini, max_depth=18, n_estimators=140; total time=   6.1s\n",
      "[CV] END ..criterion=entropy, max_depth=12, n_estimators=180; total time=   6.2s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=180; total time=   7.3s\n",
      "[CV] END ..criterion=log_loss, max_depth=4, n_estimators=170; total time=   1.8s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=120; total time=   4.8s\n",
      "[CV] END .criterion=log_loss, max_depth=10, n_estimators=100; total time=   2.7s\n",
      "[CV] END ......criterion=gini, max_depth=4, n_estimators=190; total time=   2.0s\n",
      "[CV] END ..criterion=log_loss, max_depth=12, n_estimators=90; total time=   2.9s\n",
      "[CV] END ....criterion=gini, max_depth=None, n_estimators=80; total time=   3.6s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=110; total time=   3.3s\n",
      "[CV] END .....criterion=gini, max_depth=18, n_estimators=180; total time=   7.1s\n",
      "[CV] END ...criterion=entropy, max_depth=4, n_estimators=210; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=290; total time=  15.1s\n",
      "[CV] END criterion=log_loss, max_depth=None, n_estimators=170; total time=   9.2s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=190; total time=   7.0s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=270; total time=   3.8s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=200; total time=   2.9s\n",
      "[CV] END ..criterion=log_loss, max_depth=4, n_estimators=300; total time=   2.8s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=70; total time=   1.4s\n",
      "[CV] END .....criterion=gini, max_depth=18, n_estimators=220; total time=   8.6s\n",
      "[CV] END ..criterion=entropy, max_depth=14, n_estimators=210; total time=   7.5s\n",
      "[CV] END criterion=log_loss, max_depth=None, n_estimators=270; total time=  14.4s\n",
      "[CV] END ...criterion=gini, max_depth=None, n_estimators=200; total time=   8.9s\n",
      "[CV] END ...criterion=entropy, max_depth=14, n_estimators=70; total time=   2.6s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=150; total time=   2.1s\n",
      "[CV] END .....criterion=gini, max_depth=10, n_estimators=200; total time=   5.3s\n",
      "[CV] END ..criterion=entropy, max_depth=10, n_estimators=240; total time=   6.7s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=220; total time=  12.6s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=200; total time=   6.3s\n",
      "[CV] END ...criterion=entropy, max_depth=8, n_estimators=230; total time=   4.9s\n",
      "[CV] END ...criterion=entropy, max_depth=8, n_estimators=270; total time=   5.9s\n",
      "[CV] END ......criterion=gini, max_depth=6, n_estimators=100; total time=   1.5s\n",
      "[CV] END .......criterion=gini, max_depth=6, n_estimators=10; total time=   0.2s\n",
      "[CV] END .......criterion=gini, max_depth=6, n_estimators=10; total time=   0.1s\n",
      "[CV] END ..criterion=log_loss, max_depth=16, n_estimators=90; total time=   4.0s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=290; total time=  11.5s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=300; total time=  11.9s\n",
      "[CV] END ......criterion=gini, max_depth=8, n_estimators=190; total time=   3.8s\n",
      "[CV] END .criterion=log_loss, max_depth=10, n_estimators=280; total time=   7.6s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=210; total time=   7.1s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=120; total time=   3.9s\n",
      "[CV] END ..criterion=log_loss, max_depth=16, n_estimators=50; total time=   2.1s\n",
      "[CV] END .criterion=log_loss, max_depth=14, n_estimators=150; total time=   5.7s\n",
      "[CV] END ......criterion=gini, max_depth=4, n_estimators=240; total time=   2.4s\n",
      "[CV] END ...criterion=entropy, max_depth=8, n_estimators=220; total time=   4.8s\n",
      "[CV] END ...criterion=entropy, max_depth=12, n_estimators=70; total time=   2.3s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=40; total time=   0.8s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=130; total time=   5.2s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=60; total time=   1.3s\n",
      "[CV] END .criterion=entropy, max_depth=None, n_estimators=50; total time=   2.9s\n",
      "[CV] END ...criterion=entropy, max_depth=4, n_estimators=250; total time=   2.5s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=180; total time=   5.8s\n",
      "[CV] END ......criterion=gini, max_depth=18, n_estimators=20; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=210; total time=  11.5s\n",
      "[CV] END ..criterion=log_loss, max_depth=14, n_estimators=70; total time=   2.5s\n",
      "[CV] END ...criterion=log_loss, max_depth=4, n_estimators=30; total time=   0.3s\n",
      "[CV] END ...criterion=log_loss, max_depth=4, n_estimators=30; total time=   0.3s\n",
      "[CV] END ...criterion=log_loss, max_depth=6, n_estimators=10; total time=   0.1s\n",
      "[CV] END ...criterion=log_loss, max_depth=6, n_estimators=10; total time=   0.2s\n",
      "[CV] END ....criterion=entropy, max_depth=8, n_estimators=70; total time=   1.6s\n",
      "[CV] END ..criterion=log_loss, max_depth=10, n_estimators=20; total time=   0.6s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=220; total time=   3.3s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=140; total time=   4.4s\n",
      "[CV] END ....criterion=entropy, max_depth=6, n_estimators=30; total time=   0.5s\n",
      "[CV] END ..criterion=entropy, max_depth=12, n_estimators=160; total time=   5.0s\n",
      "[CV] END ..criterion=log_loss, max_depth=4, n_estimators=100; total time=   1.0s\n",
      "[CV] END ......criterion=gini, max_depth=8, n_estimators=270; total time=   5.1s\n",
      "[CV] END ...criterion=entropy, max_depth=18, n_estimators=80; total time=   3.4s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=100; total time=   1.5s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=280; total time=   4.2s\n",
      "[CV] END ...criterion=log_loss, max_depth=8, n_estimators=60; total time=   1.2s\n",
      "[CV] END ......criterion=gini, max_depth=12, n_estimators=10; total time=   0.3s\n",
      "[CV] END ......criterion=gini, max_depth=12, n_estimators=10; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=14, n_estimators=250; total time=   8.7s\n",
      "[CV] END .criterion=log_loss, max_depth=16, n_estimators=220; total time=   9.1s\n",
      "[CV] END .....criterion=gini, max_depth=14, n_estimators=190; total time=   6.6s\n",
      "[CV] END ...criterion=entropy, max_depth=4, n_estimators=160; total time=   1.7s\n",
      "[CV] END ......criterion=gini, max_depth=6, n_estimators=200; total time=   3.2s\n",
      "[CV] END ......criterion=gini, max_depth=10, n_estimators=70; total time=   1.9s\n",
      "[CV] END ......criterion=gini, max_depth=14, n_estimators=60; total time=   2.0s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=100; total time=   3.3s\n",
      "[CV] END ..criterion=entropy, max_depth=18, n_estimators=150; total time=   7.0s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=250; total time=   3.9s\n",
      "[CV] END criterion=log_loss, max_depth=None, n_estimators=260; total time=  14.9s\n",
      "[CV] END .......criterion=gini, max_depth=6, n_estimators=40; total time=   0.7s\n",
      "[CV] END .......criterion=gini, max_depth=6, n_estimators=20; total time=   0.3s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=290; total time=   4.8s\n",
      "[CV] END ....criterion=entropy, max_depth=4, n_estimators=60; total time=   0.7s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=300; total time=   5.3s\n",
      "[CV] END ..criterion=entropy, max_depth=10, n_estimators=220; total time=   6.2s\n",
      "[CV] END ......criterion=gini, max_depth=18, n_estimators=10; total time=   0.4s\n",
      "[CV] END ..criterion=entropy, max_depth=14, n_estimators=130; total time=   5.1s\n",
      "[CV] END ......criterion=gini, max_depth=12, n_estimators=30; total time=   1.0s\n",
      "[CV] END ...criterion=entropy, max_depth=4, n_estimators=130; total time=   1.6s\n",
      "[CV] END ......criterion=gini, max_depth=6, n_estimators=140; total time=   2.4s\n",
      "[CV] END ......criterion=gini, max_depth=12, n_estimators=50; total time=   1.8s\n",
      "[CV] END ...criterion=gini, max_depth=None, n_estimators=180; total time=   9.9s\n",
      "[CV] END ......criterion=gini, max_depth=4, n_estimators=120; total time=   1.3s\n",
      "[CV] END .criterion=log_loss, max_depth=14, n_estimators=130; total time=   5.4s\n",
      "[CV] END .......criterion=gini, max_depth=6, n_estimators=30; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=170; total time=  10.3s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=110; total time=   3.5s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=100; total time=   3.0s\n",
      "[CV] END .....criterion=gini, max_depth=18, n_estimators=140; total time=   6.0s\n",
      "[CV] END ..criterion=entropy, max_depth=12, n_estimators=180; total time=   6.1s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=180; total time=   7.4s\n",
      "[CV] END ..criterion=log_loss, max_depth=4, n_estimators=170; total time=   1.8s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=120; total time=   4.9s\n",
      "[CV] END .criterion=log_loss, max_depth=10, n_estimators=100; total time=   2.8s\n",
      "[CV] END ......criterion=gini, max_depth=4, n_estimators=190; total time=   1.8s\n",
      "[CV] END ..criterion=log_loss, max_depth=12, n_estimators=90; total time=   2.9s\n",
      "[CV] END ....criterion=gini, max_depth=None, n_estimators=80; total time=   3.8s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=110; total time=   3.3s\n",
      "[CV] END .....criterion=gini, max_depth=18, n_estimators=180; total time=   7.2s\n",
      "[CV] END ...criterion=entropy, max_depth=4, n_estimators=210; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=290; total time=  15.1s\n",
      "[CV] END criterion=log_loss, max_depth=None, n_estimators=170; total time=   8.9s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=190; total time=   6.9s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=270; total time=   3.8s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=200; total time=   2.9s\n",
      "[CV] END ..criterion=log_loss, max_depth=4, n_estimators=300; total time=   2.9s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=70; total time=   1.3s\n",
      "[CV] END .....criterion=gini, max_depth=18, n_estimators=220; total time=   8.7s\n",
      "[CV] END ..criterion=entropy, max_depth=14, n_estimators=210; total time=   7.3s\n",
      "[CV] END criterion=log_loss, max_depth=None, n_estimators=270; total time=  13.8s\n",
      "[CV] END ...criterion=gini, max_depth=None, n_estimators=200; total time=   8.9s\n",
      "[CV] END ...criterion=entropy, max_depth=14, n_estimators=70; total time=   2.4s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=150; total time=   2.1s\n",
      "[CV] END .....criterion=gini, max_depth=10, n_estimators=200; total time=   5.0s\n",
      "[CV] END ..criterion=entropy, max_depth=10, n_estimators=240; total time=   6.6s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=220; total time=  12.3s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=200; total time=   6.2s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=80; total time=   1.6s\n",
      "[CV] END ...criterion=entropy, max_depth=8, n_estimators=230; total time=   4.8s\n",
      "[CV] END ...criterion=entropy, max_depth=8, n_estimators=270; total time=   5.9s\n",
      "[CV] END ......criterion=gini, max_depth=6, n_estimators=100; total time=   1.6s\n",
      "[CV] END .......criterion=gini, max_depth=6, n_estimators=10; total time=   0.2s\n",
      "[CV] END ..criterion=log_loss, max_depth=16, n_estimators=90; total time=   3.9s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=290; total time=  11.5s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=300; total time=  11.9s\n",
      "[CV] END ......criterion=gini, max_depth=8, n_estimators=190; total time=   3.9s\n",
      "[CV] END .criterion=log_loss, max_depth=10, n_estimators=280; total time=   7.6s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=210; total time=   6.7s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=120; total time=   3.7s\n",
      "[CV] END ..criterion=log_loss, max_depth=16, n_estimators=50; total time=   2.2s\n",
      "[CV] END .criterion=log_loss, max_depth=14, n_estimators=150; total time=   5.7s\n",
      "[CV] END ......criterion=gini, max_depth=4, n_estimators=240; total time=   2.5s\n",
      "[CV] END ...criterion=entropy, max_depth=8, n_estimators=220; total time=   4.7s\n",
      "[CV] END ...criterion=entropy, max_depth=12, n_estimators=70; total time=   2.4s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=40; total time=   0.8s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=130; total time=   5.2s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=60; total time=   1.3s\n",
      "[CV] END .criterion=entropy, max_depth=None, n_estimators=50; total time=   2.7s\n",
      "[CV] END ...criterion=entropy, max_depth=4, n_estimators=250; total time=   2.4s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=180; total time=   5.3s\n",
      "[CV] END ..criterion=log_loss, max_depth=10, n_estimators=40; total time=   1.1s\n",
      "[CV] END ..criterion=log_loss, max_depth=10, n_estimators=40; total time=   1.1s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=210; total time=  11.7s\n",
      "[CV] END ..criterion=log_loss, max_depth=14, n_estimators=70; total time=   2.5s\n",
      "[CV] END ...criterion=log_loss, max_depth=4, n_estimators=30; total time=   0.3s\n",
      "[CV] END ...criterion=log_loss, max_depth=4, n_estimators=30; total time=   0.3s\n",
      "[CV] END ....criterion=entropy, max_depth=8, n_estimators=70; total time=   1.5s\n",
      "[CV] END ..criterion=log_loss, max_depth=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=220; total time=   3.3s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=140; total time=   4.5s\n",
      "[CV] END ....criterion=entropy, max_depth=6, n_estimators=30; total time=   0.5s\n",
      "[CV] END ..criterion=entropy, max_depth=12, n_estimators=160; total time=   4.9s\n",
      "[CV] END ..criterion=log_loss, max_depth=4, n_estimators=100; total time=   1.0s\n",
      "[CV] END ......criterion=gini, max_depth=8, n_estimators=270; total time=   5.3s\n",
      "[CV] END ...criterion=entropy, max_depth=18, n_estimators=80; total time=   3.5s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=100; total time=   1.4s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=280; total time=   4.3s\n",
      "[CV] END ...criterion=log_loss, max_depth=8, n_estimators=60; total time=   1.3s\n",
      "[CV] END ......criterion=gini, max_depth=12, n_estimators=10; total time=   0.3s\n",
      "[CV] END ......criterion=gini, max_depth=12, n_estimators=10; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=14, n_estimators=250; total time=   8.9s\n",
      "[CV] END .criterion=log_loss, max_depth=16, n_estimators=220; total time=   9.3s\n",
      "[CV] END .....criterion=gini, max_depth=14, n_estimators=190; total time=   6.8s\n",
      "[CV] END ...criterion=entropy, max_depth=4, n_estimators=160; total time=   1.6s\n",
      "[CV] END ......criterion=gini, max_depth=6, n_estimators=200; total time=   3.0s\n",
      "[CV] END ......criterion=gini, max_depth=10, n_estimators=70; total time=   1.9s\n",
      "[CV] END ......criterion=gini, max_depth=14, n_estimators=60; total time=   2.2s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=100; total time=   3.4s\n",
      "[CV] END ..criterion=entropy, max_depth=18, n_estimators=150; total time=   7.0s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=250; total time=   3.9s\n",
      "[CV] END criterion=log_loss, max_depth=None, n_estimators=260; total time=  15.3s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=290; total time=   4.7s\n",
      "[CV] END ....criterion=entropy, max_depth=4, n_estimators=60; total time=   0.7s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=300; total time=   5.2s\n",
      "[CV] END ..criterion=entropy, max_depth=10, n_estimators=220; total time=   6.3s\n",
      "[CV] END ......criterion=gini, max_depth=18, n_estimators=10; total time=   0.5s\n",
      "[CV] END ..criterion=entropy, max_depth=14, n_estimators=130; total time=   5.1s\n",
      "[CV] END ..criterion=entropy, max_depth=16, n_estimators=160; total time=   6.8s\n",
      "[CV] END ......criterion=gini, max_depth=6, n_estimators=140; total time=   2.4s\n",
      "[CV] END ......criterion=gini, max_depth=12, n_estimators=50; total time=   1.7s\n",
      "[CV] END ...criterion=gini, max_depth=None, n_estimators=180; total time=   9.7s\n",
      "[CV] END ......criterion=gini, max_depth=4, n_estimators=120; total time=   1.3s\n",
      "[CV] END .criterion=log_loss, max_depth=14, n_estimators=130; total time=   5.4s\n",
      "[CV] END .......criterion=gini, max_depth=6, n_estimators=30; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=170; total time=  10.1s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=110; total time=   3.5s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=100; total time=   3.1s\n",
      "[CV] END .....criterion=gini, max_depth=18, n_estimators=140; total time=   6.2s\n",
      "[CV] END ..criterion=entropy, max_depth=12, n_estimators=180; total time=   6.1s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=180; total time=   7.5s\n",
      "[CV] END ..criterion=log_loss, max_depth=4, n_estimators=170; total time=   1.8s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=120; total time=   4.8s\n",
      "[CV] END .criterion=log_loss, max_depth=10, n_estimators=100; total time=   2.7s\n",
      "[CV] END ......criterion=gini, max_depth=4, n_estimators=190; total time=   2.0s\n",
      "[CV] END ..criterion=log_loss, max_depth=12, n_estimators=90; total time=   2.8s\n",
      "[CV] END ....criterion=gini, max_depth=None, n_estimators=80; total time=   3.7s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=110; total time=   3.4s\n",
      "[CV] END .....criterion=gini, max_depth=18, n_estimators=180; total time=   7.0s\n",
      "[CV] END ...criterion=entropy, max_depth=4, n_estimators=210; total time=   2.1s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=290; total time=  15.2s\n",
      "[CV] END criterion=log_loss, max_depth=None, n_estimators=170; total time=   8.7s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=190; total time=   6.8s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=270; total time=   3.8s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=200; total time=   2.8s\n",
      "[CV] END ..criterion=log_loss, max_depth=4, n_estimators=300; total time=   2.9s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=70; total time=   1.3s\n",
      "[CV] END .....criterion=gini, max_depth=18, n_estimators=220; total time=   8.8s\n",
      "[CV] END ..criterion=entropy, max_depth=14, n_estimators=210; total time=   7.5s\n",
      "[CV] END criterion=log_loss, max_depth=None, n_estimators=270; total time=  14.0s\n",
      "[CV] END ...criterion=gini, max_depth=None, n_estimators=200; total time=   9.0s\n",
      "[CV] END ...criterion=entropy, max_depth=14, n_estimators=70; total time=   2.4s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=150; total time=   2.2s\n",
      "[CV] END .....criterion=gini, max_depth=10, n_estimators=200; total time=   5.1s\n",
      "[CV] END ..criterion=entropy, max_depth=10, n_estimators=240; total time=   6.5s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=220; total time=  12.4s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=200; total time=   6.4s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=80; total time=   1.6s\n",
      "[CV] END ...criterion=entropy, max_depth=8, n_estimators=230; total time=   4.9s\n",
      "[CV] END ...criterion=entropy, max_depth=8, n_estimators=270; total time=   5.6s\n",
      "[CV] END ......criterion=gini, max_depth=6, n_estimators=100; total time=   1.6s\n",
      "[CV] END ..criterion=log_loss, max_depth=16, n_estimators=90; total time=   3.8s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=290; total time=  11.9s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=300; total time=  12.1s\n",
      "[CV] END ......criterion=gini, max_depth=8, n_estimators=190; total time=   3.8s\n",
      "[CV] END .criterion=log_loss, max_depth=10, n_estimators=280; total time=   7.7s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=210; total time=   6.8s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=120; total time=   3.9s\n",
      "[CV] END ..criterion=log_loss, max_depth=16, n_estimators=50; total time=   2.2s\n",
      "[CV] END .criterion=log_loss, max_depth=14, n_estimators=150; total time=   5.6s\n",
      "[CV] END ......criterion=gini, max_depth=4, n_estimators=240; total time=   2.4s\n",
      "[CV] END ...criterion=entropy, max_depth=8, n_estimators=220; total time=   4.7s\n",
      "[CV] END ...criterion=entropy, max_depth=12, n_estimators=70; total time=   2.3s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=40; total time=   0.8s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=130; total time=   5.2s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=60; total time=   1.3s\n",
      "[CV] END .criterion=entropy, max_depth=None, n_estimators=50; total time=   2.7s\n",
      "[CV] END ...criterion=entropy, max_depth=4, n_estimators=250; total time=   2.7s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=180; total time=   5.3s\n",
      "[CV] END ......criterion=gini, max_depth=18, n_estimators=20; total time=   0.9s\n",
      "[CV] END ......criterion=gini, max_depth=18, n_estimators=20; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=210; total time=  12.0s\n",
      "[CV] END ..criterion=log_loss, max_depth=14, n_estimators=70; total time=   2.5s\n",
      "[CV] END ....criterion=entropy, max_depth=8, n_estimators=70; total time=   1.4s\n",
      "[CV] END ..criterion=log_loss, max_depth=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=220; total time=   3.2s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=140; total time=   4.3s\n",
      "[CV] END ....criterion=entropy, max_depth=6, n_estimators=30; total time=   0.4s\n",
      "[CV] END ..criterion=entropy, max_depth=12, n_estimators=160; total time=   5.0s\n",
      "[CV] END ..criterion=log_loss, max_depth=4, n_estimators=100; total time=   1.0s\n",
      "[CV] END ......criterion=gini, max_depth=8, n_estimators=270; total time=   5.2s\n",
      "[CV] END ...criterion=entropy, max_depth=18, n_estimators=80; total time=   3.5s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=100; total time=   1.5s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=280; total time=   4.4s\n",
      "[CV] END ...criterion=log_loss, max_depth=8, n_estimators=60; total time=   1.2s\n",
      "[CV] END ......criterion=gini, max_depth=12, n_estimators=10; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=14, n_estimators=250; total time=   8.6s\n",
      "[CV] END .criterion=log_loss, max_depth=16, n_estimators=220; total time=   8.9s\n",
      "[CV] END .....criterion=gini, max_depth=14, n_estimators=190; total time=   6.8s\n",
      "[CV] END ...criterion=entropy, max_depth=4, n_estimators=160; total time=   1.7s\n",
      "[CV] END ......criterion=gini, max_depth=6, n_estimators=200; total time=   3.0s\n",
      "[CV] END ......criterion=gini, max_depth=10, n_estimators=70; total time=   1.7s\n",
      "[CV] END ......criterion=gini, max_depth=14, n_estimators=60; total time=   2.1s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=100; total time=   3.4s\n",
      "[CV] END ..criterion=entropy, max_depth=18, n_estimators=150; total time=   6.8s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=250; total time=   3.8s\n",
      "[CV] END criterion=log_loss, max_depth=None, n_estimators=260; total time=  14.7s\n",
      "[CV] END .......criterion=gini, max_depth=6, n_estimators=40; total time=   0.6s\n",
      "[CV] END .......criterion=gini, max_depth=6, n_estimators=40; total time=   0.7s\n",
      "[CV] END .......criterion=gini, max_depth=6, n_estimators=20; total time=   0.3s\n",
      "[CV] END .......criterion=gini, max_depth=6, n_estimators=20; total time=   0.4s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=290; total time=   4.8s\n",
      "[CV] END ....criterion=entropy, max_depth=4, n_estimators=60; total time=   0.7s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=300; total time=   5.2s\n",
      "[CV] END ..criterion=entropy, max_depth=10, n_estimators=220; total time=   6.1s\n",
      "[CV] END ......criterion=gini, max_depth=18, n_estimators=10; total time=   0.5s\n",
      "[CV] END ..criterion=entropy, max_depth=14, n_estimators=130; total time=   5.3s\n",
      "[CV] END ..criterion=entropy, max_depth=16, n_estimators=160; total time=   6.9s\n",
      "[CV] END ......criterion=gini, max_depth=8, n_estimators=130; total time=   2.8s\n",
      "[CV] END ......criterion=gini, max_depth=8, n_estimators=180; total time=   3.9s\n",
      "[CV] END ......criterion=gini, max_depth=12, n_estimators=50; total time=   1.8s\n",
      "[CV] END ...criterion=gini, max_depth=None, n_estimators=180; total time=   9.9s\n",
      "[CV] END ......criterion=gini, max_depth=4, n_estimators=120; total time=   1.3s\n",
      "[CV] END .criterion=log_loss, max_depth=14, n_estimators=130; total time=   5.5s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=170; total time=  10.2s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=110; total time=   3.4s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=100; total time=   3.1s\n",
      "[CV] END .....criterion=gini, max_depth=18, n_estimators=140; total time=   6.1s\n",
      "[CV] END ..criterion=entropy, max_depth=12, n_estimators=180; total time=   6.0s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=180; total time=   7.3s\n",
      "[CV] END ..criterion=log_loss, max_depth=4, n_estimators=170; total time=   1.9s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=120; total time=   4.8s\n",
      "[CV] END .criterion=log_loss, max_depth=10, n_estimators=100; total time=   2.7s\n",
      "[CV] END ......criterion=gini, max_depth=4, n_estimators=190; total time=   1.9s\n",
      "[CV] END ...criterion=entropy, max_depth=14, n_estimators=10; total time=   0.4s\n",
      "[CV] END ..criterion=log_loss, max_depth=12, n_estimators=90; total time=   2.8s\n",
      "[CV] END ....criterion=gini, max_depth=None, n_estimators=80; total time=   3.6s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=110; total time=   3.2s\n",
      "[CV] END .....criterion=gini, max_depth=18, n_estimators=180; total time=   7.4s\n",
      "[CV] END ...criterion=entropy, max_depth=4, n_estimators=210; total time=   2.1s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=290; total time=  15.2s\n",
      "[CV] END criterion=log_loss, max_depth=None, n_estimators=170; total time=   9.1s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=190; total time=   6.9s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=270; total time=   3.7s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=200; total time=   2.8s\n",
      "[CV] END ..criterion=log_loss, max_depth=4, n_estimators=300; total time=   2.9s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=70; total time=   1.3s\n",
      "[CV] END .....criterion=gini, max_depth=18, n_estimators=220; total time=   8.7s\n",
      "[CV] END ..criterion=entropy, max_depth=14, n_estimators=210; total time=   7.6s\n",
      "[CV] END criterion=log_loss, max_depth=None, n_estimators=270; total time=  13.6s\n",
      "[CV] END ...criterion=gini, max_depth=None, n_estimators=200; total time=   8.8s\n",
      "[CV] END ...criterion=entropy, max_depth=14, n_estimators=70; total time=   2.4s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=150; total time=   2.3s\n",
      "[CV] END .....criterion=gini, max_depth=10, n_estimators=200; total time=   5.1s\n",
      "[CV] END ..criterion=entropy, max_depth=10, n_estimators=240; total time=   6.7s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=220; total time=  12.5s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=200; total time=   6.2s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=80; total time=   1.6s\n",
      "[CV] END ...criterion=entropy, max_depth=8, n_estimators=230; total time=   5.1s\n",
      "[CV] END ...criterion=entropy, max_depth=8, n_estimators=270; total time=   5.9s\n",
      "[CV] END ......criterion=gini, max_depth=6, n_estimators=100; total time=   1.5s\n",
      "[CV] END ..criterion=log_loss, max_depth=16, n_estimators=90; total time=   3.9s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=290; total time=  11.4s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=300; total time=  12.0s\n",
      "[CV] END ......criterion=gini, max_depth=8, n_estimators=190; total time=   3.9s\n",
      "[CV] END .criterion=log_loss, max_depth=10, n_estimators=280; total time=   7.6s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=210; total time=   7.2s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=120; total time=   4.1s\n",
      "[CV] END .criterion=log_loss, max_depth=14, n_estimators=150; total time=   5.7s\n",
      "[CV] END ......criterion=gini, max_depth=4, n_estimators=240; total time=   2.5s\n",
      "[CV] END ...criterion=entropy, max_depth=8, n_estimators=220; total time=   4.5s\n",
      "[CV] END ...criterion=entropy, max_depth=12, n_estimators=70; total time=   2.3s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=40; total time=   0.8s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=40; total time=   0.8s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=40; total time=   0.9s\n",
      "[CV] END .....criterion=gini, max_depth=16, n_estimators=130; total time=   5.1s\n",
      "[CV] END .......criterion=gini, max_depth=8, n_estimators=60; total time=   1.2s\n",
      "[CV] END .criterion=entropy, max_depth=None, n_estimators=50; total time=   2.4s\n",
      "[CV] END ...criterion=entropy, max_depth=4, n_estimators=250; total time=   2.6s\n",
      "[CV] END .....criterion=gini, max_depth=12, n_estimators=180; total time=   5.6s\n",
      "[CV] END ..criterion=log_loss, max_depth=10, n_estimators=40; total time=   1.1s\n",
      "[CV] END criterion=entropy, max_depth=None, n_estimators=210; total time=  11.9s\n",
      "[CV] END ..criterion=log_loss, max_depth=14, n_estimators=70; total time=   2.7s\n",
      "[CV] END ...criterion=log_loss, max_depth=6, n_estimators=10; total time=   0.2s\n",
      "[CV] END ...criterion=log_loss, max_depth=6, n_estimators=10; total time=   0.2s\n",
      "[CV] END ....criterion=entropy, max_depth=8, n_estimators=70; total time=   1.5s\n",
      "[CV] END ..criterion=log_loss, max_depth=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=220; total time=   3.4s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=140; total time=   4.4s\n",
      "[CV] END ....criterion=entropy, max_depth=6, n_estimators=30; total time=   0.4s\n",
      "[CV] END ..criterion=entropy, max_depth=12, n_estimators=160; total time=   5.2s\n",
      "[CV] END ..criterion=log_loss, max_depth=4, n_estimators=100; total time=   1.0s\n",
      "[CV] END ......criterion=gini, max_depth=8, n_estimators=270; total time=   5.3s\n",
      "[CV] END ...criterion=entropy, max_depth=18, n_estimators=80; total time=   3.7s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=100; total time=   1.5s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=280; total time=   4.2s\n",
      "[CV] END ...criterion=log_loss, max_depth=8, n_estimators=60; total time=   1.3s\n",
      "[CV] END ......criterion=gini, max_depth=12, n_estimators=10; total time=   0.3s\n",
      "[CV] END .....criterion=gini, max_depth=14, n_estimators=250; total time=   8.8s\n",
      "[CV] END .criterion=log_loss, max_depth=16, n_estimators=220; total time=   8.9s\n",
      "[CV] END .....criterion=gini, max_depth=14, n_estimators=190; total time=   6.5s\n",
      "[CV] END ...criterion=entropy, max_depth=4, n_estimators=160; total time=   1.6s\n",
      "[CV] END ......criterion=gini, max_depth=6, n_estimators=200; total time=   3.1s\n",
      "[CV] END ......criterion=gini, max_depth=10, n_estimators=70; total time=   1.9s\n",
      "[CV] END ......criterion=gini, max_depth=14, n_estimators=60; total time=   2.1s\n",
      "[CV] END .criterion=log_loss, max_depth=12, n_estimators=100; total time=   3.4s\n",
      "[CV] END ..criterion=entropy, max_depth=18, n_estimators=150; total time=   7.0s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=250; total time=   3.9s\n",
      "[CV] END criterion=log_loss, max_depth=None, n_estimators=260; total time=  15.1s\n",
      "[CV] END .......criterion=gini, max_depth=6, n_estimators=40; total time=   0.7s\n",
      "[CV] END ..criterion=log_loss, max_depth=6, n_estimators=290; total time=   4.8s\n",
      "[CV] END ....criterion=entropy, max_depth=4, n_estimators=60; total time=   0.7s\n",
      "[CV] END ...criterion=entropy, max_depth=6, n_estimators=300; total time=   5.3s\n",
      "[CV] END ..criterion=entropy, max_depth=10, n_estimators=220; total time=   5.8s\n",
      "[CV] END ......criterion=gini, max_depth=18, n_estimators=10; total time=   0.4s\n",
      "[CV] END ......criterion=gini, max_depth=18, n_estimators=10; total time=   0.5s\n",
      "[CV] END ..criterion=entropy, max_depth=14, n_estimators=130; total time=   5.1s\n",
      "[CV] END ..criterion=entropy, max_depth=16, n_estimators=160; total time=   6.9s\n",
      "[CV] END ......criterion=gini, max_depth=8, n_estimators=130; total time=   2.7s\n",
      "[CV] END ......criterion=gini, max_depth=8, n_estimators=180; total time=   3.8s\n",
      "[CV] END ..criterion=entropy, max_depth=18, n_estimators=140; total time=   6.7s\n",
      "Melhores hiperparâmetros: {'n_estimators': 220, 'max_depth': 18, 'criterion': 'entropy'}\n",
      "Melhor acurácia: 0.596105493083084\n"
     ]
    }
   ],
   "source": [
    "model_forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': list(range(10,301,10)),\n",
    "    'max_depth': [4, 6, 8, 10, 12, 14, 16, 18, None],\n",
    "    'criterion': ['gini', 'entropy', 'log_loss']\n",
    "}\n",
    "\n",
    "# Executar a busca em grade\n",
    "# Configurando o RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model_forest,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter= 150,  # Número de combinações aleatórias para testar\n",
    "    scoring='accuracy',  # Métrica para avaliar os modelos\n",
    "    n_jobs=10,  # Utiliza todos os processadores disponíveis\n",
    "    cv=10,  # Validação cruzada\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Ajustando o modelo aos dados\n",
    "random_search.fit(X_train_norma, y_train)\n",
    "\n",
    "# Exibindo os melhores hiperparâmetros encontrados\n",
    "print(f\"Melhores hiperparâmetros: {random_search.best_params_}\")\n",
    "print(f\"Melhor acurácia: {random_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc35939d-8cad-4bf2-b01d-004822e7039d",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0f5dbc88-f10b-4180-98cc-07bf2453ad45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 150 candidates, totalling 1500 fits\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l2; total time=   0.5s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ...................C=15, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END ...................C=15, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END ...................C=17, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l2; total time=   0.5s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ...................C=20, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=10, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=5, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=7, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=7, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.75, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=10, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END ...................C=12, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END ...................C=15, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l2; total time=   0.5s\n",
      "[CV] END ...................C=17, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=10, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=5, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=7, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ....................C=0.5, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=0.5, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ......................C=1, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .................C=0.75, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.75, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=10, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=10, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=10, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=10, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=10, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=10, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=10, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END ...................C=10, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=10, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=10, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END ...................C=17, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ...................C=20, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=10, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=5, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END ...................C=10, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=3, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=3, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=3, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=3, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=3, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=3, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=12, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END ...................C=15, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l2; total time=   0.5s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l2; total time=   0.5s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END ...................C=20, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=10, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=5, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=1.5, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=1.5, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=1.5, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ....................C=1.5, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=1.5, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=1.5, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=1.5, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ....................C=3, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=3, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=3, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=3, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=3, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=3, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=3, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=3, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END ....................C=7, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END ...................C=12, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l2; total time=   0.5s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l2; total time=   0.5s\n",
      "[CV] END ...................C=15, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=10, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=5, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=7, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END ....................C=0.5, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=3, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=3, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=3, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=3, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=10, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=10, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=10, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=10, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=10, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=10, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=10, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=5, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=7, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END ....................C=0.5, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=0.5, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ..................C=1.5, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.75, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.75, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.75, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.75, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.75, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.75, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.75, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.75, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=0.5, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=0.5, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=0.5, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=0.5, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ...................C=0.75, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.75, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.75, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.75, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ...................C=0.75, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.75, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=20, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l2; total time=   0.5s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END ...................C=20, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=10, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=5, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .................C=0.75, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.75, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.75, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.75, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=7, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ....................C=0.5, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=0.5, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=10, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=10, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=10, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=10, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=1, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.25, max_iter=300, penalty=l2; total time=   0.1s\n",
      "[CV] END ...................C=0.25, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.25, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.25, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.25, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.25, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.25, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=12, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=3, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=3, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END ......................C=3, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END ....................C=1, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l2; total time=   0.5s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l2; total time=   0.1s\n",
      "[CV] END .....................C=10, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=300, penalty=l2; total time=   0.5s\n",
      "[CV] END ......................C=5, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.75, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.75, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.75, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.75, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.75, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.75, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.75, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.25, max_iter=300, penalty=l2; total time=   0.1s\n",
      "[CV] END ...................C=0.25, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END .................C=0.75, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.75, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.75, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.75, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.75, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.75, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.75, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.75, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.75, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.75, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l2; total time=   0.5s\n",
      "[CV] END ......................C=1, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END ....................C=1.5, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ....................C=1.5, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END .................C=0.75, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.75, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.75, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.75, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.75, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.75, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.75, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.75, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.75, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l2; total time=   0.5s\n",
      "[CV] END ...................C=20, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=10, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=5, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .................C=0.75, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.75, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ....................C=0.5, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=0.5, max_iter=400, penalty=l2; total time=   0.1s\n",
      "[CV] END ...................C=0.25, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=5, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=5, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=5, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=5, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=5, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=5, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=5, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=5, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=5, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END ...................C=15, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l2; total time=   0.5s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ....................C=7, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ......................C=3, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END ...................C=15, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ....................C=3, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=3, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=3, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=3, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=3, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=3, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=3, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=3, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=3, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=3, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=10, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=10, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=10, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=10, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=10, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=10, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .................C=0.25, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l2; total time=   0.5s\n",
      "[CV] END .................C=0.25, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ....................C=1.5, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ....................C=1.5, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=1.5, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=1.5, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=1.5, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ....................C=1.5, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ....................C=1.5, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ..................C=0.5, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=0.5, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=0.5, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=0.5, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=0.5, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=0.5, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=0.5, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=0.5, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=0.5, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=0.5, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END ....................C=1.5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=7, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=7, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=7, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=200, penalty=l2; total time=   0.1s\n",
      "[CV] END ....................C=0.5, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=0.5, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=0.5, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=0.5, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=0.5, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=0.5, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=0.25, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.25, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.25, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.25, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.25, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.25, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.25, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.25, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=12, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END ....................C=7, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END .................C=0.25, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=0.75, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.75, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.75, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.75, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.75, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ...................C=0.75, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.75, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.75, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.75, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.75, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ......................C=1, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ......................C=1, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ......................C=1, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ......................C=1, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ......................C=1, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=1, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=1, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ......................C=1, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=1, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ......................C=1, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.25, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.25, max_iter=400, penalty=l2; total time=   0.1s\n",
      "[CV] END ...................C=0.25, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.25, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.25, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.25, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.25, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.25, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.25, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.25, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END ......................C=1, max_iter=400, penalty=l2; total time=   0.2s\n",
      "Melhores hiperparâmetros: {'penalty': 'l2', 'max_iter': 400, 'C': 0.5}\n",
      "Melhor acurácia: 0.5981582627387982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thiago/lsbd/steel_2024/venv-steel/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "990 fits failed out of a total of 1500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "510 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/thiago/lsbd/steel_2024/venv-steel/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/thiago/lsbd/steel_2024/venv-steel/lib/python3.11/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/thiago/lsbd/steel_2024/venv-steel/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/thiago/lsbd/steel_2024/venv-steel/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "140 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/thiago/lsbd/steel_2024/venv-steel/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/thiago/lsbd/steel_2024/venv-steel/lib/python3.11/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/home/thiago/lsbd/steel_2024/venv-steel/lib/python3.11/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/thiago/lsbd/steel_2024/venv-steel/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l2', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "106 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/thiago/lsbd/steel_2024/venv-steel/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/thiago/lsbd/steel_2024/venv-steel/lib/python3.11/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/home/thiago/lsbd/steel_2024/venv-steel/lib/python3.11/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/thiago/lsbd/steel_2024/venv-steel/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'elasticnet', 'l2'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "124 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/thiago/lsbd/steel_2024/venv-steel/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/thiago/lsbd/steel_2024/venv-steel/lib/python3.11/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/home/thiago/lsbd/steel_2024/venv-steel/lib/python3.11/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/thiago/lsbd/steel_2024/venv-steel/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'l2', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "47 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/thiago/lsbd/steel_2024/venv-steel/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/thiago/lsbd/steel_2024/venv-steel/lib/python3.11/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/home/thiago/lsbd/steel_2024/venv-steel/lib/python3.11/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/thiago/lsbd/steel_2024/venv-steel/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'elasticnet', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "63 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/thiago/lsbd/steel_2024/venv-steel/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/thiago/lsbd/steel_2024/venv-steel/lib/python3.11/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/home/thiago/lsbd/steel_2024/venv-steel/lib/python3.11/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/thiago/lsbd/steel_2024/venv-steel/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l1', 'l2'} or None. Got 'none' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/thiago/lsbd/steel_2024/venv-steel/lib/python3.11/site-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n",
      "/home/thiago/lsbd/steel_2024/venv-steel/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1102: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.59618206 0.59618206        nan        nan\n",
      " 0.59602991        nan        nan 0.59519352 0.59815826        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.59755053        nan        nan 0.59671426        nan 0.59595392\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.59488917        nan        nan        nan        nan 0.59618206\n",
      "        nan        nan        nan 0.59815826        nan        nan\n",
      "        nan        nan 0.59572579 0.59488917        nan 0.59572596\n",
      "        nan        nan 0.59656148        nan 0.59602991        nan\n",
      "        nan 0.59815826 0.59564957 0.59656148        nan        nan\n",
      "        nan        nan 0.59572579        nan        nan 0.59755053\n",
      " 0.59717007        nan 0.59755053        nan 0.59572596        nan\n",
      "        nan        nan 0.59564957 0.59519352        nan 0.59572596\n",
      " 0.59572579 0.59618206        nan        nan 0.59564957        nan\n",
      " 0.59564957        nan        nan        nan        nan        nan\n",
      " 0.59671426        nan        nan        nan 0.59755053 0.59717007\n",
      " 0.59656148 0.59717007 0.59572579        nan 0.59602991        nan\n",
      "        nan        nan        nan        nan 0.59815826        nan\n",
      " 0.59519352        nan        nan        nan        nan 0.59519352\n",
      "        nan        nan 0.59595392        nan        nan        nan\n",
      " 0.59572596        nan        nan        nan        nan 0.59671426\n",
      "        nan 0.59602991        nan        nan        nan        nan\n",
      " 0.59717007        nan 0.59656148 0.59671426 0.59488917 0.59595392\n",
      "        nan        nan        nan        nan 0.59488917        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_logistic = LogisticRegression()\n",
    "\n",
    "param_grid = {\n",
    "    'C': [ 0.25, 0.5, 0.75, 1, 1.5, 3, 5 , 7, 10, 12 ,15, 17, 20],\n",
    "    'penalty': ['l1', 'l2', 'none'],  \n",
    "    'max_iter': [200, 300, 400, 500]\n",
    "}\n",
    "\n",
    "\n",
    "# Executar a busca em grade\n",
    "# Configurando o RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model_logistic,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter= 150,  # Número de combinações aleatórias para testar\n",
    "    scoring='accuracy',  # Métrica para avaliar os modelos\n",
    "    n_jobs=10,  # Utiliza todos os processadores disponíveis\n",
    "    cv=10,  # Validação cruzada\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Ajustando o modelo aos dados\n",
    "random_search.fit(X_train_norma, y_train)\n",
    "\n",
    "# Exibindo os melhores hiperparâmetros encontrados\n",
    "print(f\"Melhores hiperparâmetros: {random_search.best_params_}\")\n",
    "print(f\"Melhor acurácia: {random_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137d90fa-5b0d-44bc-b574-db4df2092d1a",
   "metadata": {},
   "source": [
    "## SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "172875b3-26e8-48b1-adcb-0076a7bf5657",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 150 candidates, totalling 1500 fits\n",
      "[CV] END ......................C=5, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ....................C=5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=10, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=10, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=10, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=10, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ...................C=10, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=10, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=10, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=10, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=10, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=10, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=10, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ...................C=12, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=12, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END ...................C=12, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l2; total time=   0.5s\n",
      "[CV] END ...................C=15, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END ...................C=17, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END ......................C=7, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=7, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END ....................C=7, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=7, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=7, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ....................C=7, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=10, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=10, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ...................C=12, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END ...................C=15, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l2; total time=   0.5s\n",
      "[CV] END ...................C=15, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=17, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END ...................C=20, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=optimal, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=optimal, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=1, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END ..................C=1.5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END ......................C=5, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=5, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=5, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=5, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=5, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=5, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=5, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=5, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=10, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=10, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END ...................C=10, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=10, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=10, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=10, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=10, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=10, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=10, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=10, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=10, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END ...................C=12, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l2; total time=   0.5s\n",
      "[CV] END ...................C=15, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l2; total time=   0.1s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l2; total time=   0.1s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.2s\n",
      "[CV] END ......................C=5, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=5, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=5, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END ....................C=5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=5, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=10, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=10, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=10, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=10, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ...................C=10, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=12, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l2; total time=   0.5s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l2; total time=   0.1s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l2; total time=   0.1s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l2; total time=   0.1s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END ..................C=1.5, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ..................C=1.5, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=3, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END ....................C=3, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=3, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=3, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=3, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=3, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=3, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ......................C=3, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ....................C=3, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=3, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=7, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=7, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=7, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=10, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END ...................C=10, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END ...................C=20, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l2; total time=   0.2s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=optimal, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=optimal, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.4s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................C=1.5, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ....................C=1.5, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=1.5, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=1.5, max_iter=200, penalty=l2; total time=   0.2s\n",
      "[CV] END ....................C=1.5, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ....................C=1.5, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=3, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=3, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END ....................C=7, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ....................C=7, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END ......................C=7, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=12, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ...................C=12, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END ...................C=20, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=optimal, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=optimal, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END .....................C=12, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=300, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=12, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=12, max_iter=300, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=12, max_iter=300, penalty=l2; total time=   0.3s\n",
      "[CV] END ...................C=15, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=300, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=400, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=15, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ...................C=17, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ...................C=17, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.3s\n",
      "[CV] END ...................C=12, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=12, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=12, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END ...................C=15, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=15, max_iter=500, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ...................C=17, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=17, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END ...................C=20, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=200, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=optimal, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=optimal, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=20, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END ...................C=20, max_iter=400, penalty=none; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=20, max_iter=500, penalty=l2; total time=   0.3s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=optimal, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=optimal, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=optimal, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=optimal, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=optimal, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=optimal, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.2s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l1; total time=   0.0s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=15, max_iter=200, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l2; total time=   0.3s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=17, max_iter=400, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=optimal, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=optimal, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=optimal, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=optimal, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=optimal, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=optimal, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=optimal, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=optimal, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=optimal, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=optimal, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.4s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.4s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=optimal, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=optimal, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.5s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.5s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=optimal, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=optimal, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=optimal, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=optimal, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=3000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.5s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.5s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=optimal, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=optimal, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=optimal, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=optimal, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.4s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.5s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=optimal, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=optimal, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.4s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.4s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.4s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.3s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.4s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.4s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=optimal, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=optimal, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "Melhores hiperparâmetros: {'penalty': 'l1', 'max_iter': 1000, 'learning_rate': 'optimal', 'eta0': 1.0, 'alpha': 0.0001}\n",
      "Melhor acurácia: 0.5907853617945843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thiago/lsbd/steel_2024/venv-steel/lib/python3.11/site-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.4s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=optimal, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=optimal, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=optimal, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=optimal, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.4s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.4s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.5s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.4s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=optimal, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=optimal, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.4s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=optimal, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=optimal, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=optimal, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=optimal, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=adaptive, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.4s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=invscaling, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=invscaling, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=optimal, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=optimal, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=optimal, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l1; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=optimal, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=constant, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=invscaling, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, eta0=0.1, learning_rate=invscaling, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.0001, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.1, eta0=0.1, learning_rate=adaptive, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.001, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=l1; total time=   0.3s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=1.0, learning_rate=constant, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=constant, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=invscaling, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.4s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, eta0=1.0, learning_rate=constant, max_iter=2000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.001, eta0=0.1, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.01, eta0=0.01, learning_rate=adaptive, max_iter=2000, penalty=elasticnet; total time=   0.2s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.3s\n",
      "[CV] END alpha=0.0001, eta0=1.0, learning_rate=optimal, max_iter=1000, penalty=elasticnet; total time=   0.1s\n"
     ]
    }
   ],
   "source": [
    "model_sgdc = SGDClassifier(random_state=42)\n",
    "\n",
    "# Definindo o grid de hiperparâmetros\n",
    "param_grid = {\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],  # Tipos de regularização\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1],  # Força da regularização\n",
    "    'max_iter': [1000, 2000, 3000],  # Número máximo de iterações\n",
    "    'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],  # Estratégias de ajuste da taxa de aprendizado\n",
    "    'eta0': [0.01, 0.1, 1.0]  # Taxa de aprendizado inicial\n",
    "}\n",
    "\n",
    "# Executar a busca em grade\n",
    "# Configurando o RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model_sgdc,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter= 150,  # Número de combinações aleatórias para testar\n",
    "    scoring='accuracy',  # Métrica para avaliar os modelos\n",
    "    n_jobs=10,  # Utiliza todos os processadores disponíveis\n",
    "    cv=10,  # Validação cruzada\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Ajustando o modelo aos dados\n",
    "random_search.fit(X_train_norma, y_train)\n",
    "\n",
    "# Exibindo os melhores hiperparâmetros encontrados\n",
    "print(f\"Melhores hiperparâmetros: {random_search.best_params_}\")\n",
    "print(f\"Melhor acurácia: {random_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a13fc96-51eb-4dff-9ec4-2f4674d8f247",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "158e7fec-0928-4b8e-a78f-13b8ef692e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-12 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-12 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-12 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-12 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-12 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-12 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-12 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-12 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-12 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-12 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=0.1, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=0.1, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=42, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, gamma=0.1, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=42, ...)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(eval_metric='logloss', objective='binary:logistic', random_state=42, tree_method = 'approx', subsample = 0.6, \n",
    "reg_lambda = 1.5, reg_alpha = 0.1, n_estimators = 300, max_depth = 5, learning_rate = 0.01, gamma = 0.1, colsample_bytree = 1.0)\n",
    "\n",
    "xgb_model.fit(X_train_norma, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0ccc643c-f29d-4873-811e-1b963802ab8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-10 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-10 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-10 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-10 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-10 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-10 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-10 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-10 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-10 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=18, n_estimators=220,\n",
       "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=18, n_estimators=220,\n",
       "                       random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=18, n_estimators=220,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomForestClassifier\n",
    "\n",
    "model_forest = RandomForestClassifier(random_state=42, n_estimators = 220, max_depth = 18, criterion = 'entropy')\n",
    "\n",
    "model_forest.fit(X_train_norma, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "53a3d2d1-dad5-4768-94bb-c9318b63eabe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-11 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-11 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-11 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-11 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-11 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-11 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-11 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-11 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-11 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-11 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.5, max_iter=400)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=0.5, max_iter=400)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.5, max_iter=400)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LogisticRegression\n",
    "model_logistic = LogisticRegression(penalty = 'l2', max_iter = 400, C = 0.5)\n",
    "model_logistic.fit(X_train_norma, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8200bf15-dcf7-4da6-a4f9-f1a0f629c81a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-13 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-13 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-13 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-13 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-13 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-13 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-13 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-13 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-13 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-13 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-13 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-13 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier(eta0=1.0, penalty=&#x27;l1&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SGDClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.SGDClassifier.html\">?<span>Documentation for SGDClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SGDClassifier(eta0=1.0, penalty=&#x27;l1&#x27;, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SGDClassifier(eta0=1.0, penalty='l1', random_state=42)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sgdc = SGDClassifier(random_state=42, penalty = 'l1', max_iter = 1000, learning_rate = 'optimal', eta0 = 1.0, alpha = 0.0001)\n",
    "model_sgdc.fit(X_train_norma, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dec1205-efbb-49f0-926a-e6d43a6bd7a9",
   "metadata": {},
   "source": [
    "# Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "54bde6ab-8b84-4185-b1cc-060c0fb97e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_norma =  pd.DataFrame(scaler.fit_transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbb6f0b-d4dc-4d9c-a372-6fd330877e38",
   "metadata": {},
   "source": [
    "## XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8e894c8e-4fd8-4b8a-89dc-bfe3a1f6adad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.5922772879294619\n",
      "Revocação: 0.827349524815206\n",
      "Precisão: 0.6071290197597831\n",
      "F1-score: 0.7003351955307262\n"
     ]
    }
   ],
   "source": [
    "y_pred_xgb = xgb_model.predict(X_test_norma)\n",
    "\n",
    "print(\"Acurácia:\", accuracy_score(y_test, y_pred_xgb))\n",
    "print(\"Revocação:\", recall_score(y_test, y_pred_xgb))\n",
    "print(\"Precisão:\", precision_score(y_test, y_pred_xgb))\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "523f801f-dd31-4834-9936-fa3f238240a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_proba = xgb_model.predict_proba(X_test_norma)[:, 1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba) \n",
    "roc_auc = auc(fpr, tpr)\n",
    "# Plot the ROC curve\n",
    "plt.figure()  \n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='No Skill')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "beece1f4-3413-4b62-b611-6da496a80c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "average_precision = average_precision_score(y_test, y_pred_proba)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall, precision, color='blue', lw=2, label=f'Precision-Recall curve (AP = {average_precision:.2f})')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"lower left\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "03edb491-05df-4a60-90aa-8712a763fd4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_xgb)\n",
    "\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = [0, 1])\n",
    "\n",
    "cm_display.plot()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a44adef7-bb52-4526-9092-48816712ffcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X_train.columns\n",
    "\n",
    "importances = xgb_model.feature_importances_\n",
    "\n",
    "feature_importances = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3ccdedcc-5e2e-4000-a18f-da1ebb8d0908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>team_1_ws</td>\n",
       "      <td>0.043041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>team_2_ws</td>\n",
       "      <td>0.032461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>team_1_mp</td>\n",
       "      <td>0.019036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>team_2_ts_pct</td>\n",
       "      <td>0.017644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>team_1_off_rtg</td>\n",
       "      <td>0.017399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>team_2_fg3a_per_fga_pct</td>\n",
       "      <td>0.017278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>team_2_off_rtg</td>\n",
       "      <td>0.017157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>team_2_efg_pct</td>\n",
       "      <td>0.016888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>team_1_def_rtg</td>\n",
       "      <td>0.016457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>team_1_tov</td>\n",
       "      <td>0.016433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Feature  Importance\n",
       "33                team_1_ws    0.043041\n",
       "67                team_2_ws    0.032461\n",
       "0                 team_1_mp    0.019036\n",
       "53            team_2_ts_pct    0.017644\n",
       "31           team_1_off_rtg    0.017399\n",
       "55  team_2_fg3a_per_fga_pct    0.017278\n",
       "65           team_2_off_rtg    0.017157\n",
       "54           team_2_efg_pct    0.016888\n",
       "32           team_1_def_rtg    0.016457\n",
       "16               team_1_tov    0.016433"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9f44823e-2aef-4b9a-b2fb-7dd7949a8311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>team_1_pf</td>\n",
       "      <td>0.013155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>team_2_fta</td>\n",
       "      <td>0.013042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>team_1_fta</td>\n",
       "      <td>0.012832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>team_1_ft</td>\n",
       "      <td>0.012060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>team_1_fg3</td>\n",
       "      <td>0.011839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>team_2_trb</td>\n",
       "      <td>0.011743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>team_1_orb</td>\n",
       "      <td>0.011368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>team_2_stl</td>\n",
       "      <td>0.009900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>team_1_usg_pct</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>team_2_usg_pct</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Feature  Importance\n",
       "17       team_1_pf    0.013155\n",
       "42      team_2_fta    0.013042\n",
       "8       team_1_fta    0.012832\n",
       "7        team_1_ft    0.012060\n",
       "4       team_1_fg3    0.011839\n",
       "46      team_2_trb    0.011743\n",
       "10      team_1_orb    0.011368\n",
       "48      team_2_stl    0.009900\n",
       "30  team_1_usg_pct    0.000000\n",
       "64  team_2_usg_pct    0.000000"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances.iloc[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78369a4a-5c8b-43d3-a101-119d45bfa595",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "48ec7002-3fd1-44fa-af0e-702444c86ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.5831559744603223\n",
      "Revocação: 0.8247096092925026\n",
      "Precisão: 0.6005382545174933\n",
      "F1-score: 0.6949944382647386\n"
     ]
    }
   ],
   "source": [
    "y_pred_forest = model_forest.predict(X_test_norma)\n",
    "\n",
    "print(\"Acurácia:\", accuracy_score(y_test, y_pred_forest))\n",
    "print(\"Revocação:\", recall_score(y_test, y_pred_forest))\n",
    "print(\"Precisão:\", precision_score(y_test, y_pred_forest))\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8539acf6-e609-4d46-9326-64e2f2231e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_proba = model_forest.predict_proba(X_test_norma)[:, 1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba) \n",
    "roc_auc = auc(fpr, tpr)\n",
    "# Plot the ROC curve\n",
    "plt.figure()  \n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='No Skill')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9f6aa639-b842-4293-ba22-e9f0824da052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "average_precision = average_precision_score(y_test, y_pred_proba)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall, precision, color='blue', lw=2, label=f'Precision-Recall curve (AP = {average_precision:.2f})')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"lower left\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "626e3ae9-a83c-4d0b-9595-423a9476aff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_forest)\n",
    "\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = [0, 1])\n",
    "\n",
    "cm_display.plot()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4317a60-2da8-4ab2-808f-6791a1c56d27",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6de087da-be9e-4989-93a8-98b5d826ec6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.5974460322286409\n",
      "Revocação: 0.7412882787750792\n",
      "Precisão: 0.6273458445040214\n",
      "F1-score: 0.6795740561471443\n"
     ]
    }
   ],
   "source": [
    "y_pred_logistic = model_logistic.predict(X_test_norma)\n",
    "\n",
    "print(\"Acurácia:\", accuracy_score(y_test, y_pred_logistic))\n",
    "print(\"Revocação:\", recall_score(y_test, y_pred_logistic))\n",
    "print(\"Precisão:\", precision_score(y_test, y_pred_logistic))\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred_logistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3ce65a4a-f7bc-4e7b-adf6-7f387c18baa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_proba = model_logistic.predict_proba(X_test_norma)[:, 1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba) \n",
    "roc_auc = auc(fpr, tpr)\n",
    "# Plot the ROC curve\n",
    "plt.figure()  \n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='No Skill')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d3b5de96-2775-4255-9525-34d72203ce6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "average_precision = average_precision_score(y_test, y_pred_proba)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall, precision, color='blue', lw=2, label=f'Precision-Recall curve (AP = {average_precision:.2f})')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"lower left\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0ca66b47-0d38-4355-8060-88174dd55d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAG0CAYAAACv/CQHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA6EElEQVR4nO3deXhU5fn/8c9MQhZCFiKQMBgWi6yFoKD5RkWhRLZ+EaotRaOmiFCXuIAiUAUBFQqoYJASd6Q/sNoqfJUqmoIa1DSyGAQMYYewBKQhhARCkpnz+yMyOg0jGWayzXm/rutc7ZzznDP3pClz576f8xyLYRiGAACAaVnrOwAAAFC/SAYAADA5kgEAAEyOZAAAAJMjGQAAwORIBgAAMDmSAQAATI5kAAAAkyMZAADA5EgGAAAwOZIBAABqQWZmpoYNGyabzSaLxaKVK1e6HXvPPffIYrFowYIFLvsLCwuVnJysiIgIRUVFacyYMSopKXEZ8+2336pv374KCQlRXFyc5s6d63GsgR6f0YA4HA4dPnxY4eHhslgs9R0OAMBDhmHo1KlTstlsslpr7+/TsrIylZeXe32doKAghYSE1GhsaWmp4uPjddddd+nmm292O27FihX697//LZvNVu1YcnKyjhw5ooyMDFVUVGj06NEaN26cli9fLkkqLi7WwIEDlZSUpPT0dG3ZskV33XWXoqKiNG7cuJp/MKMRy8/PNySxsbGxsTXyLT8/v9a+K86cOWPEtgrwSZyxsbHGmTNnPI5BkrFixYpq+w8ePGi0adPG2Lp1q9GuXTtj/vz5zmPfffedIclYv369c99HH31kWCwW49ChQ4ZhGMZf/vIXo3nz5sbZs2edYyZNmmR07tzZo/gadWUgPDxcktQvdrQCrUH1HA1QOw79pl19hwDUGnt5mXa8MtP573ltKC8vV8Exu/ZvbK+I8IuvPhSfcqhd7306fvy4IiIinPuDg4MVHBzs8fUcDofuuOMOTZw4Ud27d692PCsrS1FRUerTp49zX1JSkqxWq7Kzs/Wb3/xGWVlZuv766xUU9ON34KBBgzRnzhydOHFCzZs3r1EsjToZONcaCLQGKdDq+f8QQGMQEFyzkiTQmNVFq7dZuEXNwi/+fRyqOjcuLs5l/5NPPqnp06d7fL05c+YoMDBQDz744HmPFxQUqFWrVi77AgMDFR0drYKCAueYDh06uIyJiYlxHjNFMgAAQE3ZDYfshnfnS1J+fn61yoCnNm7cqBdeeEGbNm1qEHPeuJsAAGAKDhleb5IUERHhsl1MMrBu3TodO3ZMbdu2VWBgoAIDA7V//3498sgjat++vSQpNjZWx44dczmvsrJShYWFio2NdY45evSoy5hzr8+NqQmSAQAA6tgdd9yhb7/9Vjk5Oc7NZrNp4sSJ+vjjjyVJiYmJKioq0saNG53nrV27Vg6HQwkJCc4xmZmZqqiocI7JyMhQ586da9wikGgTAABMwiGHHF6e74mSkhLt2rXL+Xrv3r3KyclRdHS02rZtq0suucRlfJMmTRQbG6vOnTtLkrp27arBgwdr7NixSk9PV0VFhVJTUzVq1CjnbYi33XabZsyYoTFjxmjSpEnaunWrXnjhBc2fP9+jWEkGAACmYDcM2Y2LnzTg6bkbNmxQ//79na8nTJggSUpJSdGSJUtqdI1ly5YpNTVVAwYMkNVq1S233KK0tDTn8cjISH3yySe6//771bt3b7Vo0ULTpk3zbI0BkQwAAFAr+vXrJ8ODBGLfvn3V9kVHRzsXGHKnZ8+eWrdunafhuSAZAACYwk8nAV7s+f6KZAAAYAoOGbKTDJwXdxMAAGByVAYAAKZAm8A9kgEAgCnU9d0EjQltAgAATI7KAADAFBw/bN6c769IBgAApmD38m4Cb85t6EgGAACmYDfk5VMLfRdLQ8OcAQAATI7KAADAFJgz4B7JAADAFByyyC6LV+f7K9oEAACYHJUBAIApOIyqzZvz/RXJAADAFOxetgm8Obeho00AAIDJURkAAJgClQH3SAYAAKbgMCxyGF7cTeDFuQ0dbQIAAEyOygAAwBRoE7hHMgAAMAW7rLJ7URC3+zCWhoZkAABgCoaXcwYM5gwAAAB/RWUAAGAKzBlwj2QAAGAKdsMqu+HFnAE/Xo6YNgEAACZHZQAAYAoOWeTw4m9gh/y3NEAyAAAwBeYMuEebAAAAk6MyAAAwBe8nENImAACgUauaM+DFg4poEwAAAH9FZQAAYAoOL59NwN0EAAA0cswZcI9kAABgCg5ZWWfADeYMAABgclQGAACmYDcssnvxGGJvzm3oSAYAAKZg93ICoZ02AQAA8FdUBgAApuAwrHJ4cTeBg7sJAABo3GgTuEebAAAAk6MyAAAwBYe8uyPA4btQGhySAQCAKXi/6JD/FtP995MBAIAaoTIAADAF759N4L9/P5MMAABMwSGLHPJmzgArEAIA0KhRGXDPfz8ZAACoESoDAABT8H7RIf/9+5lkAABgCg7DIoc36wz48VML/TfNAQAANUJlAABgCg4v2wT+vOgQyQAAwBS8f2qh/yYD/vvJAABAjVAZAACYgl0W2b1YOMibcxs6kgEAgCnQJnDPfz8ZAACoESoDAABTsMu7Ur/dd6E0OCQDAABToE3gHskAAMAUeFCRe/77yQAAQI1QGQAAmIIhixxezBkwuLUQAIDGjTaBe/77yQAAQI1QGQAAmAKPMHaPZAAAYAp2L59a6M25DZ3/fjIAAFAjVAYAAKZAm8A9kgEAgCk4ZJXDi4K4N+c2dP77yQAAqEeZmZkaNmyYbDabLBaLVq5c6TxWUVGhSZMmqUePHgoLC5PNZtOdd96pw4cPu1yjsLBQycnJioiIUFRUlMaMGaOSkhKXMd9++6369u2rkJAQxcXFae7cuR7HSjIAADAFu2HxevNEaWmp4uPjtWjRomrHTp8+rU2bNmnq1KnatGmT3nvvPeXl5emmm25yGZecnKxt27YpIyNDq1atUmZmpsaNG+c8XlxcrIEDB6pdu3bauHGj5s2bp+nTp+vll1/2KFbaBAAAU6jrOQNDhgzRkCFDznssMjJSGRkZLvtefPFFXX311Tpw4IDatm2r3NxcrV69WuvXr1efPn0kSQsXLtTQoUP17LPPymazadmyZSovL9frr7+uoKAgde/eXTk5OXr++eddkoYLoTIAADAF44enFl7sZvywAmFxcbHLdvbsWZ/Ed/LkSVksFkVFRUmSsrKyFBUV5UwEJCkpKUlWq1XZ2dnOMddff72CgoKcYwYNGqS8vDydOHGixu9NMgAAgAfi4uIUGRnp3GbPnu31NcvKyjRp0iTdeuutioiIkCQVFBSoVatWLuMCAwMVHR2tgoIC55iYmBiXMedenxtTE7QJAACmYJdFdi8eNnTu3Pz8fOcXtiQFBwd7FVdFRYVGjhwpwzC0ePFir651sUgGAACm4DC8WyvAYVT9Z0REhEsy4I1zicD+/fu1du1al+vGxsbq2LFjLuMrKytVWFio2NhY55ijR4+6jDn3+tyYmqBNAABAPTiXCOzcuVP/+te/dMkll7gcT0xMVFFRkTZu3Ojct3btWjkcDiUkJDjHZGZmqqKiwjkmIyNDnTt3VvPmzWscC5UBk7tt7E4lj9vlsi9/X5ju+d31ztddepzQnffuUOdfnpTDLu3ZEaGpD16l8rMBkqTfj96lq677Xh06Fauywqrf/+rGOv0MwM+xWhy695oN+nW3Hbok7LS+Lw3T+1s76+Ws3tIPZd97rlmvwV12KTa8RBUOq7472lIvrkvQliMx1a7XJMCu/3f7u+rS6j8a+ebvlHesRR1/IlyscxMBvTnfEyUlJdq168d/X/fu3aucnBxFR0erdevW+u1vf6tNmzZp1apVstvtzh5/dHS0goKC1LVrVw0ePFhjx45Venq6KioqlJqaqlGjRslms0mSbrvtNs2YMUNjxozRpEmTtHXrVr3wwguaP3++R7GSDED7djfTE/df7Xxtr/yxjNalxwnNTNugvy+5TOnPdpPdblGHy0/J4fjx/MAmhr74V6xyt0Rp4E0H6zJ04IJGX/2Nftdrm6Z+9CvtPt5c3WK/18whn6rkbJCWb+opSdp/IlKz1/TVwaIIhQRW6vY+m7X4d6s07JXbdOJMqMv1xt+Qpe9LwtSl1X/q4+PACw5Z5PBizoCn527YsEH9+/d3vp4wYYIkKSUlRdOnT9f7778vSerVq5fLeZ9++qn69esnSVq2bJlSU1M1YMAAWa1W3XLLLUpLS3OOjYyM1CeffKL7779fvXv3VosWLTRt2jSPbiuUGkgysGjRIs2bN08FBQWKj4/XwoULdfXVV1/4RPiEw27Rif+cfwLM2PG5ev/tdvr7m79w7ju0v5nLmGUvXy5JSvpfEgE0PL3aHNVnu9pr3Z52kqTDxREa0nWnftn6x17sR7mdXM559tNrdXPP7bq85X/09YFLnfuv7bBfie3z9cj/DVLfyw7UzQdAo9WvXz8ZhuH2+M8dOyc6OlrLly//2TE9e/bUunXrPI7vp+p9zsDbb7+tCRMm6Mknn9SmTZsUHx+vQYMGVZs0gdpjizutpR+u1WsrP9OjT+WoZcwZSVJk87Pq0uOkThYG6dnXsvT/Vq/Rn1/6t7rFF9ZzxEDN5RyK0dXtDqld8yJJUqeWx3VFmwJ9safteccHWu26Jf47FZcFacf3P/Zwo5ue1pODPtfj/xygsooG8XcUPFTXKxA2JvX+G/38889r7NixGj16tCQpPT1d//znP/X6669r8uTJ9Ryd/8vbFqX5M3ro4P4wRbc4q9vG7tLcV/6t+0b1VWyb05Kk28bu0mtpXbQnL1wDfn1Ys/7yte4b1VeH88PqOXrgwl7PvlLNgiu0csxbsjusCrA6tHBdgj78r2rA9Zft05xhGQppUqnjJWG65+/DVORsERh6asha/T2nu7472kq2iOK6/yDwWl3PGWhM6jUZKC8v18aNGzVlyhTnPqvVqqSkJGVlZVUbf/bsWZeVnoqL+T+ktzZ+1dL53/ftkvK2RumNDz5T36Qjyt9X1Q74aEWc/vVBVal0z45IxV/1H91400G9uahzfYQMeGRQl10a2nWHpqxK0q7j0erS6rgm/upLfV/SVB9s6+Ictz6/jUa+OVJRoWd0S89czRv2iW5fdrMKTzfVbVduUVhQhV7LvqIePwlQe+o1GTh+/Ljsdvt5V0/avn17tfGzZ8/WjBkz6io8UyotaaJDB8LUOu60Nm+oKpHm73WdI5C/L0wtY8/UR3iAx8bfkKXXv75Sq7dXzW3ZdfwStY4o0ZiEb1ySgTMVTZRfFKn8okhtORKr9+9erhE9tuv17Ct1VdtD6mk7qvUTXB/+svyOf+jD7y7X1I8G1OlnwsVxyMtnE3gx+bChq/c2gSemTJninI0pVVUG4uLi6jEi/xMSWqnWbU5r7XGbjh4O1fFjwWrTrtRlTJu2pdrwk4oC0JCFNKl0LhZzjt2wyGr5+clbVouhoAC7JGnOmuu06IsfJzW3bHZa6b9bpcc+uFFbDle//RANk+Hl3QQGyUDtaNGihQICAs67etL5Vk4KDg72etlHuBrz0HZlr2upY0dCdUnLs0oet1MOh/T5x60lWfTe/+ug5HG7tHdHuPbsiNCA/z2kS9uVatakH8ulLWPOKDyyQi1jz8hqNXRZp6r2zeH8pio706jyTfihz3e319j/2aSC4nDtPt5cXWKO644+m/V/W6qqAqFNKnT3/2zUZ7va63hpmKJCyzTqiq1q1axUGXlVd9EUnAqXTv14zdPlTSRJB4sidaykWbX3RMNU108tbEzq9V/qoKAg9e7dW2vWrNGIESMkSQ6HQ2vWrFFqamp9hmYal7Qq02NPb1ZEZLlOngjSts3RmjA6UcVFVUnX/73VQUFBDo2dsF3hERXauzNcT6RepYJDP04evP2enUr630PO1wuXfSlJmvzHq7Vlk+uKWkBd+/O/rtP9132tPyVlKrrpGX1fGqZ/bO6ml76qehKc3WFRh+gi3TT8E0WFnlFRWYi2HWml0W+N0O7/RNdz9EDdsBg1udGxFr399ttKSUnRSy+9pKuvvloLFizQO++8o+3bt1ebS/DfiouLFRkZqSTbHxVopWIA/3RwZPv6DgGoNfazZcpd9CedPHnSZ+v9/7dz3xW/yRitJmFBFz7BjYrScq248Y1ajbW+1HsN9/e//72+//57TZs2TQUFBerVq5dWr159wUQAAABP0CZwr96TAUlKTU2lLQAAQD1pEMkAAAC1ra6fTdCYkAwAAEyBNoF7/ru2IgAAqBEqAwAAU6Ay4B7JAADAFEgG3KNNAACAyVEZAACYApUB90gGAACmYMi72wPrdbneWkYyAAAwBSoD7jFnAAAAk6MyAAAwBSoD7pEMAABMgWTAPdoEAACYHJUBAIApUBlwj2QAAGAKhmGR4cUXujfnNnS0CQAAMDkqAwAAU3DI4tWiQ96c29CRDAAATIE5A+7RJgAAwOSoDAAATIEJhO6RDAAATIE2gXskAwAAU6Ay4B5zBgAAMDkqAwAAUzC8bBP4c2WAZAAAYAqGJMPw7nx/RZsAAACTozIAADAFhyyysALheZEMAABMgbsJ3KNNAACAyVEZAACYgsOwyMKiQ+dFMgAAMAXD8PJuAj++nYA2AQAAJkdlAABgCkwgdI9kAABgCiQD7pEMAABMgQmE7jFnAAAAk6MyAAAwBe4mcI9kAABgClXJgDdzBnwYTANDmwAAAJOjMgAAMAXuJnCPZAAAYArGD5s35/sr2gQAAJgclQEAgCnQJnCPZAAAYA70CdwiGQAAmIOXlQH5cWWAOQMAAJgclQEAgCmwAqF7JAMAAFNgAqF7tAkAADA5KgMAAHMwLN5NAvTjygDJAADAFJgz4B5tAgAATI7KAADAHFh0yK0aJQPvv/9+jS940003XXQwAADUFu4mcK9GycCIESNqdDGLxSK73e5NPAAAoI7VKBlwOBy1HQcAALXPj0v93vBqzkBZWZlCQkJ8FQsAALWGNoF7Ht9NYLfb9dRTT6lNmzZq1qyZ9uzZI0maOnWqXnvtNZ8HCACATxg+2PyUx8nAM888oyVLlmju3LkKCgpy7v/lL3+pV1991afBAQCA2udxMrB06VK9/PLLSk5OVkBAgHN/fHy8tm/f7tPgAADwHYsPNv/kcTJw6NAhdezYsdp+h8OhiooKnwQFAIDP1XGbIDMzU8OGDZPNZpPFYtHKlStdwzEMTZs2Ta1bt1ZoaKiSkpK0c+dOlzGFhYVKTk5WRESEoqKiNGbMGJWUlLiM+fbbb9W3b1+FhIQoLi5Oc+fO9SxQXUQy0K1bN61bt67a/n/84x+64oorPA4AAAB/VFpaqvj4eC1atOi8x+fOnau0tDSlp6crOztbYWFhGjRokMrKypxjkpOTtW3bNmVkZGjVqlXKzMzUuHHjnMeLi4s1cOBAtWvXThs3btS8efM0ffp0vfzyyx7F6vHdBNOmTVNKSooOHTokh8Oh9957T3l5eVq6dKlWrVrl6eUAAKgbPlqBsLi42GV3cHCwgoODqw0fMmSIhgwZcv5LGYYWLFigJ554QsOHD5dU1YaPiYnRypUrNWrUKOXm5mr16tVav369+vTpI0lauHChhg4dqmeffVY2m03Lli1TeXm5Xn/9dQUFBal79+7KycnR888/75I0XIjHlYHhw4frgw8+0L/+9S+FhYVp2rRpys3N1QcffKAbb7zR08sBAFA3zj210JtNUlxcnCIjI53b7NmzPQ5l7969KigoUFJSknNfZGSkEhISlJWVJUnKyspSVFSUMxGQpKSkJFmtVmVnZzvHXH/99S4T+gcNGqS8vDydOHGixvFc1DoDffv2VUZGxsWcCgBAo5afn6+IiAjn6/NVBS6koKBAkhQTE+OyPyYmxnmsoKBArVq1cjkeGBio6OholzEdOnSodo1zx5o3b16jeC560aENGzYoNzdXUtU8gt69e1/spQAAqHW+eoRxRESESzLgDzxOBg4ePKhbb71VX375paKioiRJRUVFuuaaa/S3v/1Nl156qa9jBADAew3oqYWxsbGSpKNHj6p169bO/UePHlWvXr2cY44dO+ZyXmVlpQoLC53nx8bG6ujRoy5jzr0+N6YmPJ4zcPfdd6uiokK5ubkqLCxUYWGhcnNz5XA4dPfdd3t6OQAATKdDhw6KjY3VmjVrnPuKi4uVnZ2txMRESVJiYqKKioq0ceNG55i1a9fK4XAoISHBOSYzM9Pl1v6MjAx17ty5xi0C6SKSgc8//1yLFy9W586dnfs6d+6shQsXKjMz09PLAQBQN3w0gbCmSkpKlJOTo5ycHElVkwZzcnJ04MABWSwWPfzww3r66af1/vvva8uWLbrzzjtls9mcTwru2rWrBg8erLFjx+rrr7/Wl19+qdTUVI0aNUo2m02SdNtttykoKEhjxozRtm3b9Pbbb+uFF17QhAkTPIrV4zZBXFzceRcXstvtzuAAAGhoLEbV5s35ntiwYYP69+/vfH3uCzolJUVLlizRY489ptLSUo0bN05FRUW67rrrtHr1apcHAC5btkypqakaMGCArFarbrnlFqWlpTmPR0ZG6pNPPtH999+v3r17q0WLFpo2bZpHtxVKF5EMzJs3Tw888IAWLVrkvN1hw4YNeuihh/Tss896ejkAAOpGHc8Z6Nevn4yfmbFosVg0c+ZMzZw50+2Y6OhoLV++/Gffp2fPnuddDNATNUoGmjdvLovlx/JIaWmpEhISFBhYdXplZaUCAwN11113OcsbAACgcahRMrBgwYJaDgMAgFp2EX3/auf7qRolAykpKbUdBwAAtasB3VrY0Fz0okOSVFZWpvLycpd9/rYQAwAA/s7jWwtLS0uVmpqqVq1aKSwsTM2bN3fZAABokOr4EcaNicfJwGOPPaa1a9dq8eLFCg4O1quvvqoZM2bIZrNp6dKltREjAADeIxlwy+M2wQcffKClS5eqX79+Gj16tPr27auOHTuqXbt2WrZsmZKTk2sjTgAAUEs8rgwUFhbqsssuk1Q1P6CwsFCSdN1117ECIQCg4arjFQgbE4+Tgcsuu0x79+6VJHXp0kXvvPOOpKqKwbkHFwEA0NCcW4HQm81feZwMjB49Wps3b5YkTZ48WYsWLVJISIjGjx+viRMn+jxAAABQuzyeMzB+/Hjnf09KStL27du1ceNGdezYUT179vRpcAAA+AzrDLjl1ToDktSuXTu1a9fOF7EAAIB6UKNk4KdPSLqQBx988KKDAQCgtljk5VMLfRZJw1OjZGD+/Pk1upjFYiEZAACgkalRMnDu7oGGqvJwgWRpUt9hALVi88QP6zsEoNYUn3Ko+aI6ejMeVOSW13MGAABoFJhA6JbHtxYCAAD/QmUAAGAOVAbcIhkAAJiCt6sIsgIhAADwWxeVDKxbt0633367EhMTdejQIUnSX//6V33xxRc+DQ4AAJ/hEcZueZwMvPvuuxo0aJBCQ0P1zTff6OzZs5KkkydPatasWT4PEAAAnyAZcMvjZODpp59Wenq6XnnlFTVp8uO9/ddee602bdrk0+AAAEDt83gCYV5enq6//vpq+yMjI1VUVOSLmAAA8DkmELrncWUgNjZWu3btqrb/iy++0GWXXeaToAAA8LlzKxB6s/kpj5OBsWPH6qGHHlJ2drYsFosOHz6sZcuW6dFHH9W9995bGzECAOA95gy45XGbYPLkyXI4HBowYIBOnz6t66+/XsHBwXr00Uf1wAMP1EaMAACgFnmcDFgsFj3++OOaOHGidu3apZKSEnXr1k3NmjWrjfgAAPAJ5gy4d9ErEAYFBalbt26+jAUAgNrDcsRueZwM9O/fXxaL+0kUa9eu9SogAABQtzxOBnr16uXyuqKiQjk5Odq6datSUlJ8FRcAAL7lZZuAysBPzJ8//7z7p0+frpKSEq8DAgCgVtAmcMtnDyq6/fbb9frrr/vqcgAAoI747BHGWVlZCgkJ8dXlAADwLSoDbnmcDNx8880urw3D0JEjR7RhwwZNnTrVZ4EBAOBL3FronsfJQGRkpMtrq9Wqzp07a+bMmRo4cKDPAgMAAHXDo2TAbrdr9OjR6tGjh5o3b15bMQEAgDrk0QTCgIAADRw4kKcTAgAaH55N4JbHdxP88pe/1J49e2ojFgAAas25OQPebP7K42Tg6aef1qOPPqpVq1bpyJEjKi4udtkAAEDjUuM5AzNnztQjjzyioUOHSpJuuukml2WJDcOQxWKR3W73fZQAAPiCH/91740aJwMzZszQPffco08//bQ24wEAoHawzoBbNU4GDKPqp3DDDTfUWjAAAKDueXRr4c89rRAAgIaMRYfc8ygZ6NSp0wUTgsLCQq8CAgCgVtAmcMujZGDGjBnVViAEAACNm0fJwKhRo9SqVavaigUAgFpDm8C9GicDzBcAADRqtAncqvGiQ+fuJgAAAP6lxpUBh8NRm3EAAFC7qAy45fEjjAEAaIyYM+AeyQAAwByoDLjl8YOKAACAf6EyAAAwByoDbpEMAABMgTkD7tEmAADA5KgMAADMgTaBWyQDAABToE3gHm0CAABMjsoAAMAcaBO4RTIAADAHkgG3aBMAAGByVAYAAKZg+WHz5nx/RTIAADAH2gRukQwAAEyBWwvdY84AAAAmR2UAAGAOtAncIhkAAJiHH3+he4M2AQAAJkdlAABgCkwgdI/KAADAHAwfbB6w2+2aOnWqOnTooNDQUP3iF7/QU089JcP48UKGYWjatGlq3bq1QkNDlZSUpJ07d7pcp7CwUMnJyYqIiFBUVJTGjBmjkpKSi/kJuEUyAABALZgzZ44WL16sF198Ubm5uZozZ47mzp2rhQsXOsfMnTtXaWlpSk9PV3Z2tsLCwjRo0CCVlZU5xyQnJ2vbtm3KyMjQqlWrlJmZqXHjxvk0VtoEAABT8FWboLi42GV/cHCwgoODq43/6quvNHz4cP3617+WJLVv315vvfWWvv76a0lVVYEFCxboiSee0PDhwyVJS5cuVUxMjFauXKlRo0YpNzdXq1ev1vr169WnTx9J0sKFCzV06FA9++yzstlsF/+BfoLKAADAHHzUJoiLi1NkZKRzmz179nnf7pprrtGaNWu0Y8cOSdLmzZv1xRdfaMiQIZKkvXv3qqCgQElJSc5zIiMjlZCQoKysLElSVlaWoqKinImAJCUlJclqtSo7O9sXPxVJVAYAAPBIfn6+IiIinK/PVxWQpMmTJ6u4uFhdunRRQECA7Ha7nnnmGSUnJ0uSCgoKJEkxMTEu58XExDiPFRQUqFWrVi7HAwMDFR0d7RzjCyQDAABT8FWbICIiwiUZcOedd97RsmXLtHz5cnXv3l05OTl6+OGHZbPZlJKScvGB1AKSAQCAOdTxCoQTJ07U5MmTNWrUKElSjx49tH//fs2ePVspKSmKjY2VJB09elStW7d2nnf06FH16tVLkhQbG6tjx465XLeyslKFhYXO832BOQMAAHOo41sLT58+LavV9Ws2ICBADodDktShQwfFxsZqzZo1zuPFxcXKzs5WYmKiJCkxMVFFRUXauHGjc8zatWvlcDiUkJDgWUA/g8oAAAC1YNiwYXrmmWfUtm1bde/eXd98842ef/553XXXXZIki8Wihx9+WE8//bQuv/xydejQQVOnTpXNZtOIESMkSV27dtXgwYM1duxYpaenq6KiQqmpqRo1apTP7iSQSAYAACZR1ysQLly4UFOnTtV9992nY8eOyWaz6Y9//KOmTZvmHPPYY4+ptLRU48aNU1FRka677jqtXr1aISEhzjHLli1TamqqBgwYIKvVqltuuUVpaWkX/0HOw2L8dCmkRqa4uFiRkZHqp+EKtDSp73CAWvHx4Zz6DgGoNcWnHGreaY9OnjxZo0l5F/UeP3xXxN85SwFBIRc+wQ17eZk2L/1TrcZaX5gzAACAydEmAACYgsUwZPGiGO7NuQ0dyQAAwBzq+NbCxoQ2AQAAJkdlAABgCnV9N0FjQjIAADAH2gRu0SYAAMDkqAwAAEyBNoF7JAMAAHOgTeAWyQAAwBSoDLjHnAEAAEyOygAAwBxoE7hFMgAAMA1/LvV7gzYBAAAmR2UAAGAOhlG1eXO+nyIZAACYAncTuEebAAAAk6MyAAAwB+4mcItkAABgChZH1ebN+f6KNgEAACZHMgAXI1OP6uPDm3XPjEPOfa3bndW01/bq7S1b9V7eFj2evk9RLSpczguPqtSkF/frvbwtejd3i8Y/l6+Qpva6Dh/Qln+HadqdHXTrFd01yNZLX30U6XbsC5Mu1SBbL733SkuX/cUnAvTn+9vqN5166OYuPfT8hDidKT3/P5eH9gZpxOVV49DAGT7Y/BTJAJw6xZ/Wr28v1J5tIc59waF2zXprjwzDokm/+4UmDO+owCBDM9/cK8tPptZOevGA2nUu05RRl2laSgf1SCjRw/MO1sfHgMmVnbbqsu5nlDrr53//vvwoUts3humS2PJqx+akttP+vFDN/ttuzXxzj7ZkN9OCiXHVxlVWSH++r71+mVDqs/hRe87dTeDN5q/qNRnIzMzUsGHDZLPZZLFYtHLlyvoMx9RCmto16cX9WjDxUp06GeDc3/3q04qJK9dzD8dp3/ZQ7dseqnkPtdXl8WfU67oSSVJcxzJd9atTmv9InPK+CdO2r5vpL0+00Q3DixQdU+HuLYFacdWvTukPkwp07ZCTbsccP9JEf3mijSYt2q/A/5o5dWBnsDZ8GqHxzx1QlytP65cJpbrv6YP6/P+i9J8C18FL5rRWXMcyXT+sqBY+CXzu3DoD3mx+ql6TgdLSUsXHx2vRokX1GQYkpc46pK/XROibdeEu+5sEOSRDqii3OPdVnLXIcEjdr676a6hrn1KdKgrQzm+bOsdsWhcuwyF1ueJ03XwAoIYcDmnug23123uPqX3nsmrHczeEqVlkpTrFn3Huu7LvKVms0vZvwpz7cr5opnWronT/BSoQQGNQr3cTDBkyREOGDKnx+LNnz+rs2bPO18XFxbURluncMPyEOvY4oweGXl7t2PaNYSo7bdWYx4/ojT+3lmRozONHFBAoRbeq+qs/umWliv7j+qvksFt0qijQOQZoKN5Z1EoBAYZGjDl+3uOF3wcq6pJKl30BgVXzYgqPVf2eFxcG6NmH22rSi/sVFu7HU8z9DIsOudeo5gzMnj1bkZGRzi0urnoPD55paSvXvTMPa05qW1Wcrf7rcLIwUE//sb0SbizWyp1btCJvq8IiHNr5bagMh+U8VwQarp3fhmrlqy316IIDsnjx67tgYpz6/+aEevwPcwUaFSYQutWo1hmYMmWKJkyY4HxdXFxMQuCljj3PqHnLSi36eIdzX0Cg1ON/SnXT6OP63/Y9tenzcI2+pqsioitlr7SotDhAb+Vs05EDQZLO/5eUNcD44S+pJnX6eYCfsyW7mYqOB+r2q7o79znsFr0yw6aVr7TU0q+/O2+ly16pHypdVb/nOV+GK+uTSP0jvVXVAENyOCwaEhevh+fma9CthXX2mQBfaFTJQHBwsIKDg+s7DL+Ss66ZxvXv5LLvkfn5yt8VoncWtZTjJ3/9FxdW/brEX3tKUS0q9e9PIiRV9VjDo+zq2OO0dm2pmjfQ67qSH3qsTQU0FEm3FOrKvqdc9v3ptss04JYTGvj7qi/wrn1KVXIyUDu/DdXlPavmDeR8cW4OTFUlYMEHO+Sw//j/ja8+jtTfF7XS/Pd36pJYWmMNFW0C9xpVMgDfO1MaoP15oS77yk5bderEj/sH/r5QB3YG6+R/AtW192ndO/OQVrzcUgd3V92CmL8rROvXhuvhZw9q4aRLFdDE0P0/zL4uPEplAHXrTKlVh/f++EdDQX6Qdm8NVXhUpVpdWqGIaNf1LwIDpeatKhXXsWo+UtvLz6pP/2IteDROD8w5KHuFRYt+uDvmkthK55if2rG5qSxWqX2X6hMS0YDw1EK3SAZwQZf+okyjpxxReJRdR/Ob6K20GL33cguXMXNS2+r+Zw7pz+/sluGQvvgwUn95ok09RQwz27G5qR77bUfn65emV/0e3jiyUI8uOFCja0x6cb8WPX6pJo/8hSxW6bqhRbrv6UMXPhFopCyGUX+pTklJiXbt2iVJuuKKK/T888+rf//+io6OVtu2bS94fnFxsSIjI9VPwxVo4S9Q+KePD+fUdwhArSk+5VDzTnt08uRJRURE1M57/PBdkThkpgKbhFz4BDcqK8qU9dG0Wo21vtRrZWDDhg3q37+/8/W5yYEpKSlasmRJPUUFAPBLPLXQrXpNBvr166d6LEwAAAAxZwAAYBLcTeAeyQAAwBwcRtXmzfl+imQAAGAOzBlwq1EtRwwAAHyPygAAwBQs8nLOgM8iaXhIBgAA5sAKhG7RJgAAwOSoDAAATIFbC90jGQAAmAN3E7hFmwAAAJOjMgAAMAWLYcjixSRAb85t6EgGAADm4Phh8+Z8P0WbAAAAk6MyAAAwBdoE7pEMAADMgbsJ3CIZAACYAysQusWcAQAATI7KAADAFFiB0D2SAQCAOdAmcIs2AQAAJkdlAABgChZH1ebN+f6KZAAAYA60CdyiTQAAgMlRGQAAmAOLDrlFMgAAMAWWI3aPNgEAACZHZQAAYA5MIHSLZAAAYA6GJG9uD/TfXIBkAABgDswZcI85AwAAmByVAQCAORjycs6AzyJpcEgGAADmwARCt2gTAABgclQGAADm4JBk8fJ8P0UyAAAwBe4mcI82AQAAJkdlAABgDkwgdIvKAADAHM4lA95sHjp06JBuv/12XXLJJQoNDVWPHj20YcOGn4RkaNq0aWrdurVCQ0OVlJSknTt3ulyjsLBQycnJioiIUFRUlMaMGaOSkhKvfxw/RTIAAEAtOHHihK699lo1adJEH330kb777js999xzat68uXPM3LlzlZaWpvT0dGVnZyssLEyDBg1SWVmZc0xycrK2bdumjIwMrVq1SpmZmRo3bpxPY6VNAAAwBx+1CYqLi112BwcHKzg4uNrwOXPmKC4uTm+88YZzX4cOHX5yOUMLFizQE088oeHDh0uSli5dqpiYGK1cuVKjRo1Sbm6uVq9erfXr16tPnz6SpIULF2ro0KF69tlnZbPZLv7z/ASVAQCAOTh8sEmKi4tTZGSkc5s9e/Z53+79999Xnz599Lvf/U6tWrXSFVdcoVdeecV5fO/evSooKFBSUpJzX2RkpBISEpSVlSVJysrKUlRUlDMRkKSkpCRZrVZlZ2f74IdShcoAAMAUfHVrYX5+viIiIpz7z1cVkKQ9e/Zo8eLFmjBhgv70pz9p/fr1evDBBxUUFKSUlBQVFBRIkmJiYlzOi4mJcR4rKChQq1atXI4HBgYqOjraOcYXSAYAAPBARESESzLgjsPhUJ8+fTRr1ixJ0hVXXKGtW7cqPT1dKSkptR2mR2gTAADMoY7vJmjdurW6devmsq9r1646cOCAJCk2NlaSdPToUZcxR48edR6LjY3VsWPHXI5XVlaqsLDQOcYXSAYAAObgMLzfPHDttdcqLy/PZd+OHTvUrl07SVWTCWNjY7VmzRrn8eLiYmVnZysxMVGSlJiYqKKiIm3cuNE5Zu3atXI4HEpISLjYn0Q1tAkAAKgF48eP1zXXXKNZs2Zp5MiR+vrrr/Xyyy/r5ZdfliRZLBY9/PDDevrpp3X55ZerQ4cOmjp1qmw2m0aMGCGpqpIwePBgjR07Vunp6aqoqFBqaqpGjRrlszsJJJIBAIBZ1PEKhFdddZVWrFihKVOmaObMmerQoYMWLFig5ORk55jHHntMpaWlGjdunIqKinTddddp9erVCgkJcY5ZtmyZUlNTNWDAAFmtVt1yyy1KS0u7+M9xHhbDaLzrKxYXFysyMlL9NFyBlib1HQ5QKz4+nFPfIQC1pviUQ8077dHJkydrNCnvot7jh++KpMseVKD1/DP/a6LScVb/2pNWq7HWF+YMAABgcrQJAADmwIOK3CIZAACYg8OQ5MUXuod3EzQmtAkAADA5KgMAAHMwHFWbN+f7KZIBAIA5MGfALZIBAIA5MGfALeYMAABgclQGAADmQJvALZIBAIA5GPIyGfBZJA0ObQIAAEyOygAAwBxoE7hFMgAAMAeHQ5IXawU4/HedAdoEAACYHJUBAIA50CZwi2QAAGAOJANu0SYAAMDkqAwAAMyB5YjdIhkAAJiCYThkePHkQW/ObehIBgAA5mAY3v11z5wBAADgr6gMAADMwfByzoAfVwZIBgAA5uBwSBYv+v5+PGeANgEAACZHZQAAYA60CdwiGQAAmILhcMjwok3gz7cW0iYAAMDkqAwAAMyBNoFbJAMAAHNwGJKFZOB8aBMAAGByVAYAAOZgGJK8WWfAfysDJAMAAFMwHIYML9oEBskAAACNnOGQd5UBbi0EAAB+isoAAMAUaBO4RzIAADAH2gRuNepk4FyWVqkKr9aRABqy4lP++w8QUFxS9ftdF391e/tdUakK3wXTwDTqZODUqVOSpC/0YT1HAtSe5p3qOwKg9p06dUqRkZG1cu2goCDFxsbqiwLvvytiY2MVFBTkg6gaFovRiJsgDodDhw8fVnh4uCwWS32HYwrFxcWKi4tTfn6+IiIi6jscwKf4/a57hmHo1KlTstlsslprb057WVmZysvLvb5OUFCQQkJCfBBRw9KoKwNWq1WXXnppfYdhShEREfxjCb/F73fdqq2KwE+FhIT45Ze4r3BrIQAAJkcyAACAyZEMwCPBwcF68sknFRwcXN+hAD7H7zfMqlFPIAQAAN6jMgAAgMmRDAAAYHIkAwAAmBzJAAAAJkcygBpbtGiR2rdvr5CQECUkJOjrr7+u75AAn8jMzNSwYcNks9lksVi0cuXK+g4JqFMkA6iRt99+WxMmTNCTTz6pTZs2KT4+XoMGDdKxY8fqOzTAa6WlpYqPj9eiRYvqOxSgXnBrIWokISFBV111lV588UVJVc+FiIuL0wMPPKDJkyfXc3SA71gsFq1YsUIjRoyo71CAOkNlABdUXl6ujRs3KikpybnParUqKSlJWVlZ9RgZAMAXSAZwQcePH5fdbldMTIzL/piYGBUUFNRTVAAAXyEZAADA5EgGcEEtWrRQQECAjh496rL/6NGjio2NraeoAAC+QjKACwoKClLv3r21Zs0a5z6Hw6E1a9YoMTGxHiMDAPhCYH0HgMZhwoQJSklJUZ8+fXT11VdrwYIFKi0t1ejRo+s7NMBrJSUl2rVrl/P13r17lZOTo+joaLVt27YeIwPqBrcWosZefPFFzZs3TwUFBerVq5fS0tKUkJBQ32EBXvvss8/Uv3//avtTUlK0ZMmSug8IqGMkAwAAmBxzBgAAMDmSAQAATI5kAAAAkyMZAADA5EgGAAAwOZIBAABMjmQAAACTIxkAAMDkSAYAL/3hD3/QiBEjnK/79eunhx9+uM7j+Oyzz2SxWFRUVOR2jMVi0cqVK2t8zenTp6tXr15exbVv3z5ZLBbl5OR4dR0AtYdkAH7pD3/4gywWiywWi4KCgtSxY0fNnDlTlZWVtf7e7733np566qkaja3JFzgA1DYeVAS/NXjwYL3xxhs6e/asPvzwQ91///1q0qSJpkyZUm1seXm5goKCfPK+0dHRPrkOANQVKgPwW8HBwYqNjVW7du107733KikpSe+//76kH0v7zzzzjGw2mzp37ixJys/P18iRIxUVFaXo6GgNHz5c+/btc17TbrdrwoQJioqK0iWXXKLHHntM//14j/9uE5w9e1aTJk1SXFycgoOD1bFjR7322mvat2+f8+E4zZs3l8Vi0R/+8AdJVY+Inj17tjp06KDQ0FDFx8frH//4h8v7fPjhh+rUqZNCQ0PVv39/lzhratKkSerUqZOaNm2qyy67TFOnTlVFRUW1cS+99JLi4uLUtGlTjRw5UidPnnQ5/uqrr6pr164KCQlRly5d9Je//MXjWADUH5IBmEZoaKjKy8udr9esWaO8vDxlZGRo1apVqqio0KBBgxQeHq5169bpyy+/VLNmzTR48GDnec8995yWLFmi119/XV988YUKCwu1YsWKn33fO++8U2+99ZbS0tKUm5url156Sc2aNVNcXJzeffddSVJeXp6OHDmiF154QZI0e/ZsLV26VOnp6dq2bZvGjx+v22+/XZ9//rmkqqTl5ptv1rBhw5STk6O7775bkydP9vhnEh4eriVLlui7777TCy+8oFdeeUXz5893GbNr1y698847+uCDD7R69Wp98803uu+++5zHly1bpmnTpumZZ55Rbm6uZs2apalTp+rNN9/0OB4A9cQA/FBKSooxfPhwwzAMw+FwGBkZGUZwcLDx6KOPOo/HxMQYZ8+edZ7z17/+1ejcubPhcDic+86ePWuEhoYaH3/8sWEYhtG6dWtj7ty5zuMVFRXGpZde6nwvwzCMG264wXjooYcMwzCMvLw8Q5KRkZFx3jg//fRTQ5Jx4sQJ576ysjKjadOmxldffeUydsyYMcatt95qGIZhTJkyxejWrZvL8UmTJlW71n+TZKxYscLt8Xnz5hm9e/d2vn7yySeNgIAA4+DBg859H330kWG1Wo0jR44YhmEYv/jFL4zly5e7XOepp54yEhMTDcMwjL179xqSjG+++cbt+wKoX8wZgN9atWqVmjVrpoqKCjkcDt12222aPn2683iPHj1c5gls3rxZu3btUnh4uMt1ysrKtHv3bp08eVJHjhxRQkKC81hgYKD69OlTrVVwTk5OjgICAnTDDTfUOO5du3bp9OnTuvHGG132l5eX64orrpAk5ebmusQhSYmJiTV+j3PefvttpaWlaffu3SopKVFlZaUiIiJcxrRt21Zt2rRxeR+Hw6G8vDyFh4dr9+7dGjNmjMaOHescU1lZqcjISI/jAVA/SAbgt/r376/FixcrKChINptNgYGuv+5hYWEur0tKStS7d28tW7as2rVatmx5UTGEhoZ6fE5JSYkk6Z///KfLl7BUNQ/CV7KyspScnKwZM2Zo0KBBioyM1N/+9jc999xzHsf6yiuvVEtOAgICfBYrgNpFMgC/FRYWpo4dO9Z4/JVXXqm3335brVq1qvbX8TmtW7dWdna2rr/+eklVfwFv3LhRV1555XnH9+jRQw6HQ59//rmSkpKqHT9XmbDb7c593bp1U3BwsA4cOOC2otC1a1fnZMhz/v3vf1/4Q/7EV199pXbt2unxxx937tu/f3+1cQcOHNDhw4dls9mc72O1WtW5c2fFxMTIZrNpz549Sk5O9uj9ATQcTCAEfpCcnKwWLVpo+PDhWrdunfbu3avPPvtMDz74oA4ePChJeuihh/TnP/9ZK1eu1Pbt23Xffff97BoB7du3V0pKiu666y6tXLnSec133nlHktSuXTtZLBatWrVK33//vUpKShQeHq5HH31U48eP15tvvqndu3dr06ZNWrhwoXNS3j333KOdO3dq4sSJysvL0/Lly7VkyRKPPu/ll1+uAwcO6G9/+5t2796ttLS0806GDAkJUUpKijZv3qx169bpwQcf1MiRIxUbGytJmjFjhmbPnq20tDTt2LFDW7Zs0RtvvKHnn3/eo3gA1B+SAeAHTZs2VWZmptq2baubb75ZXbt21ZgxY1RWVuasFDzyyCO64447lJKSosTERIWHh+s3v/nNz1538eLF+u1vf6v77rtPXbp00dixY1VaWipJatOmjWbMmKHJkycrJiZGqampkqSnnnpKU6dO1ezZs9W1a1cNHjxY//znP9WhQwdJVX38d999VytXrlR8fLzS09M1a9Ysjz7vTTfdpPHjxys1NVW9evXSV199palTp1Yb17FjR918880aOnSoBg4cqJ49e7rcOnj33Xfr1Vdf1RtvvKEePXrohhtu0JIlS5yxAmj4LIa7mU8AAMAUqAwAAGByJAMAAJgcyQAAACZHMgAAgMmRDAAAYHIkAwAAmBzJAAAAJkcyAACAyZEMAABgciQDAACYHMkAAAAm9/8BNB0AP2OE3xwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_logistic)\n",
    "\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = [0, 1])\n",
    "\n",
    "cm_display.plot()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9489795f-6639-44c1-960c-de7e51666c99",
   "metadata": {},
   "source": [
    "## SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "211d1284-4ca2-408a-9708-d14060a51341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.5953177257525084\n",
      "Revocação: 0.7265047518479408\n",
      "Precisão: 0.6285975331201462\n",
      "F1-score: 0.6740142052412442\n"
     ]
    }
   ],
   "source": [
    "y_pred_sgdc = model_sgdc.predict(X_test_norma)\n",
    "\n",
    "print(\"Acurácia:\", accuracy_score(y_test, y_pred_sgdc))\n",
    "print(\"Revocação:\", recall_score(y_test, y_pred_sgdc))\n",
    "print(\"Precisão:\", precision_score(y_test, y_pred_sgdc))\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred_sgdc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1ab92401-96f1-4831-968b-6c42db41bb88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm2 = SGDClassifier(random_state=42, penalty = 'l1', max_iter = 1000, learning_rate = 'optimal', eta0 = 1.0, alpha = 0.0001)\n",
    "clf = CalibratedClassifierCV(svm2) \n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_proba = clf.predict_proba(X_test_norma)[:,1]\n",
    "\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba) \n",
    "roc_auc = auc(fpr, tpr)\n",
    "# Plot the ROC curve\n",
    "plt.figure()  \n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='No Skill')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b0d9e31a-7579-4527-9dea-85a0c8c5f4ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "average_precision = average_precision_score(y_test, y_pred_proba)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall, precision, color='blue', lw=2, label=f'Precision-Recall curve (AP = {average_precision:.2f})')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"lower left\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b2f3409b-fed8-4d94-9abf-8246fa93d276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAAGwCAYAAADWsX1oAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAABDfElEQVR4nO3de1xUdf7H8dcAchGZQTTBMbyU5aU1NS2iLdOV9ZJrtrm1FhWZ6e4mlVqmVpqXis1KC3Ozi2m22trulr9yW4u0QpNIMbqosWKUeBmsEBCM28z5/WFOTerEOAMI5/18PM7j0Zzz/Z75DMs6Hz7fy7EYhmEgIiIiphbU2AGIiIhI41NCICIiIkoIRERERAmBiIiIoIRAREREUEIgIiIiKCEQERERIKSxA/CHy+Vi//79REVFYbFYGjscERHxkWEYHD58GLvdTlBQ/f2NWllZSXV1td/3CQ0NJTw8PAARnX6adEKwf/9+4uPjGzsMERHxU2FhIWeeeWa93LuyspIunVrhOOj0+15xcXEUFBQ0y6SgSScEUVFRAAyMG0tIUGgjRyNSPxxXdGzsEETqjbO6kp0r5rn/Pa8P1dXVOA46+TqnM9aoU69ClB120anfV1RXVyshON0cGyYICQolJCiskaMRqR/Boc3vHx6Rn2uIYd9WURZaRZ36+7ho3kPTTTohEBERqSun4cLpx9N7nIYrcMGchpQQiIiIKbgwcHHqGYE/fZsCLTsUERERVQhERMQcXLjwp+jvX+/TnxICERExBadh4DROvezvT9+mQEMGIiIiogqBiIiYgyYVeqeEQERETMGFgVMJwUlpyEBERERUIRAREXPQkIF3SghERMQUtMrAOw0ZiIiIiCoEIiJiDq4fDn/6N2dKCERExBScfq4y8KdvU6CEQERETMFp4OfTDgMXy+lIcwhEREREFQIRETEHzSHwTgmBiIiYggsLTix+9W/ONGQgIiIiqhCIiIg5uIyjhz/9mzMlBCIiYgpOP4cM/OnbFGjIQERERFQhEBERc1CFwDslBCIiYgouw4LL8GOVgR99mwINGYiIiIgqBCIiYg4aMvBOFQIRETEFJ0F+H77IzMxk5MiR2O12LBYLa9as8bg+e/ZsunfvTmRkJK1btyYpKYns7GyPNsXFxSQnJ2O1WomOjmbcuHGUl5d7tPn000+57LLLCA8PJz4+nvnz55/Sz0cJgYiImILxwxyCUz0MH+cQVFRU0Lt3bxYvXnzC6+eeey5PPfUUn332GZs2baJz584MGTKEb775xt0mOTmZ7du3k5GRwdq1a8nMzGTChAnu62VlZQwZMoROnTqRk5PDo48+yuzZs3n22Wd9/vloyEBERKQeDB8+nOHDh5/0+vXXX+/xesGCBSxdupRPP/2UwYMHs3PnTtatW8eWLVvo378/AIsWLeKKK67gsccew263s3LlSqqrq3nhhRcIDQ3lvPPOIzc3lwULFngkDnWhCoGIiJjCsTkE/hxw9K/ynx5VVVV+x1ZdXc2zzz6LzWajd+/eAGRlZREdHe1OBgCSkpIICgpyDy1kZWUxYMAAQkND3W2GDh1KXl4ehw4d8ikGJQQiImIKTiPI7wMgPj4em83mPtLS0k45prVr19KqVSvCw8NZuHAhGRkZtG3bFgCHw0G7du082oeEhBATE4PD4XC3iY2N9Whz7PWxNnWlIQMREREfFBYWYrVa3a/DwsJO+V6DBg0iNzeXb7/9lueee45rr72W7Ozs4xKBhqAKgYiImIILCy6C/DiODhlYrVaPw5+EIDIykq5du3LxxRezdOlSQkJCWLp0KQBxcXEcPHjQo31tbS3FxcXExcW52xQVFXm0Ofb6WJu6UkIgIiKmEKg5BPXJ5XK55yQkJiZSUlJCTk6O+/qGDRtwuVwkJCS422RmZlJTU+Nuk5GRQbdu3WjdurVP762EQEREpB6Ul5eTm5tLbm4uAAUFBeTm5rJnzx4qKiq49957+fDDD/n666/JycnhlltuYd++fVxzzTUA9OjRg2HDhjF+/Hg++ugjPvjgA1JTUxkzZgx2ux04ulIhNDSUcePGsX37dlavXs2TTz7JlClTfI5XcwhERMQUfjox8NT6Gz6137p1K4MGDXK/PvYlnZKSwpIlS/jiiy948cUX+fbbb2nTpg0XXnghGzdu5LzzznP3WblyJampqQwePJigoCBGjx5Nenq6+7rNZuPtt99m4sSJ9OvXj7Zt2zJr1iyflxyCEgIRETGJo3MI/Hi4kY99Bw4ciOEliXj11Vd/8R4xMTGsWrXKa5vzzz+fjRs3+hTbiWjIQERERFQhEBERc3CdwvMIPPv7NmTQ1CghEBERU2joOQRNjRICERExhWP7CZx6/+adEGgOgYiIiKhCICIi5uA0LDh9fITxz/s3Z0oIRETEFJx+Tip0ashAREREmjtVCERExBRcRhAuP1YZuLTKQEREpOnTkIF3GjIQERERVQhERMQcXPi3UsAVuFBOS0oIRETEFPzfmKh5F9Wb96cTERGROlGFQERETMH/Zxk077+hlRCIiIgpuLDgwp85BNqpUEREpMlThcC75v3pREREpE5UIRAREVPwf2Oi5v03tBICERExBZdhweXPPgTN/GmHzTvdERERkTpRhUBEREzB5eeQQXPfmEgJgYiImIL/Tzts3glB8/50IiIiUieqEIiIiCk4seD0Y3Mhf/o2BUoIRETEFDRk4F3z/nQiIiJSJ6oQiIiIKTjxr+zvDFwopyUlBCIiYgoaMvBOCYGIiJiCHm7kXfP+dCIiIlInqhCIiIgpGFhw+TGHwGjmyw5VIRAREVM4NmTgz+GLzMxMRo4cid1ux2KxsGbNGve1mpoapk2bRq9evYiMjMRut3PTTTexf/9+j3sUFxeTnJyM1WolOjqacePGUV5e7tHm008/5bLLLiM8PJz4+Hjmz59/Sj8fJQQiIiL1oKKigt69e7N48eLjrh05coRt27Yxc+ZMtm3bxquvvkpeXh5XXnmlR7vk5GS2b99ORkYGa9euJTMzkwkTJrivl5WVMWTIEDp16kROTg6PPvoos2fP5tlnn/U5Xg0ZiIiIKTT044+HDx/O8OHDT3jNZrORkZHhce6pp57ioosuYs+ePXTs2JGdO3eybt06tmzZQv/+/QFYtGgRV1xxBY899hh2u52VK1dSXV3NCy+8QGhoKOeddx65ubksWLDAI3GoC1UIRETEFJw/PO3QnwOO/lX+06Oqqiog8ZWWlmKxWIiOjgYgKyuL6OhodzIAkJSURFBQENnZ2e42AwYMIDQ01N1m6NCh5OXlcejQIZ/eXwmBiIiID+Lj47HZbO4jLS3N73tWVlYybdo0rrvuOqxWKwAOh4N27dp5tAsJCSEmJgaHw+FuExsb69Hm2OtjbepKQwYiImIKgRoyKCwsdH9pA4SFhfkVV01NDddeey2GYfD000/7dS9/KCEQERFTcBGEy4/C+LG+VqvVIyHwx7Fk4Ouvv2bDhg0e942Li+PgwYMe7WtraykuLiYuLs7dpqioyKPNsdfH2tSVhgxEREQawbFkYNeuXbzzzju0adPG43piYiIlJSXk5OS4z23YsAGXy0VCQoK7TWZmJjU1Ne42GRkZdOvWjdatW/sUjxICERExBadh8fvwRXl5Obm5ueTm5gJQUFBAbm4ue/bsoaamhj/84Q9s3bqVlStX4nQ6cTgcOBwOqqurAejRowfDhg1j/PjxfPTRR3zwwQekpqYyZswY7HY7ANdffz2hoaGMGzeO7du3s3r1ap588kmmTJni889HQwYiImIKDb3scOvWrQwaNMj9+tiXdEpKCrNnz+b1118HoE+fPh793n33XQYOHAjAypUrSU1NZfDgwQQFBTF69GjS09PdbW02G2+//TYTJ06kX79+tG3bllmzZvm85BCUEIiIiEkYfj7t0PCx78CBAzEMw8v9Tn7tmJiYGFatWuW1zfnnn8/GjRt9iu1ENGQgIiIiqhCIiIg5OLHg9OMBRf70bQqUEIiIiCm4DN/nAfy8f3OmIQMRERFRhcDsrh+/i+QJ+R7nCr+K5M/XDACgdZsqbrnjC/omfEtESyd7v45k9Qtns/ndoxtetGt/hOvG7eb8/t/Ruk0Vxd+G8e5/O7D6hbOprVW+KY0vyOLiT5dv5Ypf7aJNqyN8cziSNz7txvMbL4AfSsC/6f4loy/YQY/23xDdsooxz/6B/xW19bjPfVe8z0Vd9nFGVAXfV7fgk71xpK9P4KvvfFvrLY3H5eekQn/6NgVKCISvdrfi/okXuV87a38sqU2Z/QmRUbXMndKPstJQLh+6n+lpHzPppkv48n824jtXYAkyeCrtPA7sjaTT2Ye5/d7PCY9wsvTJ7o3xcUQ83HxJLn/ot4MH/m8Qu79pTU/7N8we+R7llaH8Y0svACJa1JJbGEfGjrOZNfL9E95n54Ez+O/n53CgtBW2iCr+dPlWFif/h5GLrm/2XxTNhQsLLj/mAfjTtyk4LX6LFy9eTOfOnQkPDychIYGPPvqosUMyFZfTwqHvwtxHWemPT83qcX4Jb6zuxP92ROPY15LVL3Sl4nALuvYoAyAn6wyemHs+H2efgWNfS7IzY3n17124ZJBvD9UQqS+9z3Twfl5nNuV34kCplfU7z+bDL8/kVx1+3BL2P5+dy3Mb+5Nd0OGk93n1455s22PnQKmVLxxn8Ld3L6K9rRx79OGG+Bgi9a7RE4LVq1czZcoUHnjgAbZt20bv3r0ZOnTocfs3S/2xxx9hxZsbWLrmPe6el8sZsd+7r+38NJoBvz1AK2s1FovBgN/uJzTMxWc5MSe9X2SrWg6XtmiI0EV+0Sd747ioy146xpQAcE7st/SJd/BBfvwp3zO8RQ1X9v6CvYeicJS2ClCkUt8aeqfCpqbRhwwWLFjA+PHjGTt2LABLlizhP//5Dy+88ALTp09v5Oiav7zt0Syc04u9X0cS07aK68fnM/+5D7ltzGV8fySEv87oy7SHc1m9fj21tRaqKoN5cGpfDuyNPOH92p9Zwcg/fq3hAjltLPugL5Fh1bx62z9wuoIIDnKx+N2L+O/n5/p8r2v6fc6dSR/SMrSWgm+juW3l76h1BddD1FIfNIfAu0ZNCKqrq8nJyWHGjBnuc0FBQSQlJZGVlXVc+6qqKqqqqtyvy8rKGiTO5ixn8xnu//4qH/I+j2bZG+9xWdIB3n49nhv/vItWUTXce9uFlJWEcvHlRUxPy+We8Rfz9e4oj3u1OaOSuelb2fROHG+tOfW/vkQC6bfn7Wb4r3Zx72tJfPlNa7rFfsddQz7gm8ORrP20m0/3+u/n5/BhwZmc0eoINyZ+wiOjMxi77CqqnY3+t5WI3xo13fn2229xOp3ExsZ6nI+NjcXhOH4MOi0tDZvN5j7i4/WlE2gV5S3YtyeS9vFHiOtw9K/9J+b14pMtbSnYZeXl588hf6eN313ztUe/mLaVpD2dzc5Po1n08K8aKXqR400anMXyzX15e3tX8g+24T+fncvK7PMZ++uPfb5XeVUYhcXRbNtjZ+o/h9C5TQmDuhfUQ9RSH1xY3M8zOKVDkwpPHzNmzKC0tNR9FBYWNnZIzU54RC3tOxyh+NswwsJdABguz/8TOJ0Wgn7ym9PmjEr+uiSb/C9sPDH3fIxmPs4mTUt4i9rjNqNxGRaCLP7tMmOxABYIDXb6dR9pOMYPqwxO9TCaeULQqHWutm3bEhwcTFFRkcf5oqIi4uLijmsfFhZGWFhYQ4VnCuPu/ILsjWdw8EAEbc6oInnCLlwueP+t9lQcbsG+PS1JnfE5S5/sTllpCxIHHqRvwrfMmdwPOJoMpC3J5htHBEuf7I6tdbX73oe+0/9W0vgyd3Vi3KXbcJS2Yvc3reke9x03JHzK/33y4zwXa3glcbZyzoiqAKBzmxIAvitvyXcVLekQXcaQ8/L5cHc8h46E085awdhff0xVTTCb8js1xseSU9DQTztsaho1IQgNDaVfv36sX7+eq666CgCXy8X69etJTU1tzNBMo027Su558BOstmpKD4Wy/ZMYpoxNpKzk6Jf57En9uTk1j1kLcoho6WR/YUsWzD6frZvbAdA34Vs6dDxCh45HWPHmux73HnHh8Ab/PCI/N3/dpdw2cAszhm+kdeT3fHM4kn9v68mzmf3cbS4/9yvmjHrP/fqvo98B4Jn3+/FM5oVU1QbTN/4A11/0GdaIKr4rj2DbnvaMXf57Dh2JaOiPJFIvLEZdnr9Yj1avXk1KSgrPPPMMF110EU888QSvvPIKX3zxxXFzC36urKwMm81Gkv1PhATpr1Fpng5cqb9ApflyVlfy+fP3UVpaitVqrZf3OPZd8fuMsbSIDP3lDidRU1HNa79dVq+xNqZGnxr7xz/+kW+++YZZs2bhcDjo06cP69at+8VkQERExBcaMvCu0RMCgNTUVA0RiIiINKLTIiEQERGpb3qWgXdKCERExBQ0ZOBdk9qHQEREROqHKgQiImIKqhB4p4RARERMQQmBdxoyEBEREVUIRETEHFQh8E4JgYiImIKBf0sHG3Vb3waghEBERExBFQLvNIdAREREVCEQERFzUIXAOyUEIiJiCkoIvNOQgYiIiKhCICIi5qAKgXdKCERExBQMw4Lhx5e6P32bAg0ZiIiI1IPMzExGjhyJ3W7HYrGwZs0aj+uvvvoqQ4YMoU2bNlgsFnJzc4+7R2VlJRMnTqRNmza0atWK0aNHU1RU5NFmz549jBgxgpYtW9KuXTumTp1KbW2tz/EqIRAREVNwYfH78EVFRQW9e/dm8eLFJ71+6aWX8sgjj5z0HpMnT+aNN97gn//8J++//z779+/n6quvdl93Op2MGDGC6upqNm/ezIsvvsjy5cuZNWuWT7GChgxERMQkGnoOwfDhwxk+fPhJr994440AfPXVVye8XlpaytKlS1m1ahW/+c1vAFi2bBk9evTgww8/5OKLL+btt99mx44dvPPOO8TGxtKnTx/mzZvHtGnTmD17NqGhoXWOVxUCERERH5SVlXkcVVVV9fI+OTk51NTUkJSU5D7XvXt3OnbsSFZWFgBZWVn06tWL2NhYd5uhQ4dSVlbG9u3bfXo/JQQiImIKxyYV+nMAxMfHY7PZ3EdaWlq9xOtwOAgNDSU6OtrjfGxsLA6Hw93mp8nAsevHrvlCQwYiImIKgRoyKCwsxGq1us+HhYX5HdvpQAmBiIiYQqCWHVqtVo+EoL7ExcVRXV1NSUmJR5WgqKiIuLg4d5uPPvrIo9+xVQjH2tSVhgxEREROQ/369aNFixasX7/efS4vL489e/aQmJgIQGJiIp999hkHDx50t8nIyMBqtdKzZ0+f3k8VAhERMQXDzyEDX6sL5eXl5Ofnu18XFBSQm5tLTEwMHTt2pLi4mD179rB//37g6Jc9HP3LPi4uDpvNxrhx45gyZQoxMTFYrVZuv/12EhMTufjiiwEYMmQIPXv25MYbb2T+/Pk4HA7uv/9+Jk6c6PNQhioEIiJiCgZgGH4cPr7f1q1b6du3L3379gVgypQp9O3b171HwOuvv07fvn0ZMWIEAGPGjKFv374sWbLEfY+FCxfyu9/9jtGjRzNgwADi4uJ49dVX3deDg4NZu3YtwcHBJCYmcsMNN3DTTTcxd+5cn38+FsMwfP2Mp42ysjJsNhtJ9j8REtQ8JnWI/NyBKzs1dggi9cZZXcnnz99HaWlpvY3LH/uu6PuvKQS3PPXvCueRKj7+w4J6jbUxachARERMwYUFi4+7Df68f3OmhEBERExBDzfyTnMIRERERBUCERExB5dhwdKAzzJoapQQiIiIKRxbLeBP/+ZMQwYiIiKiCoGIiJiDJhV6p4RARERMQQmBd0oIRETEFDSp0DvNIRARERFVCERExBy0ysA7JQQiImIKRxMCf+YQBDCY05CGDEREREQVAhERMQetMvBOCYGIiJiC8cPhT//mTEMGIiIiogqBiIiYg4YMvFNCICIi5qAxA6+UEIiIiDn4WSGgmVcINIdAREREVCEQERFz0E6F3ikhEBERU9CkQu80ZCAiIiKqEIiIiEkYFv8mBjbzCoESAhERMQXNIfBOQwYiIiKiCoGIiJiENibySgmBiIiYglYZeFenhOD111+v8w2vvPLKUw5GREREGkedEoKrrrqqTjezWCw4nU5/4hEREak/zbzs7486JQQul6u+4xAREalXGjLwzq9VBpWVlYGKQ0REpH4ZATiaMZ8TAqfTybx58+jQoQOtWrXiyy+/BGDmzJksXbo04AGKiIg0RZmZmYwcORK73Y7FYmHNmjUe1w3DYNasWbRv356IiAiSkpLYtWuXR5vi4mKSk5OxWq1ER0czbtw4ysvLPdp8+umnXHbZZYSHhxMfH8/8+fNPKV6fE4KHHnqI5cuXM3/+fEJDQ93nf/WrX/H888+fUhAiIiL1zxKAo+4qKiro3bs3ixcvPuH1+fPnk56ezpIlS8jOziYyMpKhQ4d6VN+Tk5PZvn07GRkZrF27lszMTCZMmOC+XlZWxpAhQ+jUqRM5OTk8+uijzJ49m2effdanWOEUlh2uWLGCZ599lsGDB/PnP//Zfb5379588cUXPgcgIiLSIBp4H4Lhw4czfPjwE9/KMHjiiSe4//77GTVqFHD0+zU2NpY1a9YwZswYdu7cybp169iyZQv9+/cHYNGiRVxxxRU89thj2O12Vq5cSXV1NS+88AKhoaGcd9555ObmsmDBAo/EoS58rhDs27ePrl27Hnfe5XJRU1Pj6+1ERESalLKyMo+jqqrK53sUFBTgcDhISkpyn7PZbCQkJJCVlQVAVlYW0dHR7mQAICkpiaCgILKzs91tBgwY4FGxHzp0KHl5eRw6dMinmHxOCHr27MnGjRuPO/+vf/2Lvn37+no7ERGRhhGgSYXx8fHYbDb3kZaW5nMoDocDgNjYWI/zsbGx7msOh4N27dp5XA8JCSEmJsajzYnu8dP3qCufhwxmzZpFSkoK+/btw+Vy8eqrr5KXl8eKFStYu3atr7cTERFpGAF62mFhYSFWq9V9OiwszN/ITgs+VwhGjRrFG2+8wTvvvENkZCSzZs1i586dvPHGG/z2t7+tjxhFREROG1ar1eM4lYQgLi4OgKKiIo/zRUVF7mtxcXEcPHjQ43ptbS3FxcUebU50j5++R12d0j4El112GRkZGRw8eJAjR46wadMmhgwZciq3EhERaRDHHn/szxEoXbp0IS4ujvXr17vPlZWVkZ2dTWJiIgCJiYmUlJSQk5PjbrNhwwZcLhcJCQnuNpmZmR5z+DIyMujWrRutW7f2KaZTfrjR1q1b2blzJ3B0XkG/fv1O9VYiIiL1r4FXGZSXl5Ofn+9+XVBQQG5uLjExMXTs2JFJkybx4IMPcs4559ClSxdmzpyJ3W53Py6gR48eDBs2jPHjx7NkyRJqampITU1lzJgx2O12AK6//nrmzJnDuHHjmDZtGp9//jlPPvkkCxcu9Pnj+ZwQ7N27l+uuu44PPviA6OhoAEpKSrjkkkv4xz/+wZlnnulzECIiIs3N1q1bGTRokPv1lClTAEhJSWH58uXcc889VFRUMGHCBEpKSrj00ktZt24d4eHh7j4rV64kNTWVwYMHExQUxOjRo0lPT3dft9lsvP3220ycOJF+/frRtm1bZs2a5fOSQwCLYfhWBBk2bBglJSW8+OKLdOvWDYC8vDzGjh2L1Wpl3bp1PgdxqsrKyrDZbCTZ/0RIUPOY1CHycweu7NTYIYjUG2d1JZ8/fx+lpaUeE/UC6dh3xZnpcwmKCP/lDifh+r6SvXfMqtdYG5PPFYL333+fzZs3u5MBgG7durFo0SIuu+yygAYnIiISKBbj6OFP/+bM54QgPj7+hBsQOZ1O95iGiIjIaaeB5xA0NT6vMnj00Ue5/fbb2bp1q/vc1q1bufPOO3nssccCGpyIiIg0jDpVCFq3bo3F8uNmDhUVFSQkJBAScrR7bW0tISEh3HLLLe7ZkSIiIqeVAG1M1FzVKSF44okn6jkMERGReqYhA6/qlBCkpKTUdxwiIiLSiE55YyKAyspKqqurPc41x6UYIiLSDKhC4JXPkworKipITU2lXbt2REZG0rp1a49DRETktBSgpx02Vz4nBPfccw8bNmzg6aefJiwsjOeff545c+Zgt9tZsWJFfcQoIiIi9cznIYM33niDFStWMHDgQMaOHctll11G165d6dSpEytXriQ5Obk+4hQREfGPVhl45XOFoLi4mLPOOgs4Ol+guLgYgEsvvZTMzMzARiciIhIgx3Yq9OdoznxOCM466ywKCgoA6N69O6+88gpwtHJw7GFHIiIi0rT4nBCMHTuWTz75BIDp06ezePFiwsPDmTx5MlOnTg14gCIiIgGhSYVe+TyHYPLkye7/TkpK4osvviAnJ4euXbty/vnnBzQ4ERERaRh+7UMA0KlTJzp10uNZRUTk9GbBz6cdBiyS01OdEoL09PQ63/COO+445WBERESkcdQpIVi4cGGdbmaxWBolIajd7wBLiwZ/X5GGsG3mm40dgki9KTvsovXzDfRmWnboVZ0SgmOrCkRERJosbV3slc+rDERERKT58XtSoYiISJOgCoFXSghERMQU/N1tUDsVioiISLOnCoGIiJiDhgy8OqUKwcaNG7nhhhtITExk3759ALz00kts2rQpoMGJiIgEjLYu9srnhODf//43Q4cOJSIigo8//piqqioASktLefjhhwMeoIiIiNQ/nxOCBx98kCVLlvDcc8/RosWPmwH9+te/Ztu2bQENTkREJFD0+GPvfJ5DkJeXx4ABA447b7PZKCkpCURMIiIigaedCr3yuUIQFxdHfn7+cec3bdrEWWedFZCgREREAk5zCLzyOSEYP348d955J9nZ2VgsFvbv38/KlSu5++67+ctf/lIfMYqIiEg983nIYPr06bhcLgYPHsyRI0cYMGAAYWFh3H333dx+++31EaOIiIjftDGRdz4nBBaLhfvuu4+pU6eSn59PeXk5PXv2pFWrVvURn4iISGBoHwKvTnljotDQUHr27BnIWERERKSR+JwQDBo0CIvl5DMtN2zY4FdAIiIi9cLfpYPNvELg86TCPn360Lt3b/fRs2dPqqur2bZtG7169aqPGEVERPzXCKsMDh8+zKRJk+jUqRMRERFccsklbNmy5ceQDINZs2bRvn17IiIiSEpKYteuXR73KC4uJjk5GavVSnR0NOPGjaO8vNz3YH6BzxWChQsXnvD87Nmz6yVAERGRpurWW2/l888/56WXXsJut/P3v/+dpKQkduzYQYcOHZg/fz7p6em8+OKLdOnShZkzZzJ06FB27NhBeHg4AMnJyRw4cICMjAxqamoYO3YsEyZMYNWqVQGN1WIYRkCKIPn5+Vx00UUUFxcH4nZ1UlZWhs1mYyCjCLG0+OUOIk3QW/tzGzsEkXpTdthF63O/pLS0FKvVWj/v8cN3xVn3PUzwD1+yp8JZWcmXD91LYWGhR6xhYWGEhYUd1/77778nKiqK//u//2PEiBHu8/369WP48OHMmzcPu93OXXfdxd133w0cfQxAbGwsy5cvZ8yYMezcuZOePXuyZcsW+vfvD8C6deu44oor2Lt3L3a7/ZQ/z88F7PHHWVlZ7mxGRETkdBOorYvj4+Ox2WzuIy0t7YTvV1tbi9PpPO67MSIigk2bNlFQUIDD4SApKcl9zWazkZCQQFZWFnD0uzU6OtqdDAAkJSURFBREdnZ2QH8+Pg8ZXH311R6vDcPgwIEDbN26lZkzZwYsMBERkdPRiSoEJxIVFUViYiLz5s2jR48exMbG8vLLL5OVlUXXrl1xOBwAxMbGevSLjY11X3M4HLRr187jekhICDExMe42geJzQmCz2TxeBwUF0a1bN+bOncuQIUMCFpiIiMjpyGq11nl446WXXuKWW26hQ4cOBAcHc8EFF3DdddeRk5NTz1H6zqeEwOl0MnbsWHr16kXr1q3rKyYREZHAa4SNic4++2zef/99KioqKCsro3379vzxj3/krLPOIi4uDoCioiLat2/v7lNUVESfPn2Ao88POnjwoMc9a2trKS4udvcPFJ/mEAQHBzNkyBA91VBERJqcxnz8cWRkJO3bt+fQoUO89dZbjBo1ii5duhAXF8f69evd7crKysjOziYxMRGAxMRESkpKPCoKGzZswOVykZCQcOoBnYDPQwa/+tWv+PLLL+nSpUtAAxEREWlu3nrrLQzDoFu3buTn5zN16lS6d+/O2LFjsVgsTJo0iQcffJBzzjnHvezQbrdz1VVXAdCjRw+GDRvG+PHjWbJkCTU1NaSmpjJmzJiArjCAU0gIHnzwQe6++27mzZtHv379iIyM9LheX8tGRERE/NbAuw2WlpYyY8YM9u7dS0xMDKNHj+ahhx6iRYujS+XvueceKioqmDBhAiUlJVx66aWsW7fOY2XCypUrSU1NZfDgwQQFBTF69GjS09MDHmud9yGYO3cud911F1FRUT92/skWxoZhYLFYcDqdAQ/yZLQPgZiB9iGQ5qwh9yHoOu1hgsP82IegqpL8R+6t11gbU50rBHPmzOHPf/4z7777bn3GIyIiIo2gzgnBsULC5ZdfXm/BiIiI1Bd/Jwb69WCkJsCnOQTennIoIiJyWmuEZYdNiU8JwbnnnvuLSUFDPstAREREAsOnhGDOnDnH7VQoIiLSFGjIwDufEoIxY8Yct6eyiIhIk6AhA6/qvFOh5g+IiIg0Xz6vMhAREWmSVCHwqs4Jgcvlqs84RERE6pXmEHjn89bFIiIiTZIqBF759LRDERERaZ5UIRAREXNQhcArJQQiImIKmkPgnYYMRERERBUCERExCQ0ZeKWEQERETEFDBt5pyEBERERUIRAREZPQkIFXSghERMQclBB4pSEDERERUYVARETMwfLD4U//5kwJgYiImIOGDLxSQiAiIqagZYfeaQ6BiIiIqEIgIiImoSEDr5QQiIiIeTTzL3V/aMhAREREVCEQERFz0KRC75QQiIiIOWgOgVcaMhARERFVCERExBw0ZOCdEgIRETEHDRl4pSEDERGReuB0Opk5cyZdunQhIiKCs88+m3nz5mEYP2YWhmEwa9Ys2rdvT0REBElJSezatcvjPsXFxSQnJ2O1WomOjmbcuHGUl5cHPF4lBCIiYgrHhgz8OXzxyCOP8PTTT/PUU0+xc+dOHnnkEebPn8+iRYvcbebPn096ejpLliwhOzubyMhIhg4dSmVlpbtNcnIy27dvJyMjg7Vr15KZmcmECRMC9WNx05CBiIiYQ4CGDMrKyjxOh4WFERYWdlzzzZs3M2rUKEaMGAFA586defnll/noo4+O3s4weOKJJ7j//vsZNWoUACtWrCA2NpY1a9YwZswYdu7cybp169iyZQv9+/cHYNGiRVxxxRU89thj2O12Pz6QJ1UIRETEHIwAHEB8fDw2m819pKWlnfDtLrnkEtavX8///vc/AD755BM2bdrE8OHDASgoKMDhcJCUlOTuY7PZSEhIICsrC4CsrCyio6PdyQBAUlISQUFBZGdnB+Kn4qYKgYiIiA8KCwuxWq3u1yeqDgBMnz6dsrIyunfvTnBwME6nk4ceeojk5GQAHA4HALGxsR79YmNj3dccDgft2rXzuB4SEkJMTIy7TaAoIRAREVMI1LJDq9XqkRCczCuvvMLKlStZtWoV5513Hrm5uUyaNAm73U5KSsqpB1JPlBCIiIg5NPCyw6lTpzJ9+nTGjBkDQK9evfj6669JS0sjJSWFuLg4AIqKimjfvr27X1FREX369AEgLi6OgwcPety3traW4uJid/9A0RwCERGRenDkyBGCgjy/ZoODg3G5XAB06dKFuLg41q9f775eVlZGdnY2iYmJACQmJlJSUkJOTo67zYYNG3C5XCQkJAQ0XlUIRETEFCyGgcU49RKBr31HjhzJQw89RMeOHTnvvPP4+OOPWbBgAbfccsvR+1ksTJo0iQcffJBzzjmHLl26MHPmTOx2O1dddRUAPXr0YNiwYYwfP54lS5ZQU1NDamoqY8aMCegKA1BCICIiZtHAQwaLFi1i5syZ3HbbbRw8eBC73c6f/vQnZs2a5W5zzz33UFFRwYQJEygpKeHSSy9l3bp1hIeHu9usXLmS1NRUBg8eTFBQEKNHjyY9Pd2PD3JiFsPwI11qZGVlZdhsNgYyihBLi8YOR6RevLU/t7FDEKk3ZYddtD73S0pLS+s0Ue+U3uOH74o+NzxEcGj4L3c4CWd1Jbl/v69eY21MqhCIiIgp6OFG3ikhEBERc9DDjbzSKgMRERFRhUBERMxBQwbeKSEQERFz0JCBV0oIRETEFFQh8E5zCEREREQVAhERMQkNGXilhEBEREyjuZf9/aEhAxEREVGFQERETMIwjh7+9G/GlBCIiIgpaJWBdxoyEBEREVUIRETEJLTKwCslBCIiYgoW19HDn/7NmYYMRERERBUCs7vhLgc33lXkca4wP4xbB3QHYHjydwz6/SG69vqeyCgXV3f/FRVlwR7tO5xVxfiZ++l5YQUhLQwKdoazYn57PtncqsE+h8gxn30YyT//1o5dn7WkuKgFDywt4JLhpe7rLz0Wx3v/F803+1vQItSga6/vGTv9AN0vOALAJ5tbcc8fup7w3ulv5tGtz/fA0Qnn/1pyBv9d2YaDe0OxxtTyu5TvuP7OohP2ldOAhgy8UkIgfPVFONP/eJb7tdNpcf93eISLre9FsfW9KMbd6zhh/7kvfsm+gjCmXXM2VZVB/H78N8xdUcDNid059E2Leo9f5KcqjwRx1nnfM/S6YuaO63Lc9Q5nVTLxob2071RNVWUQrz17BjOuO5tlm3cQ3cZJz/4VvJz7uUefF+e3J3dTK87t/b373NMzO5DzfhTjZ+6nS49KDpcEU3Yo+OdvJ6cRrTLwrlETgszMTB599FFycnI4cOAAr732GldddVVjhmRKTicn/eJ+7fkzADg/sfyE160xtZx5djUL74qnYGcEAC881J4rb/6Ozt0rlRBIg7vwN4e58DeHT3r9N1eXeLyeMHsf615uQ8GOCPpeVk6LUIOYdrXu67U1kPWWlVG3fIvlh1x5z64w1q5oyzMbviC+axUAcR0D/lEk0LQPgVeNOoegoqKC3r17s3jx4sYMw/Q6dKlm1bbtLM/aybSnvuaMDtV17ltWHExhfhhJ1xwiLMJJULDBiBu/49A3Iez6NKIeoxbxX021hTf/3oZIq5Ozen5/wjZZb9s4fCiEIX8sdp/78G0b7TtWkf2OlZsSenDTRT1ZeFe8KgTSpDVqhWD48OEMHz68zu2rqqqoqqpyvy4rK6uPsEzli20teWxSPHt3hxHTroYb7iri8dfy+dOgbnxfUZd/3CxM/+NZPPDCV6zZ9TmGC0q+DeG+5C6Ul2pESk5PH2ZYSftLJ6q+DyImtoa0f+Rja+M8Ydu3Xm5Dv4GHOcNe4z53YE8oRftC2bg2mqnpe3A5LTzzgJ0HJ3Rm/j93N9THEB9pyMC7JrXKIC0tDZvN5j7i4+MbO6Qmb+u7VjaujaZgZwQ571u5/4azaGV1MuDKkjrewSD14X2UfBvCXb/vyh0jzmHzOhtzln9FTLuaX+4u0gj6/Lqcv2XksfD1XfQfeJiH/tSZkm+PT2C/2d+CnPeiGHrddx7nDRfUVAUx9ck99EqooPcl5Ux+vJBPPoiiMD+soT6G+MoIwNGMNamEYMaMGZSWlrqPwsLCxg6p2akoC2bvl2HYO9dt2KDPpeVclFRG2l86sWNLJPmfteSpe8+kutJC0rXFv3wDkUYQ3tJFhy7V9Oh3hCkLCgkOgXUvxxzX7u3VMUS1riVxSKnH+Zh2tQSHGJx59o8Vy47nVAJwcJ/mzUjT1KRqumFhYYSFKfuuT+Etndg7VbP+33X71QiLOLpTh+tnG3a4DAtBlhN0EDkNHfuL3+OccTQhSPrDIUJ+9h1/3oUVOGst7P8q1J087/3y6L9NsWeqMna60pCBd00qIZDAGz9rPx++beXg3lDaxNVw490OnC5477XWALQ+o4bW7Wqxdzn6l1CX7t9zpCKYb/a14HBJCDtzIikvDWbqk4WsXBhLVWUQw5O/Iy6+mo/WWxvzo4lJfV8RxP6CH/9wcBSGsvvzCKKia7HGOFn1ZCyJQ0qJia2hrDiE15e15VtHCy4bWeJxn9xNrXDsCWPY9d/xc30HHKZrryMsmNKRP8/Zh2HAU/eeyQUDyjyqBnKa0SoDr5QQmFzb9jXM+NvXRLV2UvpdCNu3RDLpd+dQWnz0V2PETd95bFz0+JqjE6YemxRPxisxlBWHcN/1Z3Hz9AM88spuglsYfJ0Xzuyxnflyh1YZSMP73yctPTYWemZ2BwB+e20xd/y1kL35Ycz7Z2fKikOIau3k3N5HePy1XXTuVulxn3Uvt6Fn/3I6nnP8F3xQ0NH9NxbffyZ3X92V8JYu+g8qY8ID++v3w4nUI4thNF7KU15eTn5+PgB9+/ZlwYIFDBo0iJiYGDp2/OVFvWVlZdhsNgYyihCLxu2keXprf25jhyBSb8oOu2h97peUlpZitdZPVfHYd0Xi8LmEtAg/5fvU1lSS9d9Z9RprY2rUCsHWrVsZNGiQ+/WUKVMASElJYfny5Y0UlYiINEvautirRk0IBg4cSCMWKEREROQHmkMgIiKmoFUG3ikhEBERc3AZRw9/+jdjSghERMQcNIfAqya1U6GIiEhT0blzZywWy3HHxIkTAaisrGTixIm0adOGVq1aMXr0aIqKijzusWfPHkaMGEHLli1p164dU6dOpba29kRv5zclBCIiYgoWfpxHcEqHj++3ZcsWDhw44D4yMjIAuOaaawCYPHkyb7zxBv/85z95//332b9/P1dffbW7v9PpZMSIEVRXV7N582ZefPFFli9fzqxZswL0E/GkIQMRETGHAO1U+PMn7Z5sW/0zzjjD4/Vf//pXzj77bC6//HJKS0tZunQpq1at4je/+Q0Ay5Yto0ePHnz44YdcfPHFvP322+zYsYN33nmH2NhY+vTpw7x585g2bRqzZ88mNDT01D/LCahCICIi4oP4+HiPJ++mpaX9Yp/q6mr+/ve/c8stt2CxWMjJyaGmpoakpCR3m+7du9OxY0eysrIAyMrKolevXsTGxrrbDB06lLKyMrZv3x7wz6UKgYiImEKglh0WFhZ67FRYl4furVmzhpKSEm6++WYAHA4HoaGhREdHe7SLjY3F4XC42/w0GTh2/di1QFNCICIi5hCgVQZWq9XnrYuXLl3K8OHDsdvtfgRQvzRkICIiUo++/vpr3nnnHW699Vb3ubi4OKqrqykpKfFoW1RURFxcnLvNz1cdHHt9rE0gKSEQERFTsBiG38epWLZsGe3atWPEiBHuc/369aNFixasX7/efS4vL489e/aQmJgIQGJiIp999hkHDx50t8nIyMBqtdKzZ89T/CmcnIYMRETEHFw/HP7097WLy8WyZctISUkhJOTHr1ybzca4ceOYMmUKMTExWK1Wbr/9dhITE7n44osBGDJkCD179uTGG29k/vz5OBwO7r//fiZOnFineQu+UkIgIiJST9555x327NnDLbfccty1hQsXEhQUxOjRo6mqqmLo0KH87W9/c18PDg5m7dq1/OUvfyExMZHIyEhSUlKYO3duvcSqhEBEREzBn7L/sf6+GjJkyEmf6hseHs7ixYtZvHjxSft36tSJN9980+f3PRVKCERExBz0LAOvlBCIiIg5BGinwuZKqwxEREREFQIRETGHQO1U2FwpIRAREXPQkIFXGjIQERERVQhERMQcLK6jhz/9mzMlBCIiYg4aMvBKQwYiIiKiCoGIiJiENibySgmBiIiYQmNsXdyUaMhAREREVCEQERGT0KRCr5QQiIiIORiAP0sHm3c+oIRARETMQXMIvNMcAhEREVGFQERETMLAzzkEAYvktKSEQEREzEGTCr3SkIGIiIioQiAiIibhAix+9m/GlBCIiIgpaJWBdxoyEBEREVUIRETEJDSp0CslBCIiYg5KCLzSkIGIiIioQiAiIiahCoFXSghERMQctOzQKyUEIiJiClp26J3mEIiIiIgqBCIiYhKaQ+CVEgIRETEHlwEWP77UXc07IdCQgYiIiCghEBERkzg2ZODP4aN9+/Zxww030KZNGyIiIujVqxdbt279SUgGs2bNon379kRERJCUlMSuXbs87lFcXExycjJWq5Xo6GjGjRtHeXm53z+On1NCICIiJuFvMuBbQnDo0CF+/etf06JFC/773/+yY8cOHn/8cVq3bu1uM3/+fNLT01myZAnZ2dlERkYydOhQKisr3W2Sk5PZvn07GRkZrF27lszMTCZMmBCoH4qb5hCIiIj4oKyszON1WFgYYWFhx7V75JFHiI+PZ9myZe5zXbp0cf+3YRg88cQT3H///YwaNQqAFStWEBsby5o1axgzZgw7d+5k3bp1bNmyhf79+wOwaNEirrjiCh577DHsdnvAPpcqBCIiYg4BGjKIj4/HZrO5j7S0tBO+3euvv07//v255ppraNeuHX379uW5555zXy8oKMDhcJCUlOQ+Z7PZSEhIICsrC4CsrCyio6PdyQBAUlISQUFBZGdnB/THowqBiIiYg8v3sv/x/aGwsBCr1eo+faLqAMCXX37J008/zZQpU7j33nvZsmULd9xxB6GhoaSkpOBwOACIjY316BcbG+u+5nA4aNeuncf1kJAQYmJi3G0CRQmBiIiID6xWq0dCcDIul4v+/fvz8MMPA9C3b18+//xzlixZQkpKSn2H6TMNGYiIiDkYLv8PH7Rv356ePXt6nOvRowd79uwBIC4uDoCioiKPNkVFRe5rcXFxHDx40ON6bW0txcXF7jaBooRARETMoYGXHf76178mLy/P49z//vc/OnXqBBydYBgXF8f69evd18vKysjOziYxMRGAxMRESkpKyMnJcbfZsGEDLpeLhISEU/1JnJCGDERExBwCNIegriZPnswll1zCww8/zLXXXstHH33Es88+y7PPPguAxWJh0qRJPPjgg5xzzjl06dKFmTNnYrfbueqqq4CjFYVhw4Yxfvx4lixZQk1NDampqYwZMyagKwxACYGIiEi9uPDCC3nttdeYMWMGc+fOpUuXLjzxxBMkJye729xzzz1UVFQwYcIESkpKuPTSS1m3bh3h4eHuNitXriQ1NZXBgwcTFBTE6NGjSU9PD3i8FsNouk9rKCsrw2azMZBRhFhaNHY4IvXirf25jR2CSL0pO+yi9blfUlpaWqeJeqf0Hj98VyTZ/0RI0IlXBNRFrauKd/Y/U6+xNiZVCERExBwM/HzaYcAiOS1pUqGIiIioQiAiIiZxig8o8ujfjCkhEBERc3C5AN/2Eji+f/OlIQMRERFRhUBERExCQwZeKSEQERFzUELglYYMRERERBUCERExiQbeuripUUIgIiKmYBguDB+fWPjz/s2ZEgIRETEHw/Dvr3zNIRAREZHmThUCERExB8PPOQTNvEKghEBERMzB5QKLH/MAmvkcAg0ZiIiIiCoEIiJiEhoy8EoJgYiImILhcmH4MWTQ3JcdashAREREVCEQERGT0JCBV0oIRETEHFwGWJQQnIyGDEREREQVAhERMQnDAPzZh6B5VwiUEIiIiCkYLgPDjyEDQwmBiIhIM2C48K9CoGWHIiIi0sypQiAiIqagIQPvlBCIiIg5aMjAqyadEBzL1mqp8WuvCZHTWdnh5v2PkJhbWfnR3++G+Ovb3++KWmoCF8xpqEknBIcPHwZgE282ciQi9af1uY0dgUj9O3z4MDabrV7uHRoaSlxcHJsc/n9XxMXFERoaGoCoTj8WowkPirhcLvbv309UVBQWi6WxwzGFsrIy4uPjKSwsxGq1NnY4IgGl3++GZxgGhw8fxm63ExRUf/PcKysrqa6u9vs+oaGhhIeHByCi00+TrhAEBQVx5plnNnYYpmS1WvUPpjRb+v1uWPVVGfip8PDwZvtFHihadigiIiJKCEREREQJgfgoLCyMBx54gLCwsMYORSTg9PstZtakJxWKiIhIYKhCICIiIkoIRERERAmBiIiIoIRAREREUEIgPli8eDGdO3cmPDychIQEPvroo8YOSSQgMjMzGTlyJHa7HYvFwpo1axo7JJEGp4RA6mT16tVMmTKFBx54gG3bttG7d2+GDh3KwYMHGzs0Eb9VVFTQu3dvFi9e3NihiDQaLTuUOklISODCCy/kqaeeAo4+RyI+Pp7bb7+d6dOnN3J0IoFjsVh47bXXuOqqqxo7FJEGpQqB/KLq6mpycnJISkpynwsKCiIpKYmsrKxGjExERAJFCYH8om+//Ran00lsbKzH+djYWBwORyNFJSIigaSEQERERJQQyC9r27YtwcHBFBUVeZwvKioiLi6ukaISEZFAUkIgvyg0NJR+/fqxfv169zmXy8X69etJTExsxMhERCRQQho7AGkapkyZQkpKCv379+eiiy7iiSeeoKKigrFjxzZ2aCJ+Ky8vJz8/3/26oKCA3NxcYmJi6NixYyNGJtJwtOxQ6uypp57i0UcfxeFw0KdPH9LT00lISGjssET89t577zFo0KDjzqekpLB8+fKGD0ikESghEBEREc0hEBERESUEIiIighICERERQQmBiIiIoIRAREREUEIgIiIiKCEQERERlBCIiIgISghE/HbzzTdz1VVXuV8PHDiQSZMmNXgc7733HhaLhZKSkpO2sVgsrFmzps73nD17Nn369PErrq+++gqLxUJubq5f9xGR+qWEQJqlm2++GYvFgsViITQ0lK5duzJ37lxqa2vr/b1fffVV5s2bV6e2dfkSFxFpCHq4kTRbw4YNY9myZVRVVfHmm28yceJEWrRowYwZM45rW11dTWhoaEDeNyYmJiD3ERFpSKoQSLMVFhZGXFwcnTp14i9/+QtJSUm8/vrrwI9l/oceegi73U63bt0AKCws5NprryU6OpqYmBhGjRrFV1995b6n0+lkypQpREdH06ZNG+655x5+/jiQnw8ZVFVVMW3aNOLj4wkLC6Nr164sXbqUr776yv1AndatW2OxWLj55puBo4+XTktLo0uXLkRERNC7d2/+9a9/ebzPm2++ybnnnktERASDBg3yiLOupk2bxrnnnkvLli0566yzmDlzJjU1Nce1e+aZZ4iPj6dly5Zce+21lJaWelx//vnn6dGjB+Hh4XTv3p2//e1vPsciIo1LCYGYRkREBNXV1e7X69evJy8vj4yMDNauXUtNTQ1Dhw4lKiqKjRs38sEHH9CqVSuGDRvm7vf444+zfPlyXnjhBTZt2kRxcTGvvfaa1/e96aabePnll0lPT2fnzp0888wztGrVivj4eP79738DkJeXx4EDB3jyyScBSEtLY8WKFSxZsoTt27czefJkbrjhBt5//33gaOJy9dVXM3LkSHJzc7n11luZPn26zz+TqKgoli9fzo4dO3jyySd57rnnWLhwoUeb/Px8XnnlFd544w3WrVvHxx9/zG233ea+vnLlSmbNmsVDDz3Ezp07efjhh5k5cyYvvviiz/GISCMyRJqhlJQUY9SoUYZhGIbL5TIyMjKMsLAw4+6773Zfj42NNaqqqtx9XnrpJaNbt26Gy+Vyn6uqqjIiIiKMt956yzAMw2jfvr0xf/589/WamhrjzDPPdL+XYRjG5Zdfbtx5552GYRhGXl6eARgZGRknjPPdd981AOPQoUPuc5WVlUbLli2NzZs3e7QdN26ccd111xmGYRgzZswwevbs6XF92rRpx93r5wDjtddeO+n1Rx991OjXr5/79QMPPGAEBwcbe/fudZ/773//awQFBRkHDhwwDMMwzj77bGPVqlUe95k3b56RmJhoGIZhFBQUGIDx8ccfn/R9RaTxaQ6BNFtr166lVatW1NTU4HK5uP7665k9e7b7eq9evTzmDXzyySfk5+cTFRXlcZ/Kykp2795NaWkpBw4cICEhwX0tJCSE/v37HzdscExubi7BwcFcfvnldY47Pz+fI0eO8Nvf/tbjfHV1NX379gVg586dHnEAJCYm1vk9jlm9ejXp6ens3r2b8vJyamtrsVqtHm06duxIhw4dPN7H5XKRl5dHVFQUu3fvZty4cYwfP97dpra2FpvN5nM8ItJ4lBBIszVo0CCefvppQkNDsdvthIR4/rpHRkZ6vC4vL6dfv36sXLnyuHudccYZpxRDRESEz33Ky8sB+M9//uPxRQxH50UESlZWFsnJycyZM4ehQ4dis9n4xz/+weOPP+5zrM8999xxCUpwcHDAYhWR+qeEQJqtyMhIunbtWuf2F1xwAatXr6Zdu3bH/ZV8TPv27cnOzmbAgAHA0b+Ec3JyuOCCC07YvlevXrhcLt5//32SkpKOu36sQuF0Ot3nevbsSVhYGHv27DlpZaFHjx7uCZLHfPjhh7/8IX9i8+bNdOrUifvuu8997uuvvz6u3Z49e9i/fz92u939PkFBQXTr1o3Y2FjsdjtffvklycnJPr2/iJxeNKlQ5AfJycm0bduWUaNGsXHjRgoKCnjvvfe444472Lt3LwB33nknf/3rX1mzZg1ffPEFt912m9c9BDp37kxKSgq33HILa9ascd/zlVdeAaBTp05YLBbWrl3LN998Q3l5OVFRUdx9991MnjyZF198kd27d7Nt2zYWLVrknqj35z//mV27djF16lTy8vJYtWoVy5cv9+nznnPOOezZs4d//OMf7N69m/T09BNOkAwPDyclJYVPPvmEjRs3cscdd3DttdcSFxcHwJw5c0hLSyM9PZ3//e9/fPbZZyxbtowFCxb4FI+INC4lBCI/aNmyJZmZmXTs2JGrr76aHj16MG7cOCorK90Vg7vuuosbb7yRlJQUEhMTiYqK4ve//73X+z799NP84Q9/4LbbbqN79+6MHz+eiooKADp06MCcOXOYPn06sbGxpKamAjBv3jxmzpxJWloaPXr0YNiwYfznP/+hS5cuwNFx/X//+9+sWbOG3r17s2TJEh5++GGfPu+VV17J5MmTSU1NpU+fPmzevJmZM2ce165r165cffXVXHHFFQwZMoTzzz/fY1nhrbfeyvPPP8+yZcvo1asXl19+OcuXL3fHKiJNg8U42WwoERERMQ1VCEREREQJgYiIiCghEBEREZQQiIiICEoIREREBCUEIiIighICERERQQmBiIiIoIRAREREUEIgIiIiKCEQERER4P8BIbpq/VpQ17EAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_sgdc)\n",
    "\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = [0, 1])\n",
    "\n",
    "cm_display.plot()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323d9335-9ecb-4ebe-8dcb-c7957efdad39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
